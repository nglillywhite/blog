{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e74da902-e5b7-49c6-b309-208ce9abaa41",
   "metadata": {},
   "source": [
    "---\n",
    "badges: true\n",
    "categories:\n",
    "- jupyter\n",
    "- fastai\n",
    "- ML\n",
    "date: '2023-01-20'\n",
    "description: No Frameworks, No Fluff\n",
    "title: Fastai Lesson 5 | Linear Models & Neural Nets from Scratch\n",
    "author: Nicholas Lillywhite\n",
    "toc: true\n",
    "image: \"images/sig.png\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88043c35-2674-452d-8bdb-b3bdef2035d7",
   "metadata": {},
   "source": [
    "# Lesson 5 | Linear Models & Neural Nets from Scratch\n",
    "> Building upon Lesson 3 Foundational Concepts\n",
    "\n",
    "> Checkout this notebook in [colab](https://colab.research.google.com/github/nglillywhite/blog/blob/main/posts/2023-01-20-Fastai%20Lesson%205.ipynb)\n",
    "\n",
    "## Lecture Content\n",
    "\n",
    "Now since we've already worked through the [chapter 4](https://github.com/fastai/fastbook/blob/master/04_mnist_basics.ipynb) book content in my lesson 3 blogpost, I won't repeat the work here, [instead I'd recommend you checkout that post](https://nglillywhite.quarto.pub/nicks-blog/posts/2022-12-29-Fastai%20Lesson%203.html#book-content) if you'd like to see the book content that pairs with this week's lecture.\n",
    "\n",
    "### Downloading Data from Kaggle\n",
    "\n",
    "Building upon the concepts and principles we learned in lesson 3, we're going to build our neural net from scratch and run it against the titanic dataset which we can source from kaggle. We can use the python api to select the competition and download all the data to a given path like we have below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0586bd4-4962-4e75-9854-2f40b0ab6a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading titanic.zip to ..\\data\\titanic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 34.1k/34.1k [00:00<00:00, 3.88MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import kaggle\n",
    "import zipfile\n",
    "\n",
    "path = Path(\"../data/titanic\")\n",
    "path.mkdir(exist_ok=True)\n",
    "kaggle.api.competition_download_cli(competition=\"titanic\",\n",
    "                                    path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dc00bf-e3f9-46ad-883e-03940e097bd6",
   "metadata": {},
   "source": [
    "Then we can extract the zip from our path to our path to unpack the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24dd3ca1-b646-4743-aa1b-bc5f4524c42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipfile.ZipFile(f\"{path}\\\\titanic.zip\").extractall(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597695fd-49fa-48ba-a3ac-feb0f4cb1d33",
   "metadata": {},
   "source": [
    "I'm just importing fastai to get the 'nice' version of Path which allows me to .ls() the directory and see whats inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb0aab0a-4f1d-48c0-9497-f5e8872be2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f68c6cd4-1399-406a-b7b2-335871fde134",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"../data/titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0afe6a19-e8d7-48ff-b12f-bc2a9cb507cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#4) [Path('../data/titanic/gender_submission.csv'),Path('../data/titanic/test.csv'),Path('../data/titanic/titanic.zip'),Path('../data/titanic/train.csv')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68767c3c-64dc-4dae-91a1-011a4c31e963",
   "metadata": {},
   "source": [
    "Cool, we've got our test, train, and submission csvs as well as the original zip.\n",
    "\n",
    "As mentioned in the lesson, we're going to import pytorch and numpy to work with arrays, and pandas for working with dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06c01e64-acf8-44b1-b17b-3151b9d35863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7d40e7-bc83-497a-a6c4-426434cf0aac",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "Lets first do some data cleaning along with the course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8facf324-8bb5-4d35-a2c3-830beac86723",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9a2c76f-3d34-4f4b-b697-4ad73b3ebfd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e51eb8-8688-431c-acff-b3328c8d16ba",
   "metadata": {},
   "source": [
    "As we learned in lesson 3, we want to apply all our inputs by some weights and biases, but if we look at the 'Cabin' column there are some 'NaN' values, or \"Not a Number\" values, we've got to change this to something computable for our model to work. Lets checkout how many NaNs are there in the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21b25d1a-0557-4789-b741-7d75e24462e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27ab450-6a0a-4f05-a4b1-a6b4aad23162",
   "metadata": {},
   "source": [
    "Ok it looks like only Age and Cabin have NaN values that we need to handle. One strategy for imputing missing values is replacing them with the 'mode', or the most commonly occuring value already present in the array, lets checkout the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b456bd9-9702-4286-a786-8c3b4d38f232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId                      1\n",
       "Survived                       0.0\n",
       "Pclass                         3.0\n",
       "Name           Abbing, Mr. Anthony\n",
       "Sex                           male\n",
       "Age                           24.0\n",
       "SibSp                          0.0\n",
       "Parch                          0.0\n",
       "Ticket                        1601\n",
       "Fare                          8.05\n",
       "Cabin                      B96 B98\n",
       "Embarked                         S\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modes = df.mode().iloc[0]\n",
    "modes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91d8b29-9532-4f41-ad35-74ed6bdd8a72",
   "metadata": {},
   "source": [
    "We can now fill the columns with the most commonly occuring values that we grabbed from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95f1fac0-954c-4be1-9fcc-2a0a370ba0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(modes, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe3b9ee-5ea6-44f6-9e94-0ad54e000009",
   "metadata": {},
   "source": [
    "Any empties left? Lets look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a5dbf54-848b-454b-8216-c429a2a10bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d76e06-a5b5-4db7-9763-56201841a359",
   "metadata": {},
   "source": [
    "The pandas describe() function is a really cool way to investigate either all or certain datatypes, combine this with numpy's types and we can get specifically all the numeric data types by using the np.number base class and the describe() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0d709d0-23c1-4d7e-a32c-c84c3c10ffeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m      Abstract base class of all numeric scalar types.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\nick\\anaconda3\\envs\\fastai\\lib\\site-packages\\numpy\\__init__.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     integer, inexact\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77ad2995-46e0-41e0-8df9-6c3f72c66052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>28.566970</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.199572</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   28.566970    0.523008   \n",
       "std     257.353842    0.486592    0.836071   13.199572    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   24.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   35.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=np.number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ac4568-8a12-4f5c-a4b2-a141d747b696",
   "metadata": {},
   "source": [
    "Ok we can see that fare has 75% of fares under \\\\$31 but a mean of \\\\$32 and a max of $512, this would lead us to thinking there's quite a skewed distribution. This kind of skewness will bias our weights to these large values when we don't really want them to, lets have a look at the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a15f2311-1bd2-40aa-858d-082fe58de0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.Fare.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21189d5-35c6-4101-9a60-dd43272de80f",
   "metadata": {},
   "source": [
    "Super skewed! Almost all the values are below 50, yet we go up to ~\\\\$500 in this graph. What we can do to distribute these values more normally is take the log of the array which will squish down these massive numbers and not fetter with the lower values too much. Also we're adding 1 to all values since there are some 0 fares and log(0) is infinity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2332a505-8005-4722-81c1-54f4c60ad032",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"LogFare\"] = np.log(df.Fare+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b3b8f69-c444-4eda-ba70-478a8c748ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.LogFare.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ecc43d-6912-4b1a-a2ee-86dd07e7ed3a",
   "metadata": {},
   "source": [
    "That looks way better, sure its not perfect but everything is a more manageable value and we can definitely see a reduced skew.\n",
    "\n",
    "Lets checkout the other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7582d91c-82be-4214-b015-abdb8b0ab512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>LogFare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>28.566970</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>2.962246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.199572</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.969048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>2.187218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>2.737881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>3.465736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>6.240917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   28.566970    0.523008   \n",
       "std     257.353842    0.486592    0.836071   13.199572    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   24.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   35.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare     LogFare  \n",
       "count  891.000000  891.000000  891.000000  \n",
       "mean     0.381594   32.204208    2.962246  \n",
       "std      0.806057   49.693429    0.969048  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    7.910400    2.187218  \n",
       "50%      0.000000   14.454200    2.737881  \n",
       "75%      0.000000   31.000000    3.465736  \n",
       "max      6.000000  512.329200    6.240917  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baed9e9-dfc6-46c4-8f73-dff5d9516a39",
   "metadata": {},
   "source": [
    "PClass also seems to only have three classes, which is actually outlined to us in the competition guidelines, we could also look at the histogram to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc57c352-7aa3-4f6b-bc71-52ca42364350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.Pclass.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8337fac-8381-41ef-a532-f86411dd6860",
   "metadata": {},
   "source": [
    "Thats not continuous at all, we can also use the unique() method on the pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8c2ca35-25a1-411a-ba27-074b7d7bceeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Pclass.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ba89a29-ec53-4ad6-b0d7-56c05c0456c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pclasses = sorted(df.Pclass.unique())\n",
    "pclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75f5826-6fbc-465b-9179-522fec4f3fe6",
   "metadata": {},
   "source": [
    "Ok now lets checkout the non numeric values, which we'll have to represent numerically somehow since we need to be able to multiply them by our weights and biases. A simple way to do this is one-hot-encoding them, also known as making 'dummy' values which creates a binary column each for 'n' classes and then a 0 or 1 in each column if that class is observed. You can technically do n-1 classes since if all the binary columns are 0 then you've technically observed the last column but most often you'll explicitly express each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e02214fd-571a-4f7f-94c4-ad4d72805501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>347082</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>691</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   Sex  Ticket    Cabin Embarked\n",
       "count                       891   891     891      891      891\n",
       "unique                      891     2     681      147        3\n",
       "top     Braund, Mr. Owen Harris  male  347082  B96 B98        S\n",
       "freq                          1   577       7      691      646"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=[object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7dd4d77e-3615-4fd2-b50c-f5a678996798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>LogFare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>4.280593</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>2.188856</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>3.990834</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>2.202765</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived                                                 Name  \\\n",
       "0            1         0                              Braund, Mr. Owen Harris   \n",
       "1            2         1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)   \n",
       "2            3         1                               Heikkinen, Miss. Laina   \n",
       "3            4         1         Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5         0                             Allen, Mr. William Henry   \n",
       "\n",
       "    Age  SibSp  Parch            Ticket     Fare    Cabin   LogFare  \\\n",
       "0  22.0      1      0         A/5 21171   7.2500  B96 B98  2.110213   \n",
       "1  38.0      1      0          PC 17599  71.2833      C85  4.280593   \n",
       "2  26.0      0      0  STON/O2. 3101282   7.9250  B96 B98  2.188856   \n",
       "3  35.0      1      0            113803  53.1000     C123  3.990834   \n",
       "4  35.0      0      0            373450   8.0500  B96 B98  2.202765   \n",
       "\n",
       "   Sex_female  Sex_male  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  \\\n",
       "0           0         1         0         0         1           0           0   \n",
       "1           1         0         1         0         0           1           0   \n",
       "2           1         0         0         0         1           0           0   \n",
       "3           1         0         1         0         0           0           0   \n",
       "4           0         1         0         0         1           0           0   \n",
       "\n",
       "   Embarked_S  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df,columns=[\"Sex\",\"Pclass\",\"Embarked\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4661c2-b0d8-4abd-9e9e-2c606b9325ef",
   "metadata": {},
   "source": [
    "Ok we can see some new columns being added, with the structure of 'originalColumn_classObservation', for example 'Sex_female'. Lets grab these added columns specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "de87d3c0-efe4-4f69-889b-4072fc3b93f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex_female  Sex_male  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  \\\n",
       "0           0         1         0         0         1           0           0   \n",
       "1           1         0         1         0         0           1           0   \n",
       "2           1         0         0         0         1           0           0   \n",
       "3           1         0         1         0         0           0           0   \n",
       "4           0         1         0         0         1           0           0   \n",
       "\n",
       "   Embarked_S  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_columns = list(df.columns[10:])\n",
    "df[new_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d720644-073c-4925-a91e-db37e40e54dc",
   "metadata": {},
   "source": [
    "### Creating Independent & Dependent Variables\n",
    "\n",
    "Now we've got to make our 'x' (Independent / Predictors) and 'y' (Dependent / Target) tensors for us to train and predict with. We're trying to predict if someone survived so \"Survived\" is our y value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aec05822-3e3f-456c-b657-0884790649b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "\n",
    "t_dep = tensor(df.Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a283c46d-108b-4e4e-9c69-25fd83aa852b",
   "metadata": {},
   "source": [
    "Our x values are all the continues values we can grab as well as the dummy values we made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8842cd7f-26a9-430e-ab8d-802babc52fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22.,  1.,  0.,  ...,  0.,  0.,  1.],\n",
       "        [38.,  1.,  0.,  ...,  1.,  0.,  0.],\n",
       "        [26.,  0.,  0.,  ...,  0.,  0.,  1.],\n",
       "        ...,\n",
       "        [24.,  1.,  2.,  ...,  0.,  0.,  1.],\n",
       "        [26.,  0.,  0.,  ...,  1.,  0.,  0.],\n",
       "        [32.,  0.,  0.,  ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "independent_cols = ['Age', \"SibSp\", \"Parch\", \"LogFare\"] + new_columns\n",
    "\n",
    "t_independent = tensor(df[independent_cols].values, dtype=torch.float)\n",
    "t_independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "87118af3-523d-4e9d-beaf-13dfbbde7f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([891, 12])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_independent.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0717da0-7181-4724-8a2c-2daea845944e",
   "metadata": {},
   "source": [
    "Ok so we've got our 891 observations of 12 columns / attributes / features to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c89be2-ad66-43fd-8b78-04536afa4418",
   "metadata": {},
   "source": [
    "### Building our Linear Model\n",
    "\n",
    "We will first build a totally linear model without any non-linear activation functions like a ReLu (That we worked through in Lesson 3), to do this we'll get a coefficient for each independent variable (column/feature) by picking a random value in the range of (-5,5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "328946c0-95e2-42de-8ff5-4555afa7b6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3313,  0.0565,  0.4642, -0.0014,  0.1842, -0.3090, -0.4595, -0.0689,\n",
       "         0.3639,  0.2758, -0.3921,  0.3848])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(26)\n",
    "\n",
    "n_coefficients = t_independent.shape[1]\n",
    "coefficients = torch.rand(n_coefficients)-0.5\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18c66db-ac9e-4f1a-96bc-c623c6bea107",
   "metadata": {},
   "source": [
    "Looks pretty random to me. We're going to multiply all our coefficients with our x values and add them up. Lets do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1117c797-8bbc-42ce-9773-8248adfb4c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.2897,  0.0565,  0.0000,  ...,  0.0000, -0.0000,  0.3848],\n",
       "        [12.5912,  0.0565,  0.0000,  ...,  0.2758, -0.0000,  0.0000],\n",
       "        [ 8.6150,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.3848],\n",
       "        ...,\n",
       "        [ 7.9523,  0.0565,  0.9284,  ...,  0.0000, -0.0000,  0.3848],\n",
       "        [ 8.6150,  0.0000,  0.0000,  ...,  0.2758, -0.0000,  0.0000],\n",
       "        [10.6031,  0.0000,  0.0000,  ...,  0.0000, -0.3921,  0.0000]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_independent*coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bbd23b-3ad7-46b0-8c47-4bcff8f980f1",
   "metadata": {},
   "source": [
    "Our first column age is simply a lot bigger than all our other columns and is dominating the output, we can normalise the values between 0 and 1 for all columns so that no particular nominal size of values for any column is bigger than another. We can use sigmoid or simply divide by the maximum of the column to do this normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "493b8955-7ffa-44c7-ae30-4bdeed3db628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([80.0000,  8.0000,  6.0000,  6.2409,  1.0000,  1.0000,  1.0000,  1.0000,\n",
       "          1.0000,  1.0000,  1.0000,  1.0000]),\n",
       " tensor([630, 159, 678, 258,   1,   0,   1,   9,   0,   1,   5,   0]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals, indices = t_independent.max(dim=0)\n",
    "vals, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009e4b58-17de-4a44-a99f-f6dfeba5c3e0",
   "metadata": {},
   "source": [
    "You can see that we have the maximum for each column, and the index of where that value occured, lets now normalise those independant/x values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2987ef17-601e-4c7c-81bc-961625225654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2750, 0.1250, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
       "        [0.4750, 0.1250, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
       "        [0.3250, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
       "        ...,\n",
       "        [0.3000, 0.1250, 0.3333,  ..., 0.0000, 0.0000, 1.0000],\n",
       "        [0.3250, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
       "        [0.4000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_independent = t_independent / vals\n",
    "t_independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c324d612-9b82-49aa-ae91-87ce9390ba4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0911,  0.0071,  0.0000,  ...,  0.0000, -0.0000,  0.3848],\n",
       "        [ 0.1574,  0.0071,  0.0000,  ...,  0.2758, -0.0000,  0.0000],\n",
       "        [ 0.1077,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.3848],\n",
       "        ...,\n",
       "        [ 0.0994,  0.0071,  0.1547,  ...,  0.0000, -0.0000,  0.3848],\n",
       "        [ 0.1077,  0.0000,  0.0000,  ...,  0.2758, -0.0000,  0.0000],\n",
       "        [ 0.1325,  0.0000,  0.0000,  ...,  0.0000, -0.3921,  0.0000]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_independent*coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed939f99-0e36-4e2e-aa64-9d46dbdfb905",
   "metadata": {},
   "source": [
    "Awesome, everything is looking far more balanced now.\n",
    "\n",
    "The course makes a great note to highlight the vector by matrix calculations we're running here. Note that 't_independent' is a matrix and coefficients is a vector of values, even though we're simply saying multiply each other, pytorch knows to broadcast the vector over the whole matrix for the calculations. Definitely checkout lesson 3 / chapter 4 of the book to learn more about this. I've also linked some decent broadcasting documentation there as well.\n",
    "\n",
    "Ok lets now make our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6e617f9f-7b07-48dd-a675-ffe4150882e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.5373,  0.1640,  1.0401,  0.2606,  0.5841, -0.2383, -0.1610,  0.5458,\n",
       "          1.1989,  0.4553]),\n",
       " torch.Size([891]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = (t_independent*coefficients).sum(axis=1)\n",
    "preds[:10], preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464c22b9-0fef-49dc-b2c2-64aa2ae31c3c",
   "metadata": {},
   "source": [
    "### Building a Loss Function\n",
    "\n",
    "As with lesson 3, we need a way to optimise those coefficients/weights and we do that via calculating a loss and gradients which we then multiply by a learning rate to move our coefficients/weights to a more effective value. Lets do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e82a8c47-1364-4595-af17-d9c852aca9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5372)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.abs(preds-t_dep).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e26a1ea-d3d4-4387-9b41-9a35be702fbe",
   "metadata": {},
   "source": [
    "We've taken the absolute error of our predictions minus the true value and then grabbed the mean(). We're pretty close to random chance at .53 since there can only be a 0 or 1 value.\n",
    "\n",
    "Lets wrap calculating the predictions and losses in some helper functions and keep moving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fa996f05-e2d3-4a8a-858c-dd94e3c329fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_preds(coefficients, independent_variables): return (independent_variables*coefficients).sum(axis=1)\n",
    "def calculate_loss(coefficients, independent_variables, dependent_variables): return torch.abs(calculate_preds(coefficients, independent_variables)-dependent_variables).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547e56bc-0407-44c7-b2cf-c9d963a3d6fa",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "\n",
    "Here we're going to manually do gradient descent, or a single 'epoch' of training. Pytorch will automatically track our gradients for us with the 'requires_grad_()' attribute on our coefficients so we don't have to manually set them but you can handle this manually if you wish (which we did in lesson 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5efa92f5-2c36-440f-8a1c-31249526cfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3313,  0.0565,  0.4642, -0.0014,  0.1842, -0.3090, -0.4595, -0.0689,\n",
       "         0.3639,  0.2758, -0.3921,  0.3848], requires_grad=True)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1b5b9f99-4603-44de-a3cf-a2c6f9ae4335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5372, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = calculate_loss(coefficients, t_independent, t_dep)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c936594-96c5-4764-9cb3-451d52dbb578",
   "metadata": {},
   "source": [
    "loss.backward() will ask pytorch to calculate the gradients on our coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dd4b29d9-7a7e-4ef2-a0e5-505cb1a0b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "613378ed-3d5b-4803-aad7-8fb2ce512d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0012,  0.0146,  0.0075, -0.0405, -0.0898,  0.1448, -0.2334,  0.0045,\n",
       "         0.2840, -0.0718, -0.0662,  0.1930])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5722b420-a7fa-4a2b-9ee7-afdb200c981e",
   "metadata": {},
   "source": [
    "Gradients for free! So cool, Pytorch will add the gradients anytime our coefficients are involved in a function and calculate them for us, it will simply add them to the .grad attribute. Lets calculate the loss again and see them double "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "55bfc9bb-faca-4019-822b-0ed875532e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0023,  0.0292,  0.0150, -0.0810, -0.1796,  0.2896, -0.4669,  0.0090,\n",
       "         0.5679, -0.1437, -0.1324,  0.3861])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = calculate_loss(coefficients,t_independent, t_dep)\n",
    "loss.backward()\n",
    "coefficients.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c66ca6-a28c-433c-b86a-db206dae06fb",
   "metadata": {},
   "source": [
    "Perfect, lets now modify our coefficients and zero out our gradients so that they don't keep blowing up/doubling as we keep calculating. Lets also introduce our learning rate that will decide by how much to step our weights against the gradients. We're going to modify our coefficients by subtracting the gradients by the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5915db72-d91c-4d70-abec-103786367f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4774)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "loss = calculate_loss(coefficients, t_independent, t_dep)\n",
    "loss.backward()\n",
    "with torch.no_grad():\n",
    "    coefficients.sub_(coefficients.grad * learning_rate)\n",
    "    coefficients.grad.zero_()\n",
    "    print(calculate_loss(coefficients, t_independent, t_dep))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac5fd96-8282-4be0-8a29-f914672ade60",
   "metadata": {},
   "source": [
    "Our loss went down to .4774 from .5372, its working! We're heading in the right direction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa095198-2ebe-4276-8af7-eb16ceece373",
   "metadata": {},
   "source": [
    "### Training the Linear Model\n",
    "\n",
    "As we worked through in lesson 3, we need to setup a validation set in order to see how well we're performing on data that we haven't seen, but this is separate from our test set which we keep separate until the very end. We can use the fastai RandomSplitter and simply use a random split in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4cc79086-3283-4f43-90c2-a394e5ea340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.transforms import RandomSplitter\n",
    "\n",
    "train_split, validation_split = RandomSplitter(seed=26)(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "54c7722b-60f1-47be-b9a5-cf7c93500eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#713) [415,655,160,258,8,79,162,128,824,82...],\n",
       " (#178) [443,399,827,171,352,505,718,396,374,633...])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split, validation_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d8c318-849e-4e1b-ad1c-70b1688ed260",
   "metadata": {},
   "source": [
    "RandomSplitter will give us back a bunch of indices representing the splits, we simply need to index on those rows to get the equivalent datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8b5f6c91-793b-4aa1-b5f6-602ce3d5e270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713, 178)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_independent, validation_independent = t_independent[train_split], t_independent[validation_split]\n",
    "train_dependent, validation_dependent = t_dep[train_split], t_dep[validation_split]\n",
    "\n",
    "len(train_independent), len(validation_independent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef901da-0d1d-41c9-b271-323a2102d7c4",
   "metadata": {},
   "source": [
    "Lets create some functions for the three steps we just did:\n",
    "\n",
    "1. Updating our coefficients (weights)\n",
    "2. Doing a gradient descent step\n",
    "3. Initialising coefficients to random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "20b965e2-4d9f-4655-a901-b9e63229fa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coefficients(coefficients, learning_rate):\n",
    "    coefficients.sub_(coefficients.grad * learning_rate)\n",
    "    coefficients.grad.zero_()\n",
    "    \n",
    "def one_epoch(coefficients, learning_rate):\n",
    "    loss = calculate_loss(coefficients, train_independent, train_dependent)\n",
    "    loss.backward()\n",
    "    with torch.no_grad(): update_coefficients(coefficients, learning_rate)\n",
    "    print(f\"{loss:.3f}\", end=\"; \")\n",
    "    \n",
    "def initialise_coefficients(): return (torch.rand(n_coefficients)-0.5).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e3cda2-df10-4ce7-b744-e10d2f1ac4b3",
   "metadata": {},
   "source": [
    "Now we have everything to train our model over many epochs, lets build a train_model method that allows us to package all this up together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8433dfbd-b57d-484e-98f5-62a0fc0273c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs=30, learning_rate=0.01):\n",
    "    torch.manual_seed(26)\n",
    "    coefficients = initialise_coefficients()\n",
    "    for i in range(epochs): one_epoch(coefficients, learning_rate=learning_rate)\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c78e38-9e46-4062-a079-cd8948e9eea6",
   "metadata": {},
   "source": [
    "All wired together, lets fire it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "85764538-dc40-4980-886d-12bf64966e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.539; 0.497; 0.461; 0.429; 0.397; 0.367; 0.339; 0.319; 0.321; 0.317; 0.331; 0.314; 0.332; 0.310; 0.330; 0.306; 0.332; 0.301; "
     ]
    }
   ],
   "source": [
    "coefficients = train_model(18, learning_rate=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520f3001-c0ea-455f-a053-9d43e601e9ce",
   "metadata": {},
   "source": [
    "From .539 error all the way down to .301, consistent and deliberate progress, good stuff.\n",
    "\n",
    "Now considering we have a coefficient for each column, we can look at the coefficients and infer some knowledge of how each feature impacted someone's chances for survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9c010719-603f-494b-bf60-51106d70b8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': tensor(0.3461),\n",
       " 'SibSp': tensor(0.0012),\n",
       " 'Parch': tensor(0.3972),\n",
       " 'LogFare': tensor(0.1611),\n",
       " 'Sex_female': tensor(0.4428),\n",
       " 'Sex_male': tensor(-0.3775),\n",
       " 'Pclass_1': tensor(-0.0191),\n",
       " 'Pclass_2': tensor(0.0119),\n",
       " 'Pclass_3': tensor(0.0329),\n",
       " 'Embarked_C': tensor(0.3212),\n",
       " 'Embarked_Q': tensor(-0.1801),\n",
       " 'Embarked_S': tensor(0.3174)}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(independent_cols, coefficients.requires_grad_(False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c90b0e87-9dae-4097-87be-242f72027f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_coefficients(): return dict(zip(independent_cols, coefficients.requires_grad_(False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a2e9b5-8a0c-4692-ab2f-9be27d2f218c",
   "metadata": {},
   "source": [
    "How cool is that, we can see each column and the literal impact of increasing or decreasing each value on the survival of the person observed in the dataset.\n",
    "\n",
    "Lets move on to measuring accuracy since we're currently using absolute error whereas the competition actually uses accuracy.\n",
    "\n",
    "### Measuring Accuracy\n",
    "\n",
    "Lets get our predictions first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dc2d4481-c8cf-4596-a0ba-ed011d16bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = calculate_preds(coefficients, validation_independent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfc13fc-031e-44d1-a9a3-7d3b43337fb4",
   "metadata": {},
   "source": [
    "Lets make the assumption that any passenger over 0.5 is predicted to survive, any prediction over 0.5 where the individual survived is correct in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "29a44bc2-9939-489f-ba73-5658f8d13d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True, False,  True,  True,  True,  True, False, False,  True])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = validation_dependent.bool() == (preds>0.5)\n",
    "results[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d784c13c-7aec-42e0-b1cb-62815ecd95a2",
   "metadata": {},
   "source": [
    "Lets checkout the average accuracy over the whole set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9be5ae5b-d014-43b2-bab7-d4a6effc1b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7809)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78995dc-917d-4919-9f50-9b56dc6421e8",
   "metadata": {},
   "source": [
    "78% accuracy considering we have only have 12 coefficients and a linear function is kind of amazing. Lets define a nice accuracy helper function so we can re-calculate this anytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0c26d2d3-9c6c-4e1f-9519-40f3adda9bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(coefficients): return (validation_dependent.bool() == (calculate_preds(coefficients, validation_independent) > 0.5)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1d33c729-e7e6-473a-81b4-4be0dbbb04ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.3649), tensor(1.3972))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.min(), preds.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e8538c-c56b-4550-9ae9-fb3d4f1cf19f",
   "metadata": {},
   "source": [
    "We do however have the problem of both below 0 and above 1 predictions which make no sense since 0 and 1 are limits. There's a magical function call sigmoid that provides a way to smooth all our predictions between 0 and 1, lets do it!\n",
    "\n",
    "### Using Sigmoid\n",
    "\n",
    "Sigmoid lets us nicely smooth everything between 0 and 1 whilst never actually reaching either, lets have a look at the function visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9fbeacfa-fbc1-4632-b11f-fcd9a57398d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<sympy.plotting.plot.Plot at 0x18916282cb0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy\n",
    "sympy.plot(\"1/(1+exp(-x))\",xlim=(-5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76383385-164f-4790-837a-55ba5eaf1e85",
   "metadata": {},
   "source": [
    "We're using this cool library called sympy which allows us to write an expression like we did above and have it nicely plotted. Similar to the plot_function() method from fastai but a whole library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6b09a883-0282-42b1-89b8-57b33f279206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<hr/>\n",
       "<h3>sympy</h3>\n",
       "<blockquote><pre><code>sympy</code></pre></blockquote><p>SymPy is a Python library for symbolic mathematics. It aims to become a\n",
       "full-featured computer algebra system (CAS) while keeping the code as simple\n",
       "as possible in order to be comprehensible and easily extensible.  SymPy is\n",
       "written entirely in Python. It depends on mpmath, and other external libraries\n",
       "may be optionally for things like plotting support.\n",
       "\n",
       "See the webpage for more information and documentation:\n",
       "\n",
       "    https://sympy.org</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc(sympy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa50fab9-7aa9-46c1-9448-fbbd2306c734",
   "metadata": {},
   "source": [
    "Pytorch already has sigmoid out the box so we don't have to write up a custom method, it'll do the awesome math on our GPU, all parallel and quick. Lets redefine our calculate_predictions method to include this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4f9419eb-3211-495a-a166-7c887192aa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_preds(coefficients, independents): return torch.sigmoid((independents*coefficients).sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af639a4a-1d3e-44f0-a078-37c336bfa834",
   "metadata": {},
   "source": [
    "Lets retrain our model to see if our loss has improved with our sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6d2d9066-f439-4087-9dc7-a83c220b2cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.521; 0.292; 0.219; 0.217; 0.215; 0.213; 0.211; 0.210; 0.209; 0.208; 0.207; 0.206; 0.205; 0.205; 0.204; 0.204; 0.203; 0.203; 0.203; 0.203; 0.202; 0.202; 0.202; 0.202; 0.201; 0.201; 0.201; 0.201; 0.201; 0.201; "
     ]
    }
   ],
   "source": [
    "coefficients = train_model(learning_rate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb2fcc2-718a-41dc-978a-9245619b5f0f",
   "metadata": {},
   "source": [
    "By quite a margin, lets now checkout the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bc9e1187-3295-4afd-90b0-7ae816f90164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8371)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d820585f-d269-405d-b396-509619c457b2",
   "metadata": {},
   "source": [
    "~83% is certainly better for basically just smoothing out our predictions, awesome stuff. Lets checkout our coefficients again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "45b02792-7eae-4033-b1e1-2ad28782141f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': tensor(-0.1973),\n",
       " 'SibSp': tensor(-1.5336),\n",
       " 'Parch': tensor(-0.7395),\n",
       " 'LogFare': tensor(0.1039),\n",
       " 'Sex_female': tensor(5.5895),\n",
       " 'Sex_male': tensor(-6.1751),\n",
       " 'Pclass_1': tensor(1.8641),\n",
       " 'Pclass_2': tensor(1.8072),\n",
       " 'Pclass_3': tensor(-4.2965),\n",
       " 'Embarked_C': tensor(0.8785),\n",
       " 'Embarked_Q': tensor(1.7818),\n",
       " 'Embarked_S': tensor(-2.8526)}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_coefficients()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048f4eac-cc67-4f2b-845d-02c9e79ba198",
   "metadata": {},
   "source": [
    "### Moving to Matrix Products\n",
    "\n",
    "We've been doing vector to matrix calculations, where we have to sum all the rows over axis '1' to get our results, we can instead run a matrix multiplication on the vector by matrix and it will broadcast the vector over the entire matrix to achieve the same thing. We simply need to change our '*' operator to a '@' operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f3da61c9-7346-48c8-9c69-71197c3c976b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  4.5189,   4.5185,  -3.6778,  -9.5330,  -9.9099,  -3.5904,  -8.7023,\n",
       "          -1.5997,  -2.2138,  -7.2228, -13.3593,   4.5212,  -7.3525,  -7.6108,\n",
       "           2.8706, -13.3393,  -7.4905,  -7.2564,  -7.2358,  -3.4341,  -3.6701,\n",
       "          -8.9045, -13.3738, -14.1698, -13.3469,  -7.1682,  -1.5776,  -9.9207,\n",
       "           4.4992, -13.3319,   8.2373, -13.6142,   4.5131,  -1.5741,  -7.2383,\n",
       "          -9.6171,  -3.4187,  -9.5704,   4.3943,   8.1180, -13.5418,   4.2315,\n",
       "         -13.3382,  -7.2183, -13.3312,   3.0646, -13.5579,  -3.7432,  -7.4114,\n",
       "          -3.4149,  -7.3426, -13.4416,   3.8130,   8.1548,   4.3626,  -7.2589,\n",
       "          -7.2604,  -2.2993,  -9.6171,  -7.3642, -13.3372,  -7.2307, -13.3713,\n",
       "           7.7432, -13.3467,  -7.2588,  -7.2451,   3.0518, -13.3274, -13.3445,\n",
       "          -2.2153, -13.3678,  -3.5231,  -7.2613,   4.3899,   4.5091,  -9.5281,\n",
       "          -8.6952, -13.3456, -13.3467,  -9.6155,  -1.7632,  -7.6220,  -8.8870,\n",
       "           4.6027,  -7.2358,  -1.8948,   3.0644, -13.3368, -14.1871,  -7.2563,\n",
       "         -13.3427,   4.3357,  -8.7128,   2.0829,  -7.2573,  -7.2267,   4.0337,\n",
       "          -1.7061, -13.3482,   3.0515,   8.3257,  -2.0726,  -7.3926, -13.3801,\n",
       "          -7.2551,  -9.6171, -13.7635,  -7.2440,  -7.2228,   1.9885,  -7.1567,\n",
       "           2.1475, -13.3469,  -9.6366, -13.5437,   4.2840,   4.2790,  -9.6171,\n",
       "           1.9000,  -1.5643, -13.3472, -13.3422,   8.0966,  -9.6798, -13.3469,\n",
       "           4.3631,   4.1848,  -1.8365,  -2.2626,   1.9663,   4.0889, -13.3370,\n",
       "          -7.3029,  -7.3475,  -7.4190,  -7.2530, -13.3516, -13.3348,   4.3369,\n",
       "           4.3562, -13.3694,  -8.7128,   4.4293,  -7.1629,  -9.0793,  -1.8108,\n",
       "          -8.7535,   8.3459,  -2.1523,  -1.5922, -13.3486,  -3.6424, -13.3469,\n",
       "          -8.7301,  -9.9836, -13.4345,  -2.4034, -13.3442,  -8.8275, -13.3395,\n",
       "          -7.3657, -13.3831,  -3.7040,  -1.6115,  -7.9393,   3.0745,   4.6304,\n",
       "           4.5329, -13.3469, -14.4919,   3.0715,   1.9871,  -1.8999,   9.1624,\n",
       "         -13.4049,   4.3804,   9.1476]),\n",
       " tensor(-915.6960))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(validation_independent*coefficients).sum(axis=1), ((validation_independent*coefficients).sum(axis=1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "972a6980-99e0-4bf8-920b-f26e39302504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  4.5189,   4.5185,  -3.6778,  -9.5330,  -9.9099,  -3.5904,  -8.7023,\n",
       "          -1.5997,  -2.2138,  -7.2228, -13.3593,   4.5212,  -7.3525,  -7.6108,\n",
       "           2.8706, -13.3393,  -7.4905,  -7.2564,  -7.2358,  -3.4341,  -3.6701,\n",
       "          -8.9045, -13.3738, -14.1698, -13.3469,  -7.1682,  -1.5776,  -9.9207,\n",
       "           4.4992, -13.3319,   8.2373, -13.6142,   4.5131,  -1.5741,  -7.2383,\n",
       "          -9.6171,  -3.4187,  -9.5704,   4.3943,   8.1180, -13.5418,   4.2315,\n",
       "         -13.3382,  -7.2183, -13.3312,   3.0646, -13.5579,  -3.7432,  -7.4114,\n",
       "          -3.4149,  -7.3426, -13.4416,   3.8130,   8.1548,   4.3626,  -7.2589,\n",
       "          -7.2604,  -2.2993,  -9.6171,  -7.3642, -13.3372,  -7.2307, -13.3713,\n",
       "           7.7432, -13.3467,  -7.2588,  -7.2451,   3.0518, -13.3274, -13.3445,\n",
       "          -2.2153, -13.3678,  -3.5231,  -7.2613,   4.3899,   4.5091,  -9.5281,\n",
       "          -8.6952, -13.3456, -13.3467,  -9.6155,  -1.7632,  -7.6220,  -8.8870,\n",
       "           4.6027,  -7.2358,  -1.8948,   3.0644, -13.3368, -14.1871,  -7.2563,\n",
       "         -13.3427,   4.3357,  -8.7128,   2.0829,  -7.2573,  -7.2267,   4.0337,\n",
       "          -1.7061, -13.3482,   3.0515,   8.3257,  -2.0726,  -7.3926, -13.3801,\n",
       "          -7.2551,  -9.6171, -13.7635,  -7.2440,  -7.2228,   1.9885,  -7.1567,\n",
       "           2.1475, -13.3469,  -9.6366, -13.5437,   4.2840,   4.2790,  -9.6171,\n",
       "           1.9000,  -1.5643, -13.3472, -13.3422,   8.0966,  -9.6798, -13.3469,\n",
       "           4.3631,   4.1848,  -1.8365,  -2.2626,   1.9663,   4.0889, -13.3370,\n",
       "          -7.3029,  -7.3475,  -7.4190,  -7.2530, -13.3516, -13.3348,   4.3369,\n",
       "           4.3562, -13.3694,  -8.7128,   4.4293,  -7.1629,  -9.0793,  -1.8108,\n",
       "          -8.7535,   8.3459,  -2.1523,  -1.5922, -13.3486,  -3.6424, -13.3469,\n",
       "          -8.7301,  -9.9836, -13.4345,  -2.4034, -13.3442,  -8.8275, -13.3395,\n",
       "          -7.3657, -13.3831,  -3.7040,  -1.6115,  -7.9393,   3.0745,   4.6304,\n",
       "           4.5329, -13.3469, -14.4919,   3.0715,   1.9871,  -1.8999,   9.1624,\n",
       "         -13.4049,   4.3804,   9.1476]),\n",
       " tensor(-915.6960))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_independent@coefficients, (validation_independent@coefficients).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b22497-3251-4768-96c3-513405025afe",
   "metadata": {},
   "source": [
    "We produce the identical tensor and total but this is more efficient since we're able to run these calculations in parallel on the GPU, lets modify our calculate_preds() again to reflect this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2064c079-6017-4f81-92b2-3e7815f579ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_preds(coefficients, independents): return torch.sigmoid(independents@coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427fa2aa-0f0a-429d-8f66-d919bb51f01b",
   "metadata": {},
   "source": [
    "The only other thing we need to do is convert our vector to a matrix with a single column and 'transpose' it so that its a matrix by matrix calculation instead of a matrix by vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "abcc37f3-8923-4cb7-a33b-52f9e60e43c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_coefficients(): return (torch.randn(n_coefficients, 1)*0.1).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "35a85db6-a709-4036-a61a-64cd780c3b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0634],\n",
       "        [-0.0220],\n",
       "        [-0.0140],\n",
       "        [-0.0766],\n",
       "        [ 0.0887],\n",
       "        [ 0.0815],\n",
       "        [ 0.0809],\n",
       "        [ 0.0619],\n",
       "        [-0.0255],\n",
       "        [ 0.0457],\n",
       "        [ 0.0780],\n",
       "        [ 0.0032]], requires_grad=True)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialise_coefficients()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d79f2f4-a7cb-4e0c-a622-f1e4f2cfce66",
   "metadata": {},
   "source": [
    "See how we now have a single column matrix instead of the previous vector, we'll have to transform the same for our dependent sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "707dff12-cd71-4f91-80f7-9b83635e1111",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dependent = train_dependent[:,None]\n",
    "validation_dependent = validation_dependent[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "20fecc46-2eeb-4b57-bb47-061e47b2ef69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.483; 0.305; 0.222; 0.212; 0.210; 0.209; 0.208; 0.207; 0.206; 0.205; 0.205; 0.204; 0.204; 0.203; 0.203; 0.203; 0.202; 0.202; 0.202; 0.202; 0.201; 0.201; 0.201; 0.201; 0.201; 0.201; 0.200; 0.200; 0.200; 0.200; "
     ]
    }
   ],
   "source": [
    "coefficients = train_model(learning_rate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bff299e9-594c-4edf-aa57-e81b041bba71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8371)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94be9fb8-61f2-46dd-9fae-53681e95775d",
   "metadata": {},
   "source": [
    "And we have the same model and output, awesome. Lets now move to making a neural net as we have all the pieces and tools we need to do so\n",
    "\n",
    "### Neural Networks\n",
    "\n",
    "We will need a few things:\n",
    "\n",
    " - Coefficients (weights/parameters) for each of our layers\n",
    " - A number of 'hidden' layers of various sizes (model architecture)\n",
    " - A final output layer (prediction output / model head)\n",
    " \n",
    "We will control a few of these parameters by creating variables we set such as n_hidden, n_coefficients etc, lets get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a067ef19-9730-4d06-b673-700dfcb352f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_coefficients(n_hidden=20):\n",
    "    layer1 = (torch.rand(n_coefficients, n_hidden)-0.5)/n_hidden\n",
    "    layer2 = torch.rand(n_hidden, 1)-0.3\n",
    "    const = torch.rand(1)[0]\n",
    "    return layer1.requires_grad_(), layer2.requires_grad_(), const.requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb58d39-349f-473b-8e2d-ad603110db58",
   "metadata": {},
   "source": [
    "Ok so we have our coefficients for each of our layers, we have a constant bias term, we can now make our neural network by handcrafting our layers and adding our non-linearities in between them before finally passing to sigmoid for our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d546cdf5-4be4-45a0-b583-4db78b230b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_preds(coefficients, independents):\n",
    "    l1, l2, const = coefficients\n",
    "    res = F.relu(independents@l1)\n",
    "    res = res@l2 + const\n",
    "    return torch.sigmoid(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16f2dea-0336-4a85-af75-302aa8c4a248",
   "metadata": {},
   "source": [
    "Ok see here how we're grabbing our layers, multiplying the independents by the first layer, multiplying that result by a relu activation (non-linearity is introduced here) and then finally multiplying by our final layer and adding our constant term. We then have our output which we can sigmoid to get our final prediction.\n",
    "\n",
    "We also need to write our method to update the coefficients by calculating the gradients for each layer, subtracting them by the learning rate and zeroing out the gradients to be calculated in the next batch/epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e4c4fe1b-ac65-4f2b-bad3-a258210439d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coefficients(coefficients, learning_rate):\n",
    "    for layer in coefficients:\n",
    "        layer.sub_(layer.grad * learning_rate)\n",
    "        layer.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ee6277-31bb-4bee-86eb-3164daadb5f2",
   "metadata": {},
   "source": [
    "We've got everything together, lets quickly checkout our layers, remembering there's a relu inbetween the layers and we have our final constant term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ffb0c336-72db-47fe-8d41-bd987cda108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1, layer2, const = initialise_coefficients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c3e443fa-ce46-43cd-b363-2bf7677299a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 20]), torch.Size([20, 1]), tensor(0.8732, requires_grad=True))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.shape, layer2.shape, const"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b81498-9d02-45e5-903d-90e8cdd5f638",
   "metadata": {},
   "source": [
    "Layer one takes in our 12 'x' values as the independent variables, outputs a shape of 20 which our next layer takes in and then condenses to 1 output which we sigmoid for our prediction. Hopefully these shapes make sense, and that bigger architectures are just more complicated connections between these matrices of different sizes and shapes which are suited better to particular problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a85d00-da40-4915-b9e3-be31db829b1e",
   "metadata": {},
   "source": [
    "Ok lets train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8a41114c-4483-477b-8ec9-76f3616dd79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.525; 0.503; 0.485; 0.465; 0.440; 0.412; 0.382; 0.352; 0.325; 0.304; 0.287; 0.275; 0.265; 0.257; 0.250; 0.245; 0.241; 0.238; 0.235; 0.233; 0.231; 0.229; 0.227; 0.226; 0.225; 0.223; 0.222; 0.221; 0.220; 0.219; "
     ]
    }
   ],
   "source": [
    "coefficients = train_model(learning_rate=1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ed687995-4650-468c-ac35-773ec2415ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.525; 0.372; 0.249; 0.314; 0.220; 0.202; 0.200; 0.199; 0.198; 0.198; 0.197; 0.196; 0.196; 0.196; 0.196; 0.196; 0.196; 0.196; 0.196; 0.196; 0.196; 0.196; 0.196; 0.196; 0.196; 0.195; 0.195; 0.195; 0.195; 0.195; "
     ]
    }
   ],
   "source": [
    "coefficients = train_model(learning_rate=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "349abdc2-c572-43bc-bb98-5b2e3a50397b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8371)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec3e992-529d-4bd8-99c1-c7772ffc152d",
   "metadata": {},
   "source": [
    "Well our loss is definitely better at 0.195 but our accuracy is still the same which is interesting, whilst we haven't blown away our linear model, its really cool to see how only a couple of layers of matrices can give effective results.\n",
    "\n",
    "### Making the Neural Net 'Deep'\n",
    "\n",
    "Now whilst the universal approximation paper says that two layers is all you need to approximate any function in the universe (a terrible paraphrase of what the paper says), its not very practical in the real world. It also isn't very 'deep' since we only have two layers, by building more layers, we make our network 'deep', hence the name. Again we need to connect layer to layer with activations in between, lets do it.\n",
    "\n",
    "Note that the sizes variables is our 'crude' model architecture, simply the structure of all the hidden layers (the model body) and the final output layer which spits out predictions is the (model head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "2930735d-6e0a-4a48-859d-b86f6e3a0081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_coefficients():\n",
    "    hiddens=[12,5,12,5]\n",
    "    sizes = [n_coefficients] + hiddens + [1]\n",
    "    n =  len(sizes)\n",
    "    layers = [(torch.rand(sizes[i], sizes[i+1])-0.3)/sizes[i+1]*4 for i in range(n-1)]\n",
    "    consts = [(torch.rand(1)[0]-0.5)*0.1 for i in range(n-1)]\n",
    "    for l in layers+consts: l.requires_grad_()\n",
    "    return layers, consts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0332cb50-3129-49dc-a316-67b365b36dcc",
   "metadata": {},
   "source": [
    "As Jeremy notes in the course, there are lots of fiddly constants here, the initialisation of weights has drastic impacts on the training progress of your model, there are ways to address this which we'll work on later through the course but its important to note these aren't accidental and are part of the difficult nature of this type of model.\n",
    "\n",
    "We'll also re-define our calculate predictions method and loop through each layer instead of explicitly calling them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "7cdc48f3-43b0-4461-aed1-9cec7441776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_preds(coefficients, independents):\n",
    "    layers, consts = coefficients\n",
    "    n = len(layers)\n",
    "    res = independents\n",
    "    for iteration, layer in enumerate(layers):\n",
    "        res = res@layer + consts[iteration]\n",
    "        if iteration!=n-1: res = F.relu(res)\n",
    "    return torch.sigmoid(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c360c4be-4e2e-4143-880e-1414d6fa41d9",
   "metadata": {},
   "source": [
    "Check it out, the line **res = res@layer + consts[i]** is our $prediction = weights * inputs + bias$ or $y = mx + b$ equation from lesson 3. Still blows my mind that these simple equations can be built up into such flexible models that are truly effective at solving problems.\n",
    "\n",
    "We also need to update our coefficients updating method since we've got many layers and constants rather than explicit setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "4eca5386-4da6-4c4f-bdc2-4433af72512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coefficients(coefficients, learning_rate):\n",
    "    layers, consts = coefficients\n",
    "    for layer in layers+consts:\n",
    "        layer.sub_(layer.grad*learning_rate)\n",
    "        layer.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b6f9a2-8b87-4992-994b-acb3bfc442ca",
   "metadata": {},
   "source": [
    "And back to training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "553a7deb-3b47-4a46-ada5-36974d6e2076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.566; 0.476; 0.443; 0.423; 0.412; 0.406; 0.402; 0.399; 0.397; 0.395; 0.394; 0.393; 0.392; 0.391; 0.391; 0.390; 0.390; 0.390; 0.389; 0.389; 0.389; 0.389; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.387; 0.387; "
     ]
    }
   ],
   "source": [
    "coefficients = train_model(learning_rate=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "b8c000ec-c217-40cb-bc1b-95d889e7ea2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6180)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f16814-3b5a-4ae3-9c68-414c8c048ad1",
   "metadata": {},
   "source": [
    "Ok maybe this model architecture wasn't as great as our two layers but its still cool to see how we can 'artisinally' create our layers and whats happening within each layer. This was a really interesting 'double up' on lesson 3 which covers the same chapter 4 of the book. I'm feeling very confident in the raw mechanices of how these models function which is fantastic. On to lesson 6 and thanks for reading if you're here with me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2646457e-0cce-4b28-a157-7978ff7a4d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
