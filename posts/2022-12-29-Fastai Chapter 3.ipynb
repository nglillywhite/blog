{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6cee887a",
   "metadata": {},
   "source": [
    "---\n",
    "aliases:\n",
    "- /ML/fastai/jupyter/2022/12/26/Fastai Chapter 3\n",
    "badges: true\n",
    "categories:\n",
    "- jupyter\n",
    "- fastai\n",
    "- ML\n",
    "date: '2022-12-29'\n",
    "description: ReLu, Matrix Multiplication, Tensors, Gradient Descent\n",
    "output-file: 2022-12-29-fastai chapter 3.html\n",
    "title: Fastai Chapter 3 | Neural Net Foundations\n",
    "author: Nicholas Lillywhite\n",
    "draft: true\n",
    "toc: true\n",
    "image: \"images/shark.jpg\"\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60018f19-1234-438b-ba12-777cd35ca633",
   "metadata": {},
   "source": [
    "# Chapter 3 | Neural Nets Foundations\n",
    "> If You are Feeling Intimidated Like Me, Lets Work Through This Together\n",
    "\n",
    ">Checkout this notebook in [colab](https://colab.research.google.com/github/nglillywhite/blog/blob/main/posts/2022-12-29-Fastai%20Chapter%203.ipynb)\n",
    "\n",
    "This chapter focuses on understanding the absolute bare bones fundamentals of how deep learning works. In particular the individual calculations that are being done at each and every 'artificial neuron' of any deep learning network that we build. I'm certainly not from a math background and am generally intimidated but intrigued by learning math like this. I think I have shaky foundational math understanding but I'm hoping working through this course in great detail will bolster these core concepts and I can build on them. Despite my enjoyment of math in school, I did only the general curriculum in my final two years because the math teachers in my school were able to induce a coma purely via the audio of their voice. I have no doubt they were well intentioned people but many were phoning in the days and I wasn't willing to spend half of my school day with them. I'm paying the price for it now having to re-learn these concepts but maybe its for the best, if they'd explained that $y=mx+b$, derivatives, and quadratics could detect cancers and make self driving cars I probably would have been a more passionate student. I feel very much a product of the \"[Mathematician's Lament](https://www.maa.org/external_archive/devlin/LockhartsLament.pdf)\" that is referenced in chapter 1 of the book. Its a lovely read and I took many lessons away from the write-up, not only in how I want to teach things going forward but also a strong emotional response to how something as incredible as math is ruined and tarnished because of how its taught. Think of where we could be, but nonetheless this blog is about chapter 3 of the fastai course, not math education.\n",
    "\n",
    "Nonetheless here I am, and in the spirit of the \"Sidebar: Tenacity and Deep Learning\" from the book, I'm hoping that writing this blog and working through the content is a explicit evidence of success for me being both tenacious, and re-learning my math roots.\n",
    "\n",
    "## Main Topics\n",
    "\n",
    "The main concepts I want to have a 'mechanistic' & intuitive feeling for after this chapter are:\n",
    "\n",
    " - ReLu\n",
    " - Matrix Multiplication\n",
    " - Tensors\n",
    " - Gradient Descent\n",
    " \n",
    "Hopefully after reading this blog you also feel comfortable with these important tools and feel as comfortable as I intend to be implementing and discussing these core concepts.\n",
    "\n",
    "As mentioned in the lecture, this chapter has different content in the book from the lecture and I'd like to work through both, I'm firstly going to follow along the lecture with Jeremy and re-write & create the functions and tools he builds, barring the excel work which I'd like to re-write in python here, I will then work through the book content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59603e6f-a0d3-492e-93d6-cccecd43c64d",
   "metadata": {},
   "source": [
    "## Lecture Content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c83957-84d2-4bee-8fcb-9f36170045c1",
   "metadata": {},
   "source": [
    "### Timm Module\n",
    "\n",
    "Jeremy first talks through improving his pet classifier from the previous lesson, in particular having a look at different architectures and using the 'timm' library for vision model architectures. Lets have a look at the timm module and whats available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3b9216d-5f42-433d-85a7-000cdb67dfa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(964,\n",
       " ['adv_inception_v3',\n",
       "  'bat_resnext26ts',\n",
       "  'beit_base_patch16_224',\n",
       "  'beit_base_patch16_224_in22k',\n",
       "  'beit_base_patch16_384',\n",
       "  'beit_large_patch16_224',\n",
       "  'beit_large_patch16_224_in22k',\n",
       "  'beit_large_patch16_384',\n",
       "  'beit_large_patch16_512',\n",
       "  'beitv2_base_patch16_224',\n",
       "  'beitv2_base_patch16_224_in22k',\n",
       "  'beitv2_large_patch16_224',\n",
       "  'beitv2_large_patch16_224_in22k',\n",
       "  'botnet26t_256',\n",
       "  'botnet50ts_256',\n",
       "  'cait_m36_384',\n",
       "  'cait_m48_448',\n",
       "  'cait_s24_224',\n",
       "  'cait_s24_384',\n",
       "  'cait_s36_384'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "len(timm.list_models()), timm.list_models()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288369e7-1949-4d27-b2ac-ba12218f51a5",
   "metadata": {},
   "source": [
    "There are a lot of models, almost ~1000 which is kind of nuts, looks like its certainly beefed up by different sizes of what I think is the same architecture structure, lets get a model down and have a look at the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "835d3747-98c4-4cc2-96d4-5e4f9b109a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18 = timm.models.resnet18()\n",
    "resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fd81dc-860b-4cd5-b632-ef471256a6ec",
   "metadata": {},
   "source": [
    "Ok so I've brought down a 'tiny' model (in the scheme of todays models which have millions of parameters) called resnet16 which I used on my shark classifier in chapter 2 and the resnet architecture is what Jeremy references in the lecture.\n",
    "\n",
    "It looks like there are many 'Sequential' layers with 'BasicBlocks' inside them which then have a bunch of individual 'submodules' if we copy the language from the model.get_submodule() API which we're about to use. Lets now have a look at a particular submodule. The get_submodule() method allows us to step down the 'tree' and 'branches' of the layers with a dot notation. We shall step all the way down to a leaf, take particular note of the branch names contained within the smooth brackets '()'. First we go via the \"Layer1\" layer, into the first BasicBlock which has the notation of '(O)', I'm guessing because the layer is an array of BasicBlocks, the first index being 0, then I'm going to pick the BatchNorm2d submodule which has the notation of '(bn1)' within the brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ee929c-900c-49f3-bef6-78cc529ec284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = resnet18.get_submodule(\"layer1.0.bn1\")\n",
    "list(layer.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194d1d9f-2d3a-4965-929c-ff5c9bb5cc5c",
   "metadata": {},
   "source": [
    "OK so we've got a couple of tensors, one set to all ones and another set to all zeroes, lets have a look at the doc to see if there's any hints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aed2fe06-c1b4-43f5-8b38-7cbc31acc206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mBatchNorm2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnum_features\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0meps\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-05\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmomentum\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0maffine\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtrack_running_stats\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs\n",
       "with additional channel dimension) as described in the paper\n",
       "`Batch Normalization: Accelerating Deep Network Training by Reducing\n",
       "Internal Covariate Shift <https://arxiv.org/abs/1502.03167>`__ .\n",
       "\n",
       ".. math::\n",
       "\n",
       "    y = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\n",
       "\n",
       "The mean and standard-deviation are calculated per-dimension over\n",
       "the mini-batches and :math:`\\gamma` and :math:`\\beta` are learnable parameter vectors\n",
       "of size `C` (where `C` is the input size). By default, the elements of :math:`\\gamma` are set\n",
       "to 1 and the elements of :math:`\\beta` are set to 0. The standard-deviation is calculated\n",
       "via the biased estimator, equivalent to `torch.var(input, unbiased=False)`.\n",
       "\n",
       "Also by default, during training this layer keeps running estimates of its\n",
       "computed mean and variance, which are then used for normalization during\n",
       "evaluation. The running estimates are kept with a default :attr:`momentum`\n",
       "of 0.1.\n",
       "\n",
       "If :attr:`track_running_stats` is set to ``False``, this layer then does not\n",
       "keep running estimates, and batch statistics are instead used during\n",
       "evaluation time as well.\n",
       "\n",
       ".. note::\n",
       "    This :attr:`momentum` argument is different from one used in optimizer\n",
       "    classes and the conventional notion of momentum. Mathematically, the\n",
       "    update rule for running statistics here is\n",
       "    :math:`\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momentum} \\times x_t`,\n",
       "    where :math:`\\hat{x}` is the estimated statistic and :math:`x_t` is the\n",
       "    new observed value.\n",
       "\n",
       "Because the Batch Normalization is done over the `C` dimension, computing statistics\n",
       "on `(N, H, W)` slices, it's common terminology to call this Spatial Batch Normalization.\n",
       "\n",
       "Args:\n",
       "    num_features: :math:`C` from an expected input of size\n",
       "        :math:`(N, C, H, W)`\n",
       "    eps: a value added to the denominator for numerical stability.\n",
       "        Default: 1e-5\n",
       "    momentum: the value used for the running_mean and running_var\n",
       "        computation. Can be set to ``None`` for cumulative moving average\n",
       "        (i.e. simple average). Default: 0.1\n",
       "    affine: a boolean value that when set to ``True``, this module has\n",
       "        learnable affine parameters. Default: ``True``\n",
       "    track_running_stats: a boolean value that when set to ``True``, this\n",
       "        module tracks the running mean and variance, and when set to ``False``,\n",
       "        this module does not track such statistics, and initializes statistics\n",
       "        buffers :attr:`running_mean` and :attr:`running_var` as ``None``.\n",
       "        When these buffers are ``None``, this module always uses batch statistics.\n",
       "        in both training and eval modes. Default: ``True``\n",
       "\n",
       "Shape:\n",
       "    - Input: :math:`(N, C, H, W)`\n",
       "    - Output: :math:`(N, C, H, W)` (same shape as input)\n",
       "\n",
       "Examples::\n",
       "\n",
       "    >>> # With Learnable Parameters\n",
       "    >>> m = nn.BatchNorm2d(100)\n",
       "    >>> # Without Learnable Parameters\n",
       "    >>> m = nn.BatchNorm2d(100, affine=False)\n",
       "    >>> input = torch.randn(20, 100, 35, 45)\n",
       "    >>> output = m(input)\n",
       "\u001b[1;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\nick\\anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     BatchNormAct2d, SplitBatchNorm2d\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.nn import BatchNorm2d\n",
    "\n",
    "BatchNorm2d?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b99a37f-01d6-4c2e-aa7c-d9c232e33670",
   "metadata": {},
   "source": [
    "Ok deadset I'm not sure what a lot, if not all of this means, but there's a nice link to the paper that proposed this submodule. Maybe I'll revisit this later or what I'm guessing is that we will discuss batch normalisation as part of the course. Nonetheless, credit due to the pytorch team for awesome docs and references. I'm certainly feeling comfortable picking apart a model and submodules to then research or understand the peices. And to Jeremy's point, it looks like each module is just tensors which I'm assuming get matrix multiplied.\n",
    "\n",
    "Lets have a look at another one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85871cda-3f6d-4bf6-86c6-0fff6f7c0b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[-0.1708, -0.0008,  0.0283],\n",
       "           [ 0.0404, -0.0414,  0.0004],\n",
       "           [-0.0582,  0.0575,  0.0221]],\n",
       " \n",
       "          [[ 0.0625, -0.0453, -0.0501],\n",
       "           [ 0.0574, -0.0478,  0.0110],\n",
       "           [-0.0031, -0.0606,  0.0476]],\n",
       " \n",
       "          [[-0.0282, -0.0254,  0.0456],\n",
       "           [ 0.1134, -0.1320,  0.0408],\n",
       "           [-0.0691, -0.0602,  0.0513]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0202, -0.0382, -0.0890],\n",
       "           [ 0.0555,  0.0035, -0.0764],\n",
       "           [-0.0448,  0.0637, -0.0027]],\n",
       " \n",
       "          [[-0.0301, -0.0475, -0.0891],\n",
       "           [-0.0582, -0.0620, -0.0160],\n",
       "           [ 0.0097,  0.0429, -0.0588]],\n",
       " \n",
       "          [[-0.1014,  0.0125, -0.0374],\n",
       "           [ 0.0455,  0.0338,  0.0002],\n",
       "           [-0.0432, -0.0051, -0.0248]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0417, -0.0425, -0.0326],\n",
       "           [-0.0089, -0.0420, -0.0853],\n",
       "           [-0.0394, -0.0970, -0.0747]],\n",
       " \n",
       "          [[ 0.0112,  0.0069, -0.0039],\n",
       "           [-0.0214, -0.0187, -0.0827],\n",
       "           [-0.0781, -0.0208,  0.0359]],\n",
       " \n",
       "          [[ 0.0689,  0.0129,  0.0185],\n",
       "           [ 0.0721,  0.0241,  0.0292],\n",
       "           [ 0.0155,  0.0769,  0.0311]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0188, -0.0575,  0.0516],\n",
       "           [ 0.0724, -0.0890,  0.0791],\n",
       "           [ 0.0572, -0.1107, -0.0922]],\n",
       " \n",
       "          [[ 0.0727,  0.1694, -0.0277],\n",
       "           [ 0.1195, -0.0304, -0.0985],\n",
       "           [-0.0701,  0.0545,  0.0616]],\n",
       " \n",
       "          [[ 0.0438, -0.0230, -0.0073],\n",
       "           [ 0.0115, -0.0022,  0.0713],\n",
       "           [-0.0340, -0.0145, -0.0772]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0652,  0.0245,  0.0267],\n",
       "           [-0.0443,  0.0372, -0.0279],\n",
       "           [ 0.0063, -0.0324, -0.0012]],\n",
       " \n",
       "          [[-0.0050, -0.1213, -0.0122],\n",
       "           [ 0.0700,  0.0524, -0.0447],\n",
       "           [-0.0122, -0.0237,  0.0698]],\n",
       " \n",
       "          [[ 0.0884, -0.0317, -0.0079],\n",
       "           [ 0.0495, -0.1041, -0.0545],\n",
       "           [-0.0719,  0.0075, -0.0378]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0690, -0.0273, -0.0637],\n",
       "           [-0.0728, -0.0545, -0.0121],\n",
       "           [ 0.0023, -0.0022,  0.0468]],\n",
       " \n",
       "          [[ 0.0066,  0.0419,  0.0615],\n",
       "           [ 0.0044,  0.0573,  0.0197],\n",
       "           [-0.0264, -0.1143, -0.0521]],\n",
       " \n",
       "          [[ 0.0254,  0.0286,  0.0720],\n",
       "           [-0.0133,  0.0253,  0.0596],\n",
       "           [ 0.0399, -0.0278, -0.0306]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0581,  0.0442,  0.0279],\n",
       "           [-0.0310, -0.0229, -0.0231],\n",
       "           [ 0.0409, -0.0507,  0.0483]],\n",
       " \n",
       "          [[ 0.0646,  0.0647,  0.0178],\n",
       "           [ 0.0226,  0.0695,  0.0022],\n",
       "           [ 0.0326,  0.0064, -0.0377]],\n",
       " \n",
       "          [[ 0.0989, -0.0013,  0.0477],\n",
       "           [ 0.0953, -0.0774, -0.0227],\n",
       "           [ 0.0117,  0.0316,  0.0031]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0123, -0.0435,  0.0406],\n",
       "           [ 0.0118, -0.0544, -0.1162],\n",
       "           [ 0.0171, -0.0611, -0.0534]],\n",
       " \n",
       "          [[ 0.1073, -0.0412, -0.0227],\n",
       "           [ 0.0085,  0.0252, -0.0248],\n",
       "           [ 0.0456, -0.0725,  0.0739]],\n",
       " \n",
       "          [[-0.0464, -0.0286,  0.0573],\n",
       "           [-0.0572, -0.1016, -0.0295],\n",
       "           [ 0.0325, -0.0745,  0.0240]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0471, -0.0457,  0.0659],\n",
       "           [ 0.0070,  0.0052, -0.0399],\n",
       "           [-0.0279, -0.0290,  0.0649]],\n",
       " \n",
       "          [[-0.0136, -0.0168, -0.0601],\n",
       "           [-0.0239,  0.0988,  0.0027],\n",
       "           [ 0.0466,  0.0765, -0.0345]],\n",
       " \n",
       "          [[-0.0289,  0.0530,  0.0121],\n",
       "           [ 0.0161, -0.0301, -0.0096],\n",
       "           [ 0.0130, -0.0366,  0.0348]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0406,  0.1105,  0.0933],\n",
       "           [ 0.0727, -0.0109,  0.0132],\n",
       "           [-0.0242,  0.0572, -0.0248]],\n",
       " \n",
       "          [[ 0.0936, -0.0235,  0.0355],\n",
       "           [-0.0265, -0.1317, -0.0026],\n",
       "           [-0.0317,  0.0232,  0.0543]],\n",
       " \n",
       "          [[ 0.0115,  0.0452, -0.0261],\n",
       "           [-0.0191, -0.0126, -0.0341],\n",
       "           [ 0.0698,  0.0234,  0.0748]]],\n",
       " \n",
       " \n",
       "         [[[-0.0470,  0.0225, -0.0626],\n",
       "           [ 0.1119, -0.0407,  0.0687],\n",
       "           [-0.1261, -0.0341,  0.0531]],\n",
       " \n",
       "          [[ 0.0302,  0.0131,  0.0365],\n",
       "           [ 0.0466,  0.0757, -0.0115],\n",
       "           [-0.0861, -0.0048,  0.1317]],\n",
       " \n",
       "          [[-0.1384,  0.0171, -0.0450],\n",
       "           [ 0.0192, -0.0143, -0.0467],\n",
       "           [ 0.0729,  0.0098, -0.0715]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.1310,  0.0443, -0.0072],\n",
       "           [ 0.0362,  0.0047, -0.0409],\n",
       "           [ 0.0991, -0.0405, -0.0100]],\n",
       " \n",
       "          [[-0.0769, -0.0091,  0.1166],\n",
       "           [-0.0998, -0.0135, -0.0102],\n",
       "           [-0.0284, -0.0630,  0.0137]],\n",
       " \n",
       "          [[-0.0143, -0.0146,  0.1312],\n",
       "           [-0.0391, -0.0225,  0.0209],\n",
       "           [ 0.0646, -0.0575, -0.0710]]]], requires_grad=True)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = resnet18.get_submodule(\"layer1.0.conv2\")\n",
    "list(layer.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b2cde-105a-49b5-9ed2-f4a58f4d7ecb",
   "metadata": {},
   "source": [
    "Ok lets stop that, this thing is big. But nonetheless its interesting to see the different shapes and values, the batch norm module had zeroes and ones, this one seems to have all sorts of values and the shape is very different.\n",
    "\n",
    "As Jeremy mentions, apparently these numbers can figure out if a dog is a basset hound or not, or in our previous example, a great white shark or a hammerhead. However this isn't clear at this time. Again as Jeremy mentions, machine learning is the act of fitting a function to data, lets investigate this further.\n",
    "\n",
    "### How Do We Fit a Function to Data\n",
    "\n",
    "Lets first build a general quadratic equation and plot it. I don't actually have an intuitive feeling for what makes this a 'quadratic' but again in the spirit of 80% do and 20% study, I'm going to soldier on to see the 'ball game' played out and circle back later to solidfy my theory as part of the 20% reading principle outlined in Radek's Metalearning book which I love. Note to Radek, I'm trusting you that this is a good plan, its working so far but as a product of school doing the opposite, I feel very conflicted moving on without actually 'knowing'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee1d47de-4628-462b-bbed-c9dcbfd54c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastbook import plot_function\n",
    "\n",
    "def f(x): return 3*x**2 + 2*x + 1\n",
    "\n",
    "plot_function(f, title=\"$3x^2 + 2x + 1$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca64f01-50d4-4e99-8655-bd51df571d2d",
   "metadata": {},
   "source": [
    "This f(x) function is nice to plot that particular function but it'd be nice to be able to play with the parameters, so lets define a quad() function where we can pass in what we like.\n",
    "\n",
    "Also functionally these two definitions of a function are the same that I've written below, its just a nice python syntax to be able to write it on one line but its not very common in the general python universe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f12167b-a880-40ef-9d6d-b476247f66f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quad(a,b,c,x): return a*x**2 + b*x + c\n",
    "\n",
    "def quad(a,b,c,x):\n",
    "    return a*x**2 + b*x + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "304e8083-e4e0-4df9-8db8-5162771c8acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.75"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quad(3,2,1,1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10378769-8587-48cd-af48-635bb0831ac4",
   "metadata": {},
   "source": [
    "Lets introduce as Jeremy does partial functions, he describes it as something along the lines of 'fixing' part of a function. I've thought of it as making a modified function from another function but his description is simpler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb09cc2-b144-4fdd-a877-b1f3a64b8158",
   "metadata": {},
   "source": [
    "### Partial Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da4fa2f2-8576-4faa-b96f-1565901deb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.75"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "def mk_quad(a,b,c): return partial(quad,a,b,c)\n",
    "f = mk_quad(3,2,1)\n",
    "f(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c4586dd-895b-4179-813e-33e54f676775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<hr/>\n",
       "<h3>partial</h3>\n",
       "<blockquote><pre><code>partial</code></pre></blockquote><p>partial(func, *args, **keywords) - new function with partial application\n",
       "of the given arguments and keywords.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.torch_core import doc\n",
    "\n",
    "doc(partial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088eef81-ee4c-400a-ad69-296fa299c36b",
   "metadata": {},
   "source": [
    "The [python docs themselves are quite useful](https://docs.python.org/3/library/functools.html#functools.partial) at describing partials. For example, \"Return a new partial object which when called will behave like *func* called with the positional and keyword arguments.\"\n",
    "\n",
    "\"The partial() is used for *partial function application* which \"freezes\" some portion of a function's arguements and keywords, resulting in a new object with a simplified signature.\"\n",
    "\n",
    "Looks like Jeremy is more accurate, closer to the original python docs & its probably a better analogy of partial objects. My understanding is improved and I'll stop saying function from another function and start espousing something similar to the docs & Jeremy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c7ff2df-88b4-4b9a-bb84-c4d8aed67ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_function(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a27df66-1a87-447a-a7f7-31975d19a280",
   "metadata": {},
   "source": [
    "### Adding Noise to Our Perfect Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2999cf96-7a19-4a83-81e0-06f0946fc5cb",
   "metadata": {},
   "source": [
    "Lets now make some 'real' looking data,  we can add some noise to this function to more closely represent what data we're more likely to spot out in the hypothetical real world where the generator function of our data is perfect like this but we also live in the same world with innacurate measuring devices.\n",
    "\n",
    "### Nassim Taleb is an Awesome Writer\n",
    "\n",
    "Side note, the book \"Fooled by Randomness\" and \"Black Swan\" by Nassim Taleb are genuinely inspiring works that made me think and behave about and in the world differently. In particular Nassim introduces the concept of these 'invisible' generators that create the randomness in our world, the main problem is that we only ever observe a sample from these generators. Despite 'long' time frames relative to our lives, ie having data over 20 years, that simply might be an insufficient sample from the 'generator' to make any worthwhile inference of what the actual likelihood of your observations actually are. Irrelevant to the python we're writing right now but when imaginging this hypothetical world where we observe this perfect function but only see a noisy version, I thought I'd share some of my favourite books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "957bed43-7456-4ab9-9a74-1acf97a4694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import normal, seed, uniform\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def noise(x, scale): return normal(scale=scale, size=x.shape)\n",
    "def add_noise(x, mult, add): return x * (1+noise(x, mult)) + noise(x,add)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c19947-54a0-4116-b027-8e7eeabf9665",
   "metadata": {},
   "source": [
    "Lets investigate each of the variables that Jeremy instantiates in the next few lines. I want to understand what each method is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "879dbf3d-8ad6-478b-8065-c7794fe96fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<hr/>\n",
       "<h3>RandomState.normal</h3>\n",
       "<blockquote><pre><code>RandomState.normal</code></pre></blockquote><p>Draw random samples from a normal (Gaussian) distribution.\n",
       "\n",
       "The probability density function of the normal distribution, first\n",
       "derived by De Moivre and 200 years later by both Gauss and Laplace\n",
       "independently [2]_, is often called the bell curve because of\n",
       "its characteristic shape (see the example below).\n",
       "\n",
       "The normal distributions occurs often in nature.  For example, it\n",
       "describes the commonly occurring distribution of samples influenced\n",
       "by a large number of tiny, random disturbances, each with its own\n",
       "unique distribution [2]_.\n",
       "\n",
       ".. note::\n",
       "    New code should use the ``normal`` method of a ``default_rng()``\n",
       "    instance instead; please see the :ref:`random-quick-start`.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc(normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f38c25f-2a90-4a6d-8abf-287b57b9e338",
   "metadata": {},
   "source": [
    "Ok so the normal function will draw random samples from a normal distribution, we have a scale and size variable which set the standard deviation and number of outputs we'd like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6737fe6-85bc-49a7-8016-f2473bd00e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.13902531, -0.13971893,  0.07258868, -0.57398407, -0.51747535, -0.16868626, -0.30384934,  0.0942742 , -0.27240722, -0.42369111])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see 10 samples which are taken from a normal distribution with a standard deviation of 0.3\n",
    "\n",
    "normal(scale=.3,size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c841d1b5-bb2f-4588-a314-05a45fa56f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "linspace(start, end, steps, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
       "\n",
       "Creates a one-dimensional tensor of size :attr:`steps` whose values are evenly\n",
       "spaced from :attr:`start` to :attr:`end`, inclusive. That is, the value are:\n",
       "\n",
       ".. math::\n",
       "    (\\text{start},\n",
       "    \\text{start} + \\frac{\\text{end} - \\text{start}}{\\text{steps} - 1},\n",
       "    \\ldots,\n",
       "    \\text{start} + (\\text{steps} - 2) * \\frac{\\text{end} - \\text{start}}{\\text{steps} - 1},\n",
       "    \\text{end})\n",
       "\n",
       "\n",
       "From PyTorch 1.11 linspace requires the steps argument. Use steps=100 to restore the previous behavior.\n",
       "\n",
       "Args:\n",
       "    start (float): the starting value for the set of points\n",
       "    end (float): the ending value for the set of points\n",
       "    steps (int): size of the constructed tensor\n",
       "\n",
       "Keyword arguments:\n",
       "    out (Tensor, optional): the output tensor.\n",
       "    dtype (torch.dtype, optional): the data type to perform the computation in.\n",
       "        Default: if None, uses the global default dtype (see torch.get_default_dtype())\n",
       "        when both :attr:`start` and :attr:`end` are real,\n",
       "        and corresponding complex dtype when either is complex.\n",
       "    layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
       "        Default: ``torch.strided``.\n",
       "    device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
       "        Default: if ``None``, uses the current device for the default tensor type\n",
       "        (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
       "        for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
       "    requires_grad (bool, optional): If autograd should record operations on the\n",
       "        returned tensor. Default: ``False``.\n",
       "\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> torch.linspace(3, 10, steps=5)\n",
       "    tensor([  3.0000,   4.7500,   6.5000,   8.2500,  10.0000])\n",
       "    >>> torch.linspace(-10, 10, steps=5)\n",
       "    tensor([-10.,  -5.,   0.,   5.,  10.])\n",
       "    >>> torch.linspace(start=-10, end=10, steps=5)\n",
       "    tensor([-10.,  -5.,   0.,   5.,  10.])\n",
       "    >>> torch.linspace(start=-10, end=10, steps=1)\n",
       "    tensor([-10.])\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.linspace?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad98fbce-b654-4b36-96aa-86b106bbd012",
   "metadata": {},
   "source": [
    "torch.linspace looks like a really nice way to build a tensor that I think is 'linearly' spaced out based on the start,stop, and steps variables you provide. So below we start from -2, go all the way to 2, and add 20 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fee1a5d8-80c5-4368-81f1-45a268826ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-2.0000, -1.7895, -1.5789, -1.3684, -1.1579, -0.9474, -0.7368, -0.5263, -0.3158, -0.1053,  0.1053,  0.3158,  0.5263,  0.7368,  0.9474,  1.1579,  1.3684,  1.5789,  1.7895,  2.0000]),\n",
       " torch.Size([20]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.linspace(-2,2,steps=20)\n",
    "test, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd7b6eb-d456-4499-8071-cdcb405fe19d",
   "metadata": {},
   "source": [
    "Jeremy also runs a '[:,None]' indexation on this linspace which seems like a cool trick to do something but I'm not quite sure what. It look like he wants all of the columns, hence the ';' semi-colon which gives you all but I'm not sure what the None command does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9416c41-5b29-4f84-a364-ab2733f32cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.0000],\n",
       "         [-1.7895],\n",
       "         [-1.5789],\n",
       "         [-1.3684],\n",
       "         [-1.1579],\n",
       "         [-0.9474],\n",
       "         [-0.7368],\n",
       "         [-0.5263],\n",
       "         [-0.3158],\n",
       "         [-0.1053],\n",
       "         [ 0.1053],\n",
       "         [ 0.3158],\n",
       "         [ 0.5263],\n",
       "         [ 0.7368],\n",
       "         [ 0.9474],\n",
       "         [ 1.1579],\n",
       "         [ 1.3684],\n",
       "         [ 1.5789],\n",
       "         [ 1.7895],\n",
       "         [ 2.0000]]),\n",
       " torch.Size([20]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:,None], test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dcde7b-ab72-4184-a777-594b9704dfdf",
   "metadata": {},
   "source": [
    "Ok so it looks like it transposes the tensor from being a single row with many columns to being one column with many rows. I think my language of 'rows' and 'columns' is incorrect, this is simply a data table / dataframe way of thinking and tensors are fundamentally different so I need to figure out better language but I'm hoping we're at a simple enough state where this makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c82750fc-2ebe-4f3e-9fbd-356f52141623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([14.0650,  6.8087,  5.2557,  1.7704,  0.0466,  0.7778,  0.0653,  2.4518,  1.0627, -1.8938,  1.5054,  2.4260,  1.8566,  3.7182,  8.5125,  6.0473,  8.6819,  4.3318,  9.0302, 19.4673],\n",
       "        dtype=torch.float64),\n",
       " tensor([[ 7.3767],\n",
       "         [ 7.1719],\n",
       "         [ 5.7720],\n",
       "         [ 1.7108],\n",
       "         [ 2.1533],\n",
       "         [ 1.7766],\n",
       "         [ 2.5033],\n",
       "         [ 1.5059],\n",
       "         [-0.0546],\n",
       "         [ 1.4334],\n",
       "         [ 1.5242],\n",
       "         [ 4.2746],\n",
       "         [ 1.7996],\n",
       "         [ 5.5367],\n",
       "         [ 0.6079],\n",
       "         [ 6.9520],\n",
       "         [10.0430],\n",
       "         [10.9848],\n",
       "         [14.5838],\n",
       "         [ 6.5115]], dtype=torch.float64))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_noise(f(test),.3,1.5),add_noise(f(test)[:,None],.3,1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5647da02-90ec-4a06-a679-a78cbd65542e",
   "metadata": {},
   "source": [
    "Ok so it looks like the same kind of data but transposed as we saw before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1275794-c1d9-40b8-bb06-98b817310bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a2f3be64a0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x = torch.linspace(-2, 2, steps=20)[:,None]\n",
    "y = add_noise(f(x), 0.3, 1.5)\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67343d4c-1a6a-4d84-a85f-4d904f638a00",
   "metadata": {},
   "source": [
    "Lets try it without the transposing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a691cfc-550d-4a80-bb76-ef51c294aeba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a2f3c2ccd0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.linspace(-2,2,steps=20)\n",
    "y = add_noise(f(x),0.3,1.5)\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc11e541-7aca-448c-8a22-e7a043186836",
   "metadata": {},
   "source": [
    "Ok looks the same, Jeremy not sure why we did this transposing of a 1d tensor but its certainly a neat trick. Lets move on and start playing with some parameters and Ipython interactivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba29f217-8e25-4cf2-a731-8dbdfb33ac87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831e808eead34acdb595820902871be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.5, description='a', max=4.5, min=-1.5), FloatSlider(value=1.5, descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "@interact(a=1.5, b=1.5, c=1.5)\n",
    "def plot_quad(a,b,c):\n",
    "    plot_function(mk_quad(a,b,c))\n",
    "    plt.scatter(x,y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9f5112-4221-469c-a269-3f750d321503",
   "metadata": {},
   "source": [
    "Now if you're reading on quarto, I recognise that you won't be able to play with the plot I've written above so I've re-written a plot function command with Altair so that you can play around with it on the blog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e4932ca1-6c65-4903-acd9-4ff16c198452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-b4306f9b7ed94a7faa58f3c6468a5787\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-b4306f9b7ed94a7faa58f3c6468a5787\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-b4306f9b7ed94a7faa58f3c6468a5787\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"data\": {\"name\": \"data-9ba740e81f0e38a6466420e14ecacb0a\"}, \"mark\": {\"type\": \"line\", \"color\": \"red\"}, \"encoding\": {\"x\": {\"field\": \"x\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"y\", \"type\": \"quantitative\"}}, \"selection\": {\"selector_b\": {\"type\": \"single\", \"fields\": [\"b\"], \"bind\": {\"input\": \"range\", \"max\": 3, \"min\": 0, \"name\": \"B\", \"step\": 0.1}, \"init\": {\"b\": 1.5}}, \"selector_a\": {\"type\": \"single\", \"fields\": [\"a\"], \"bind\": {\"input\": \"range\", \"max\": 3, \"min\": 0, \"name\": \"A\", \"step\": 0.1}, \"init\": {\"a\": 1.5}}}, \"title\": \"$3x^2 + 2x + 1$\", \"transform\": [{\"calculate\": \"((selector_a.a*pow(datum.x,2) + selector_b.b*datum.x)) + datum.c\", \"as\": \"y\"}]}, {\"data\": {\"name\": \"data-bbf1e8f9dbd7b2551661e60c5f22e61a\"}, \"mark\": \"point\", \"encoding\": {\"x\": {\"field\": \"x\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"y\", \"type\": \"quantitative\"}}}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-9ba740e81f0e38a6466420e14ecacb0a\": [{\"x\": -2.0, \"y\": 1, \"c\": 1}, {\"x\": -1.7894736528396606, \"y\": 1, \"c\": 1}, {\"x\": -1.5789473056793213, \"y\": 1, \"c\": 1}, {\"x\": -1.3684210777282715, \"y\": 1, \"c\": 1}, {\"x\": -1.1578947305679321, \"y\": 1, \"c\": 1}, {\"x\": -0.9473683834075928, \"y\": 1, \"c\": 1}, {\"x\": -0.736842155456543, \"y\": 1, \"c\": 1}, {\"x\": -0.5263158082962036, \"y\": 1, \"c\": 1}, {\"x\": -0.31578946113586426, \"y\": 1, \"c\": 1}, {\"x\": -0.10526314377784729, \"y\": 1, \"c\": 1}, {\"x\": 0.10526317358016968, \"y\": 1, \"c\": 1}, {\"x\": 0.31578946113586426, \"y\": 1, \"c\": 1}, {\"x\": 0.5263158082962036, \"y\": 1, \"c\": 1}, {\"x\": 0.736842155456543, \"y\": 1, \"c\": 1}, {\"x\": 0.9473683834075928, \"y\": 1, \"c\": 1}, {\"x\": 1.1578947305679321, \"y\": 1, \"c\": 1}, {\"x\": 1.3684210777282715, \"y\": 1, \"c\": 1}, {\"x\": 1.5789473056793213, \"y\": 1, \"c\": 1}, {\"x\": 1.7894736528396606, \"y\": 1, \"c\": 1}, {\"x\": 2.0, \"y\": 1, \"c\": 1}], \"data-bbf1e8f9dbd7b2551661e60c5f22e61a\": [{\"x\": -2.0, \"y\": 7.1532941228294025}, {\"x\": -1.7894736528396606, \"y\": 1.893956234841271}, {\"x\": -1.5789473056793213, \"y\": 3.971887457752789}, {\"x\": -1.3684210777282715, \"y\": 2.827167635794204}, {\"x\": -1.1578947305679321, \"y\": 1.6756875626679537}, {\"x\": -0.9473683834075928, \"y\": 2.3718046504650157}, {\"x\": -0.736842155456543, \"y\": 1.695710642867792}, {\"x\": -0.5263158082962036, \"y\": -1.716006165774023}, {\"x\": -0.31578946113586426, \"y\": 3.0151138960180557}, {\"x\": -0.10526314377784729, \"y\": 2.665373312526635}, {\"x\": 0.10526317358016968, \"y\": 0.14548339482690498}, {\"x\": 0.31578946113586426, \"y\": 1.4044058622172635}, {\"x\": 0.5263158082962036, \"y\": 3.2101158051480274}, {\"x\": 0.736842155456543, \"y\": 3.87755749778438}, {\"x\": 0.9473683834075928, \"y\": 2.395760880005427}, {\"x\": 1.1578947305679321, \"y\": 5.982437481493932}, {\"x\": 1.3684210777282715, \"y\": 3.6677187164190683}, {\"x\": 1.5789473056793213, \"y\": 5.7444791380748494}, {\"x\": 1.7894736528396606, \"y\": 9.87444752253596}, {\"x\": 2.0, \"y\": 12.585373409707303}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "def plot_altair(a=1.5,b=1.5,c=1.5, title=\"$3x^2 + 2x + 1$\"):\n",
    "    a, b, c = 1.5, 1.5, 1\n",
    "    f = mk_quad(a,b,c)\n",
    "    x = torch.linspace(-2,2,steps=20)\n",
    "    y = add_noise(f(x),0.3,1.5)\n",
    "    data = pd.DataFrame({\"x\":x.numpy(), \"y\":y.numpy()})\n",
    "    scatter = alt.Chart(data).mark_point().encode(\n",
    "        x='x:Q',\n",
    "        y='y:Q'\n",
    "    )\n",
    "\n",
    "    f = mk_quad(a,b,c)\n",
    "\n",
    "    selector_a =  alt.selection_single(name=\"selector_a\", \n",
    "                                    fields=['a'],  \n",
    "                                    bind=alt.binding_range(min=0, max=3, step=0.1, name='A'),\n",
    "                                    init={'a': a,}) \n",
    "    selector_b = alt.selection_single(name=\"selector_b\",\n",
    "                                    fields=['b'], \n",
    "                                    bind=alt.binding_range(min=0, max=3, step=0.1, name='B'),\n",
    "                                    init={'b': b})\n",
    "    # selector_c = alt.selection_single(name=\"selector_c\",\n",
    "    #                                 fields=['c'], \n",
    "    #                                 bind=alt.binding_range(min=0, max=3, step=0.1, name='C'),\n",
    "    #                                 init={'c': c})\n",
    "\n",
    "\n",
    "    line = alt.Chart(pd.DataFrame({\"x\":x.numpy(),\"y\":1,\"c\":c})).mark_line(color=\"red\").encode(\n",
    "        x='x',\n",
    "        y='y',\n",
    "    ).transform_calculate(\n",
    "        y=\"((selector_a.a*pow(datum.x,2) + selector_b.b*datum.x)) + datum.c\").properties(title=title).add_selection(selector_b).add_selection(selector_a)\n",
    "\n",
    "    return (line + scatter)\n",
    "\n",
    "plot_altair()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec07e6a-b5e0-4bbc-98a9-c34d014eb3c1",
   "metadata": {},
   "source": [
    "Also I know I've not given you the bias term to play with here or \"c\" for you to adjust. For whatever reason altair absolutely throws a fit if I change the \"datum.c\" to \"selector_c.c\" despite them supposedly being the same values. The function line plot goes absolutely haywire and I have not been able to troubleshoot it and playing with \"a\" and \"b\" still hammers home the point of seeing the 'fit' of the line dependent on these values.\n",
    "\n",
    "### Adding a Loss Function\n",
    "As Jeremy mentions, if we think back to Arthur Samuel from the first chapter, we want some automatic way to measure how well we've fit our function to the data, this would be our loss function. A simple and popular metric is Mean Squared Error (MSE) which is calculated by averaging the squared error of all the predictions of your model. Here is a python implementation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa4d8886-2cec-4d07-94f2-c4f76d64a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the lecture\n",
    "\n",
    "def mse(predictions, actuals): return ((predictions-actuals)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "1d104c76-bfa7-44a1-84c4-7ed897854575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbc78ee120744eea9820d70487bfc95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.5, description='a', max=4.5, min=-1.5), FloatSlider(value=1.5, descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(a=1.5, b=1.5, c=1.5)\n",
    "def plot_quad(a,b,c):\n",
    "    f = mk_quad(a,b,c)\n",
    "    loss = mse(f(x),y)\n",
    "    plot_function(f, title=f\"Mean Squared Error Loss: {loss}\")\n",
    "    plt.scatter(x,y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6890032e-491d-4867-8b87-d7c9ff01af3f",
   "metadata": {},
   "source": [
    "Again if you're on quarto, you won't be able to play with the interactive pyplot graph here where you can see the loss change as the parameters are modified. There's also no way to dynamically change labels in Altair to my knowledge from a few stack overflow and github question. I'm going to replot our interactive graph with an example title that matches the pyplot so you can follow along without bringing down my notebook. If you wanted to see the magic values change and really have this sink in, please bring down the notebook or open it in colab & play with the plots ☺."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "69cf60f1-12dd-495d-968a-11f116826737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-67f1155a96964939985c2500c38f344d\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-67f1155a96964939985c2500c38f344d\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-67f1155a96964939985c2500c38f344d\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"data\": {\"name\": \"data-9ba740e81f0e38a6466420e14ecacb0a\"}, \"mark\": {\"type\": \"line\", \"color\": \"red\"}, \"encoding\": {\"x\": {\"field\": \"x\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"y\", \"type\": \"quantitative\"}}, \"selection\": {\"selector_b\": {\"type\": \"single\", \"fields\": [\"b\"], \"bind\": {\"input\": \"range\", \"max\": 3, \"min\": 0, \"name\": \"B\", \"step\": 0.1}, \"init\": {\"b\": 1.5}}, \"selector_a\": {\"type\": \"single\", \"fields\": [\"a\"], \"bind\": {\"input\": \"range\", \"max\": 3, \"min\": 0, \"name\": \"A\", \"step\": 0.1}, \"init\": {\"a\": 1.5}}}, \"title\": \"Mean Squared Error Loss: 3.1498 \", \"transform\": [{\"calculate\": \"((selector_a.a*pow(datum.x,2) + selector_b.b*datum.x)) + datum.c\", \"as\": \"y\"}]}, {\"data\": {\"name\": \"data-ba1ea4b2b9fcfe9da74e05e29013375b\"}, \"mark\": \"point\", \"encoding\": {\"x\": {\"field\": \"x\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"y\", \"type\": \"quantitative\"}}}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-9ba740e81f0e38a6466420e14ecacb0a\": [{\"x\": -2.0, \"y\": 1, \"c\": 1}, {\"x\": -1.7894736528396606, \"y\": 1, \"c\": 1}, {\"x\": -1.5789473056793213, \"y\": 1, \"c\": 1}, {\"x\": -1.3684210777282715, \"y\": 1, \"c\": 1}, {\"x\": -1.1578947305679321, \"y\": 1, \"c\": 1}, {\"x\": -0.9473683834075928, \"y\": 1, \"c\": 1}, {\"x\": -0.736842155456543, \"y\": 1, \"c\": 1}, {\"x\": -0.5263158082962036, \"y\": 1, \"c\": 1}, {\"x\": -0.31578946113586426, \"y\": 1, \"c\": 1}, {\"x\": -0.10526314377784729, \"y\": 1, \"c\": 1}, {\"x\": 0.10526317358016968, \"y\": 1, \"c\": 1}, {\"x\": 0.31578946113586426, \"y\": 1, \"c\": 1}, {\"x\": 0.5263158082962036, \"y\": 1, \"c\": 1}, {\"x\": 0.736842155456543, \"y\": 1, \"c\": 1}, {\"x\": 0.9473683834075928, \"y\": 1, \"c\": 1}, {\"x\": 1.1578947305679321, \"y\": 1, \"c\": 1}, {\"x\": 1.3684210777282715, \"y\": 1, \"c\": 1}, {\"x\": 1.5789473056793213, \"y\": 1, \"c\": 1}, {\"x\": 1.7894736528396606, \"y\": 1, \"c\": 1}, {\"x\": 2.0, \"y\": 1, \"c\": 1}], \"data-ba1ea4b2b9fcfe9da74e05e29013375b\": [{\"x\": -2.0, \"y\": 7.041993345260002}, {\"x\": -1.7894736528396606, \"y\": 4.904178821209572}, {\"x\": -1.5789473056793213, \"y\": 1.7727710341311442}, {\"x\": -1.3684210777282715, \"y\": 0.7606898982401522}, {\"x\": -1.1578947305679321, \"y\": 2.3201959322288626}, {\"x\": -0.9473683834075928, \"y\": 1.1939174214330404}, {\"x\": -0.736842155456543, \"y\": 2.3717677847263436}, {\"x\": -0.5263158082962036, \"y\": 1.7435753402411593}, {\"x\": -0.31578946113586426, \"y\": 2.205424429334659}, {\"x\": -0.10526314377784729, \"y\": 0.06279923783679553}, {\"x\": 0.10526317358016968, \"y\": 3.224030981362147}, {\"x\": 0.31578946113586426, \"y\": 0.925382778264971}, {\"x\": 0.5263158082962036, \"y\": 5.154370596897669}, {\"x\": 0.736842155456543, \"y\": 1.2885357751694446}, {\"x\": 0.9473683834075928, \"y\": 5.239233881923008}, {\"x\": 1.1578947305679321, \"y\": 4.644395880794835}, {\"x\": 1.3684210777282715, \"y\": 8.045508666899412}, {\"x\": 1.5789473056793213, \"y\": 7.748744125516475}, {\"x\": 1.7894736528396606, \"y\": 6.552643142338891}, {\"x\": 2.0, \"y\": 12.35399726367135}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_altair(title=\"Mean Squared Error Loss: 3.1498 \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d155df-1777-421e-a0bb-f3b3487aead3",
   "metadata": {},
   "source": [
    "### Derivatives, Rate of Change, Gradients\n",
    "\n",
    "At this point it should be clear that you can muck around with these variables to fit this function line to our data depending on the a,b,c terms. We can manually play around with them and see the MSE or loss function improve or get worse. When doing this by hand, its a manual activity and we're checking the number go up or down but if we wanted to 'Arthur Samuel' style automate this process, we can use derivatives.\n",
    "\n",
    "The way that I have understood derivates previously is that they help you explain the 'rate of change' for a function at any point. This relates to the gradient of a point on the curve since the gradient will tell me for any point on a function how much y will change if I change x, but because we don't have a linear function, this gradient changes a lot as we move along the curve. Derivatives let me figure out this gradient at any point.\n",
    "\n",
    "Now this is a naive and likely wrong way of explaining derivatives, its just me writing out my thoughts and shaky foundations as they are currently. However the high level concept of derivatives being 'a way of knowing the correct direction to change a value in order to minimise our loss' is the important bit and I'm fairly confident that I'm not too wrong there. Take my explanations with a grain of salt as I am but this is the current nuance of how I think about derivatives, and gradients in relation to functions and minimising losses\n",
    "\n",
    "Pytorch will calculate these gradients for us so we reliably can always know how to change our parameters in order to improve our loss function. I feel like we're starting to see the symphony of concepts come together here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b37cd797-a9ac-4829-b748-603264ccf509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0430, dtype=torch.float64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from lecture\n",
    "\n",
    "def quad_mse(params):\n",
    "    f = mk_quad(*params)\n",
    "    return mse(f(x), y)\n",
    "\n",
    "quad_mse([1.5,1.5,1.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1752d217-2414-47fa-abd4-48c33584641a",
   "metadata": {},
   "source": [
    "### 1D Tensors & functions_\n",
    "\n",
    "Ok we're now playing with tensors again, and there's two important things to note, firstly how many dimensions our tensor has, in this case only 1 as we can only move along one dimension of the tensor. Unlike a 2D tensor like a dataframe where we could move along rows and columns, and a 3D tensor where we could move along columns, up or down rows, and depth-wise into different 'slices' of this dataframe. Hopefully that feels comfortable of the dimensions of a tensor. The other important note here is we are calling a *requires_grad_()* function which has an important *_* after the function name, this means to do the operation 'inplace' or on the object we're calling it with. If we call the function without the *_* it will return the output of the function but to a new object instead of the object we used to call the function, I'll show you below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fd7055cf-1861-4878-aaae-6740f7e8dccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5000, 1.5000, 1.5000])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = torch.tensor([1.5,1.5,1.5])\n",
    "abc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393e64c5-e3e4-429c-9e7b-ff1e8936166f",
   "metadata": {},
   "source": [
    "Lets modify 'abc' via the add function but also inspect abc after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "198caf2e-a552-41af-baf9-7f222ca9cf20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6.5000, 6.5000, 6.5000]), tensor([1.5000, 1.5000, 1.5000]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.add(5), abc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9611fbf5-4fd3-4150-b9a7-d83cc7110feb",
   "metadata": {},
   "source": [
    "We can see the 'abc' tensor is still unchanged, despite calling the 'add()' function to it which returned a modified tensor with what we'd expect abc to look like after adding '5' to each value. Lets now try and inplace function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ce3b901f-fe3f-45ba-8d7d-6f8cb0471bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6.5000, 6.5000, 6.5000]), tensor([6.5000, 6.5000, 6.5000]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.add_(5), abc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cdc584-770f-4e03-b4d0-d5a4b06e0a86",
   "metadata": {},
   "source": [
    "Now we can see that 'abc' has been modified as well as returning our modified tensor. Now [pytorch actually recommends *NOT* doing in-place modifications](https://pytorch.org/docs/stable/notes/autograd.html#in-place-operations-with-autograd) as its less memory efficient but for demonstration purposes or simplicity if you're not worried about taking the performance hit its totally ok. [Checkout this awesome stackoverflow Q&A](https://stackoverflow.com/questions/52920098/what-does-the-underscore-suffix-in-pytorch-functions-mean) to read more on the *_* underscore functions of pytorch and the pytorch recommendations.\n",
    "\n",
    "Lets get back to using torch's mad grad functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8050099d-f9e3-4900-a9f6-f0b576ebce4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5000, 1.5000, 1.5000], requires_grad=True)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = torch.tensor([1.5,1.5,1.5])\n",
    "abc.requires_grad_()\n",
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ea1dd36c-6641-4710-b9be-c525ac86be90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0430, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = quad_mse(abc)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fc0f96-a7e9-4170-859c-f05b62122949",
   "metadata": {},
   "source": [
    "Ok so we've replicated our call before to quad_mse and can see the same loss, lets now calculate the gradients on our tensor by calling backward(), which is a reference to backpropagation or backprop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6c62beee-d3c8-4277-b588-b9c4121a079b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mgradient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Computes the gradient of current tensor w.r.t. graph leaves.\n",
       "\n",
       "The graph is differentiated using the chain rule. If the tensor is\n",
       "non-scalar (i.e. its data has more than one element) and requires\n",
       "gradient, the function additionally requires specifying ``gradient``.\n",
       "It should be a tensor of matching type and location, that contains\n",
       "the gradient of the differentiated function w.r.t. ``self``.\n",
       "\n",
       "This function accumulates gradients in the leaves - you might need to zero\n",
       "``.grad`` attributes or set them to ``None`` before calling it.\n",
       "See :ref:`Default gradient layouts<default-grad-layouts>`\n",
       "for details on the memory layout of accumulated gradients.\n",
       "\n",
       ".. note::\n",
       "\n",
       "    If you run any forward ops, create ``gradient``, and/or call ``backward``\n",
       "    in a user-specified CUDA stream context, see\n",
       "    :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
       "\n",
       ".. note::\n",
       "\n",
       "    When ``inputs`` are provided and a given input is not a leaf,\n",
       "    the current implementation will call its grad_fn (though it is not strictly needed to get this gradients).\n",
       "    It is an implementation detail on which the user should not rely.\n",
       "    See https://github.com/pytorch/pytorch/pull/60521#issuecomment-867061780 for more details.\n",
       "\n",
       "Args:\n",
       "    gradient (Tensor or None): Gradient w.r.t. the\n",
       "        tensor. If it is a tensor, it will be automatically converted\n",
       "        to a Tensor that does not require grad unless ``create_graph`` is True.\n",
       "        None values can be specified for scalar Tensors or ones that\n",
       "        don't require grad. If a None value would be acceptable then\n",
       "        this argument is optional.\n",
       "    retain_graph (bool, optional): If ``False``, the graph used to compute\n",
       "        the grads will be freed. Note that in nearly all cases setting\n",
       "        this option to True is not needed and often can be worked around\n",
       "        in a much more efficient way. Defaults to the value of\n",
       "        ``create_graph``.\n",
       "    create_graph (bool, optional): If ``True``, graph of the derivative will\n",
       "        be constructed, allowing to compute higher order derivative\n",
       "        products. Defaults to ``False``.\n",
       "    inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
       "        accumulated into ``.grad``. All other Tensors will be ignored. If not\n",
       "        provided, the gradient is accumulated into all the leaf Tensors that were\n",
       "        used to compute the attr::tensors.\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\nick\\anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\_tensor.py\n",
       "\u001b[1;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss.backward?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "565ed82a-ecf3-469c-93fd-c72aeab6ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b62e45-d1ab-4bd2-b1b5-f2c7e4b26a0d",
   "metadata": {},
   "source": [
    "Now its silently succeeded, but what its done is add a 'grad' attribute to our abc tensor, with each corresponding value of grad explaining how the values of the tensor 'abc' will change if we add to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c4ce2e32-db02-44e7-9ed6-8644f03b8057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0015, 0.2250, 0.3953])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3746f5-66f1-446c-8850-422824b2e28a",
   "metadata": {},
   "source": [
    "Ok so with each of these gradients, we need to decrease our parameters in order to reduce our loss function as the gradients are positive, meaning if we add to them, the loss will get worse.\n",
    "\n",
    "As Jeremy states, we want to add the 'negative' of our gradients by some small value as we don't want to leap too far along our function curve and overshoot the optimal value. We need to multiply our gradients by a 'learning rate', which is this small value that helps us move along the curve, the size of the learning rate changes how far along the curve we leap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a928b4d1-4d6e-41b8-8cb6-9b48fd2e8fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0430, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our loss previously\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a991d5-033e-4805-baea-c85fdb2fd2d9",
   "metadata": {},
   "source": [
    "Note we disable the gradient calculation with torch.no_grad() since \"abc.requires_grad\" is true which means that anytime the tensor is used in a function, it calculates the gradients. We want to actually do this manually ourselves by updating abc by the learning and then re-calculating the loss.\n",
    "\n",
    "Lets do this and see if our loss improves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f22edce9-d063-4851-b3d2-168d5a58e90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0409, dtype=torch.float64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with torch.no_grad():\n",
    "    abc -= abc.grad*learning_rate\n",
    "    loss = quad_mse(abc)\n",
    "    \n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f56758-71bf-4cc8-8056-cdf7a4e2307f",
   "metadata": {},
   "source": [
    "It got better! By an absolutely abysmal amount, maybe we need a bigger learning rate.... Or more compute, lets try a few iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dd15e40a-2679-4f7c-988e-b2ad47c5973f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current loss is 2.0389189772360474\n",
      "The current loss is 2.0369663885871843\n",
      "The current loss is 2.0350602976519268\n",
      "The current loss is 2.0332007599435213\n",
      "The current loss is 2.031387810476578\n",
      "The current loss is 2.0296212739311534\n",
      "The current loss is 2.0279015750808718\n",
      "The current loss is 2.0262280107856907\n",
      "The current loss is 2.024601005141407\n",
      "The current loss is 2.0230206668897206\n",
      "The current loss is 2.0214867744911467\n",
      "The current loss is 2.019999455730664\n",
      "The current loss is 2.0185587881549756\n",
      "The current loss is 2.0171645932529865\n",
      "The current loss is 2.015816816414771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.0158, dtype=torch.float64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "for iteration in range(15):\n",
    "    with torch.no_grad():\n",
    "        abc -= abc.grad*learning_rate\n",
    "        loss = quad_mse(abc)\n",
    "        print(f\"The current loss is {loss}\")\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c249e2-0690-4a52-8bc5-a6c8ae920bd5",
   "metadata": {},
   "source": [
    "How awesome is this, we have a improving loss value because of these gradients being updated, our loss being calculated and being looped over again and again. This process is called **Optimisation using gradient descent**, we've done a very basic implementation but nonetheless this is a key term to solidify and refer back to in the future. Its a sensible name since we're *Optimising* our parameters in our tensor for our loss function using *gradients* to *descend* down to the lowest loss value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220503ad-cf0e-41fe-892f-0e06c025584f",
   "metadata": {},
   "source": [
    "### Rectified Linear Units | ReLu\n",
    "\n",
    "As Jeremy noted, this is all well and good so far but it doesn't feel very likely that we can optimise for many real world datasets or observations since they'd have to fit a quadratic form to match the parameters we have to play with. If we introduce the ReLu, we can start to address this problem.\n",
    "\n",
    "A relu has the form of $f(x) = max(0,x)$ with all values under 0 being clipped to 0, we do this with torch.clip(). This probably isn't the correct 'math' way to write it out but this is the useful illustration to me of anything at 0 or below being clipped and then returning x otherwise.\n",
    "\n",
    "Lets first plot a ReLu with the function $y=mx+b$ and see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8c058794-5064-4945-8d03-14dd339f6d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "clip(input, min=None, max=None, *, out=None) -> Tensor\n",
       "\n",
       "Alias for :func:`torch.clamp`.\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.clip?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70178af1-c2bf-45a2-8751-88e682bb55a1",
   "metadata": {},
   "source": [
    "Ok so clip is a nice alias for torch.clamp, lets checkout those docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5b492e55-48db-4b13-979f-673595d83726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "clamp(input, min=None, max=None, *, out=None) -> Tensor\n",
       "\n",
       "Clamps all elements in :attr:`input` into the range `[` :attr:`min`, :attr:`max` `]`.\n",
       "Letting min_value and max_value be :attr:`min` and :attr:`max`, respectively, this returns:\n",
       "\n",
       ".. math::\n",
       "    y_i = \\min(\\max(x_i, \\text{min\\_value}_i), \\text{max\\_value}_i)\n",
       "\n",
       "If :attr:`min` is ``None``, there is no lower bound.\n",
       "Or, if :attr:`max` is ``None`` there is no upper bound.\n",
       "\n",
       "\n",
       ".. note::\n",
       "    If :attr:`min` is greater than :attr:`max` :func:`torch.clamp(..., min, max) <torch.clamp>`\n",
       "    sets all elements in :attr:`input` to the value of :attr:`max`.\n",
       "\n",
       "Args:\n",
       "    input (Tensor): the input tensor.\n",
       "    min (Number or Tensor, optional): lower-bound of the range to be clamped to\n",
       "    max (Number or Tensor, optional): upper-bound of the range to be clamped to\n",
       "\n",
       "Keyword args:\n",
       "    out (Tensor, optional): the output tensor.\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> a = torch.randn(4)\n",
       "    >>> a\n",
       "    tensor([-1.7120,  0.1734, -0.0478, -0.0922])\n",
       "    >>> torch.clamp(a, min=-0.5, max=0.5)\n",
       "    tensor([-0.5000,  0.1734, -0.0478, -0.0922])\n",
       "\n",
       "    >>> min = torch.linspace(-1, 1, steps=4)\n",
       "    >>> torch.clamp(a, min=min)\n",
       "    tensor([-1.0000,  0.1734,  0.3333,  1.0000])\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.clamp?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd17e899-19cd-4403-b0ed-724ade0d2111",
   "metadata": {},
   "source": [
    "We're using the 'min' variable to enforce every value being at least 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e9c26e2a-5117-4e85-8db7-bf74088ae81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def relu(x,m,b):\n",
    "    y = m*x+b\n",
    "    return torch.clip(y,0.)\n",
    "\n",
    "relu_partial = partial(relu,1,1)\n",
    "\n",
    "plot_function(relu_partial, title=\"ReLu $y=mx+b$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74780cf1-b219-4bc0-aedf-1dac94e2b299",
   "metadata": {},
   "source": [
    "Lets make it interactive again with altair & matplotlib so you can muck around on the blog as well as in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2472347c-d327-467d-9826-91f76a244dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05267af41df4deda0e936dfe7c2d5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='m', max=3.0, min=-1.0), FloatSlider(value=1.5, descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(m=1.0, b=1.5)\n",
    "def plot_relu(m,b):\n",
    "    plot_function(partial(relu,m,b), title=\"ReLu $y=mx+b$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bf9515-d93b-4029-a58a-9fad8b8a0d9f",
   "metadata": {},
   "source": [
    "For my Quarto friends...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "30460187-2b48-442a-bdc9-87213c7121e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-15bc87972ec5473ea5a66f43d24978e9\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-15bc87972ec5473ea5a66f43d24978e9\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-15bc87972ec5473ea5a66f43d24978e9\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-6ba7a12ce6880e0d8c473613bec83719\"}, \"mark\": {\"type\": \"line\", \"color\": \"red\"}, \"encoding\": {\"x\": {\"field\": \"x\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"y\", \"type\": \"quantitative\"}}, \"selection\": {\"selector_m\": {\"type\": \"single\", \"fields\": [\"m\"], \"bind\": {\"input\": \"range\", \"max\": 3, \"min\": 0, \"name\": \"M\", \"step\": 0.1}, \"init\": {\"m\": 1.5}}}, \"title\": \"y = mx+b\", \"transform\": [{\"calculate\": \"max(0,(selector_m.m * datum.x) + 1.5)\", \"as\": \"y\"}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-6ba7a12ce6880e0d8c473613bec83719\": [{\"x\": -2.0, \"y\": 0.0}, {\"x\": -1.9183673858642578, \"y\": 0.0}, {\"x\": -1.836734652519226, \"y\": 0.0}, {\"x\": -1.7551020383834839, \"y\": 0.0}, {\"x\": -1.6734694242477417, \"y\": 0.0}, {\"x\": -1.59183669090271, \"y\": 0.0}, {\"x\": -1.5102040767669678, \"y\": 0.0}, {\"x\": -1.4285714626312256, \"y\": 0.0}, {\"x\": -1.3469388484954834, \"y\": 0.0}, {\"x\": -1.2653062343597412, \"y\": 0.0}, {\"x\": -1.1836735010147095, \"y\": 0.0}, {\"x\": -1.1020408868789673, \"y\": 0.0}, {\"x\": -1.020408272743225, \"y\": 0.0}, {\"x\": -0.9387755990028381, \"y\": 0.061224400997161865}, {\"x\": -0.8571429252624512, \"y\": 0.14285707473754883}, {\"x\": -0.775510311126709, \"y\": 0.22448968887329102}, {\"x\": -0.6938775777816772, \"y\": 0.30612242221832275}, {\"x\": -0.6122449040412903, \"y\": 0.3877550959587097}, {\"x\": -0.5306122899055481, \"y\": 0.4693877100944519}, {\"x\": -0.44897961616516113, \"y\": 0.5510203838348389}, {\"x\": -0.36734697222709656, \"y\": 0.632652997970581}, {\"x\": -0.285714328289032, \"y\": 0.714285671710968}, {\"x\": -0.20408165454864502, \"y\": 0.795918345451355}, {\"x\": -0.12244904041290283, \"y\": 0.8775509595870972}, {\"x\": -0.040816307067871094, \"y\": 0.9591836929321289}, {\"x\": 0.04081634432077408, \"y\": 1.040816307067871}, {\"x\": 0.12244899570941925, \"y\": 1.1224490404129028}, {\"x\": 0.20408165454864502, \"y\": 1.204081654548645}, {\"x\": 0.2857142984867096, \"y\": 1.2857142686843872}, {\"x\": 0.36734694242477417, \"y\": 1.367347002029419}, {\"x\": 0.44897961616516113, \"y\": 1.4489796161651611}, {\"x\": 0.5306122303009033, \"y\": 1.5306122303009033}, {\"x\": 0.6122449636459351, \"y\": 1.612244963645935}, {\"x\": 0.693877637386322, \"y\": 1.6938776969909668}, {\"x\": 0.7755102515220642, \"y\": 1.775510311126709}, {\"x\": 0.8571429252624512, \"y\": 1.8571429252624512}, {\"x\": 0.9387755393981934, \"y\": 1.9387755393981934}, {\"x\": 1.0204081535339355, \"y\": 2.0204081535339355}, {\"x\": 1.1020408868789673, \"y\": 2.1020407676696777}, {\"x\": 1.1836735010147095, \"y\": 2.18367338180542}, {\"x\": 1.2653061151504517, \"y\": 2.265305995941162}, {\"x\": 1.3469387292861938, \"y\": 2.3469386100769043}, {\"x\": 1.4285714626312256, \"y\": 2.4285714626312256}, {\"x\": 1.5102040767669678, \"y\": 2.5102040767669678}, {\"x\": 1.59183669090271, \"y\": 2.59183669090271}, {\"x\": 1.6734693050384521, \"y\": 2.673469305038452}, {\"x\": 1.7551020383834839, \"y\": 2.7551021575927734}, {\"x\": 1.836734652519226, \"y\": 2.8367347717285156}, {\"x\": 1.9183673858642578, \"y\": 2.918367385864258}, {\"x\": 2.0, \"y\": 3.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m,b = 1.5,1.5\n",
    "\n",
    "x = torch.linspace(-2,2,50)\n",
    "y=relu_partial(x)\n",
    "\n",
    "selector_m =  alt.selection_single(name=\"selector_m\", \n",
    "                                fields=['m'],\n",
    "                                bind=alt.binding_range(min=0, max=3, step=0.1, name='M'),\n",
    "                                init={'m': m}) \n",
    "selector_b = alt.selection_single(name=\"selector_b\",\n",
    "                                fields=['b'], \n",
    "                                bind=alt.binding_range(min=0, max=3, step=0.1, name='B'),\n",
    "                                init={'b': b})\n",
    "# selector_c = alt.selection_single(name=\"selector_c\",\n",
    "#                                 fields=['c'], \n",
    "#                                 bind=alt.binding_range(min=0, max=3, step=0.1, name='C'),\n",
    "#                                 init={'c': c})\n",
    "\n",
    "data = pd.DataFrame({\"x\":x.numpy(),\"y\":y})\n",
    "\n",
    "line = alt.Chart(data=data,title=\"ReLu y = mx + b\").mark_line(color=\"red\").encode(\n",
    "    x='x:Q',\n",
    "    y='y:Q',\n",
    ").transform_calculate(y=f\"max(0,(selector_m.m * datum.x) + {b})\").properties(title=\"y = mx+b\").add_selection(selector_m)\n",
    "\n",
    "line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f78813-d64c-481d-a604-cb2fb81074d2",
   "metadata": {},
   "source": [
    "Similar to the quadratic, I can't seem to get the bias term which changes the intercept to interact nicely with the transform_calculate function of altair but you can see how playing with the 'm' term changes partly the steepness of the slope up as well as where the curve starts its ascent from 0 where its been clipped. Again, highly recommend bringing the notebook from my github over to colab but hopefully there's enough interactivity that it sinks in what we're playing with.\n",
    "\n",
    "Lets now make a double ReLu which lets us connect two of these units together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "14d74426-5d98-42b3-b979-55c45fbb778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_relu(m1,b1,m2,b2,x): return relu(x,m1,b1) + relu(x,m2,b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "949baf12-9de8-4770-8ae7-a3aa22206780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687015cbfc2f4c40b13082ab8faeb7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=-1.5, description='m1', max=1.5, min=-4.5), FloatSlider(value=-1.5, de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(m1=-1.5,b1=-1.5,m2=1.5,b2=1.5)\n",
    "def plot_double_relu(m1,b1,m2,b2):plot_function(partial(double_relu,m1,b1,m2,b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95e13f4-41d9-4780-a3aa-c4478a689b55",
   "metadata": {},
   "source": [
    "Once again for my Quarto friends, forgive me for the lack of b1/b2 bias terms, you can still get the point with the m1 and m2 values how you can make any kind of point and direction that you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "aefb86ee-c64c-4d57-9999-d9490ba888e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-16651a38c8204200951377260db7e947\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-16651a38c8204200951377260db7e947\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-16651a38c8204200951377260db7e947\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-3b140e715a8e3d27dc4e21ba14d4e2de\"}, \"mark\": {\"type\": \"line\", \"color\": \"red\"}, \"encoding\": {\"x\": {\"field\": \"x\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"y\", \"type\": \"quantitative\"}}, \"selection\": {\"selector_m\": {\"type\": \"single\", \"fields\": [\"m1\"], \"bind\": {\"input\": \"range\", \"max\": 3, \"min\": -3, \"name\": \"M1\", \"step\": 0.1}, \"init\": {\"m1\": -1.5}}, \"selector_mm\": {\"type\": \"single\", \"fields\": [\"m2\"], \"bind\": {\"input\": \"range\", \"max\": 3, \"min\": -3, \"name\": \"M2\", \"step\": 0.1}, \"init\": {\"m2\": 3}}}, \"title\": \"y = mx+b\", \"transform\": [{\"calculate\": \"(max(0,(selector_m.m1 * datum.x) + -1.5)) + (max(0,(selector_mm.m2 * datum.x) + 3))\", \"as\": \"y\"}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-3b140e715a8e3d27dc4e21ba14d4e2de\": [{\"x\": -2.0, \"y\": 1.5}, {\"x\": -1.9183673858642578, \"y\": 1.3775510787963867}, {\"x\": -1.836734652519226, \"y\": 1.2551019191741943}, {\"x\": -1.7551020383834839, \"y\": 1.132652997970581}, {\"x\": -1.6734694242477417, \"y\": 1.0102040767669678}, {\"x\": -1.59183669090271, \"y\": 0.8877549171447754}, {\"x\": -1.5102040767669678, \"y\": 0.7653059959411621}, {\"x\": -1.4285714626312256, \"y\": 0.6428570747375488}, {\"x\": -1.3469388484954834, \"y\": 0.5204081535339355}, {\"x\": -1.2653062343597412, \"y\": 0.3979593515396118}, {\"x\": -1.1836735010147095, \"y\": 0.275510311126709}, {\"x\": -1.1020408868789673, \"y\": 0.1530613899230957}, {\"x\": -1.020408272743225, \"y\": 0.030612468719482422}, {\"x\": -0.9387755990028381, \"y\": 0.18367314338684082}, {\"x\": -0.8571429252624512, \"y\": 0.4285712242126465}, {\"x\": -0.775510311126709, \"y\": 0.673469066619873}, {\"x\": -0.6938775777816772, \"y\": 0.9183673858642578}, {\"x\": -0.6122449040412903, \"y\": 1.1632652282714844}, {\"x\": -0.5306122899055481, \"y\": 1.408163070678711}, {\"x\": -0.44897961616516113, \"y\": 1.6530611515045166}, {\"x\": -0.36734697222709656, \"y\": 1.8979591131210327}, {\"x\": -0.285714328289032, \"y\": 2.142857074737549}, {\"x\": -0.20408165454864502, \"y\": 2.3877549171447754}, {\"x\": -0.12244904041290283, \"y\": 2.632652759552002}, {\"x\": -0.040816307067871094, \"y\": 2.8775510787963867}, {\"x\": 0.04081634432077408, \"y\": 3.1224489212036133}, {\"x\": 0.12244899570941925, \"y\": 3.367347002029419}, {\"x\": 0.20408165454864502, \"y\": 3.6122450828552246}, {\"x\": 0.2857142984867096, \"y\": 3.857142925262451}, {\"x\": 0.36734694242477417, \"y\": 4.102040767669678}, {\"x\": 0.44897961616516113, \"y\": 4.3469390869140625}, {\"x\": 0.5306122303009033, \"y\": 4.591836929321289}, {\"x\": 0.6122449636459351, \"y\": 4.836734771728516}, {\"x\": 0.693877637386322, \"y\": 5.081632614135742}, {\"x\": 0.7755102515220642, \"y\": 5.326530456542969}, {\"x\": 0.8571429252624512, \"y\": 5.5714287757873535}, {\"x\": 0.9387755393981934, \"y\": 5.81632661819458}, {\"x\": 1.0204081535339355, \"y\": 6.061224460601807}, {\"x\": 1.1020408868789673, \"y\": 6.306122779846191}, {\"x\": 1.1836735010147095, \"y\": 6.551020622253418}, {\"x\": 1.2653061151504517, \"y\": 6.7959184646606445}, {\"x\": 1.3469387292861938, \"y\": 7.040816307067871}, {\"x\": 1.4285714626312256, \"y\": 7.285714149475098}, {\"x\": 1.5102040767669678, \"y\": 7.530611991882324}, {\"x\": 1.59183669090271, \"y\": 7.775509834289551}, {\"x\": 1.6734693050384521, \"y\": 8.020407676696777}, {\"x\": 1.7551020383834839, \"y\": 8.26530647277832}, {\"x\": 1.836734652519226, \"y\": 8.510204315185547}, {\"x\": 1.9183673858642578, \"y\": 8.755102157592773}, {\"x\": 2.0, \"y\": 9.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1,b1, m2, b2 = -1.5,-1.5,3,3\n",
    "\n",
    "x = torch.linspace(-2,2,50)\n",
    "f = partial(double_relu,m1,b1,m2,b2)\n",
    "y= f(x)\n",
    "\n",
    "selector_m =  alt.selection_single(name=\"selector_m\", \n",
    "                                fields=['m1'],\n",
    "                                bind=alt.binding_range(min=-3, max=3, step=0.1, name='M1'),\n",
    "                                init={'m1': m1}) \n",
    "selector_b = alt.selection_single(name=\"selector_b\",\n",
    "                                fields=['b1'], \n",
    "                                bind=alt.binding_range(min=-3, max=3, step=0.1, name='B'),\n",
    "                                init={'b1': b1})\n",
    "selector_mm =  alt.selection_single(name=\"selector_mm\", \n",
    "                                fields=['m2'],\n",
    "                                bind=alt.binding_range(min=-3, max=3, step=0.1, name='M2'),\n",
    "                                init={'m2': m2}) \n",
    "selector_bb = alt.selection_single(name=\"selector_bb\",\n",
    "                                fields=['b2'], \n",
    "                                bind=alt.binding_range(min=-3, max=3, step=0.1, name='B'),\n",
    "                                init={'b12': b2})\n",
    "\n",
    "data = pd.DataFrame({\"x\":x.numpy(),\"y\":y})\n",
    "\n",
    "line = alt.Chart(data=data,title=\"Double ReLu y = (mx + b) + (mx+b)\").mark_line(color=\"red\").encode(\n",
    "    x='x:Q',\n",
    "    y='y:Q',\n",
    ").transform_calculate(y=f\"(max(0,(selector_m.m1 * datum.x) + {b1})) + (max(0,(selector_mm.m2 * datum.x) + {b2}))\").properties(title=\"y = mx+b\").add_selection(selector_m).add_selection(selector_mm)\n",
    "\n",
    "line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b439f38-0d9a-45e1-b918-ee0e3d53fca4",
   "metadata": {},
   "source": [
    "### Draw the Owl Problem\n",
    "\n",
    "**\"At this point, we have the ability to draw an elbow/squiggle, if we connect enough of these elbows and squiggles together, we can approximate/fit any function in existence given enough elbows.\"**\n",
    "\n",
    "As mentioned by Jeremy, we run into the the 'draw the rest of the owl problem'. This fact seems rediculous, this is an important essence of deep learning and we've established every foundational peice of this 'magic'. Its absolutely mind blowing (to me at least) that this is the underlying mechanics of the kind of software that detects cancers and shazam's the song you're listening to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd538b2a-cb5b-46d2-9f89-333c36a7e007",
   "metadata": {},
   "source": [
    "![Draw the Rest of the Owl Meme](https://pbs.twimg.com/media/Bs13i6LCcAAvwCf.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e216f8-d458-43e5-94c6-74b697f7450b",
   "metadata": {},
   "source": [
    "Everything further in deep learning are tricks, methods, strategies, ideas, and efficient ways to play around and build upon this simple concept, honestly astonishing. It doesn't quite feel real to me but I can see Jeremy's point, given enough squiggles you could make any shape imaginable, with our ability to create a loss function and update our parameters accordingly, we can also automatically find the right values given we have enough squiggles which is a product of our model architecture.\n",
    "\n",
    "How do we do all this efficiently, in comes matrix calculations which allows us to combine a whole bunch of parameters multiplied by a whole bunch of other input values that we're feeding them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed33ae2-eb20-4a6d-8c39-6e0ce98d22b0",
   "metadata": {},
   "source": [
    "### Matrix Calculations\n",
    "\n",
    "[Jeremy walks through an awesome site](http://matrixmultiplication.xyz/) that visually shows how matrix multiplication works. This really helps sink in how the process works, I think its naturally confusing because you have to have two matrices (tensors in our case) of different shapes and you topple one over on the side and slide it over like a window in order to multiply it by the other matrix as the website shows.\n",
    "\n",
    "Lets replicate the matrices (tensors) in python and step through each of the multiplications one by one to see how we arrive at our final tensor (matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "6ec8a579-d11c-454e-a456-20004e520f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 1],\n",
       "         [0, 1, 1],\n",
       "         [2, 3, 1]]),\n",
       " tensor([[2, 5],\n",
       "         [6, 7],\n",
       "         [1, 8]]))"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,1],\n",
    "                  [0,1,1],\n",
    "                  [2,3,1]])\n",
    "\n",
    "x = torch.tensor([[2,5],\n",
    "                  [6,7],\n",
    "                  [1,8]])\n",
    "\n",
    "a,x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e87f583-699d-4aa7-95b9-9e05ae54c5c9",
   "metadata": {},
   "source": [
    "Ok so we've got two tensors, one which is 3x3 (rows x columns) and the other which is 3x2, if we multiply them together we will yield a 3x2 tensor.\n",
    "\n",
    "Lets also checkout the docs for pytorch's matrix multiplication method which is torch.mm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "0a787caf-6f2e-436e-948b-c3b1105138a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "mm(input, mat2, *, out=None) -> Tensor\n",
       "\n",
       "Performs a matrix multiplication of the matrices :attr:`input` and :attr:`mat2`.\n",
       "\n",
       "If :attr:`input` is a :math:`(n \\times m)` tensor, :attr:`mat2` is a\n",
       ":math:`(m \\times p)` tensor, :attr:`out` will be a :math:`(n \\times p)` tensor.\n",
       "\n",
       ".. note:: This function does not :ref:`broadcast <broadcasting-semantics>`.\n",
       "          For broadcasting matrix products, see :func:`torch.matmul`.\n",
       "\n",
       "Supports strided and sparse 2-D tensors as inputs, autograd with\n",
       "respect to strided inputs.\n",
       "\n",
       "This operation has support for arguments with :ref:`sparse layouts<sparse-docs>`.\n",
       "If :attr:`out` is provided it's layout will be used. Otherwise, the result\n",
       "layout will be deduced from that of :attr:`input`.\n",
       "\n",
       "\n",
       ".. warning::\n",
       "    Sparse support is a beta feature and some layout(s)/dtype/device combinations may not be supported,\n",
       "    or may not have autograd support. If you notice missing functionality please\n",
       "    open a feature request.\n",
       "\n",
       "This operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
       "\n",
       "On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n",
       "\n",
       "Args:\n",
       "    input (Tensor): the first matrix to be matrix multiplied\n",
       "    mat2 (Tensor): the second matrix to be matrix multiplied\n",
       "\n",
       "Keyword args:\n",
       "    out (Tensor, optional): the output tensor.\n",
       "\n",
       "Example::\n",
       "\n",
       "    >>> mat1 = torch.randn(2, 3)\n",
       "    >>> mat2 = torch.randn(3, 3)\n",
       "    >>> torch.mm(mat1, mat2)\n",
       "    tensor([[ 0.4851,  0.5037, -0.3633],\n",
       "            [-0.0760, -3.6705,  2.4784]])\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.mm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cb0276-00d4-4588-9ccb-fffad8f73aaa",
   "metadata": {},
   "source": [
    "And lets run our matrix multiplication to see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "1335f6ae-ae59-42af-ba17-a9a386f1a942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15, 27],\n",
       "        [ 7, 15],\n",
       "        [23, 39]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(a,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4ef08a-18c5-4245-aeda-95b0451a9cb8",
   "metadata": {},
   "source": [
    "Awesome, looks just like the website demonstrated.\n",
    "\n",
    "As we tip the x tensor on its side to match the width of tensor a, our first set of calculations are ((2x1) + (6x2) + (1x1)) = 15. We can see the python indexation equivalent below which helps match up mentally how these calculations are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "b2f73a09-c71d-4fdd-acab-2b5fd38e5314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(2 x 1) + (6 x 2) + (1 x 1)'"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"({x[0,0]} x {a[0,0]}) + ({x[1,0]} x {a[0,1]}) + ({x[2,0]} x {a[0,2]})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c6344c-fab4-416c-ba4e-4d34bdb4261c",
   "metadata": {},
   "source": [
    "This gives us our first result of our output tensor which is '15', which we can see at the 0,0 index of our result.\n",
    "\n",
    "We then slide the 'x' tensor down one so we've now got two 'window' rows to calculate.\n",
    "\n",
    "We run the first row of calculations which is (5x1) + (7x2) + (8x1) = 27, again we can check the indexation in python and our result ends up in the 0,1 position of our output tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "e3602169-b000-462a-86d5-6a39aadeb4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(5 x 1) + (7 x 2) + (8 x 1)'"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"({x[0,1]} x {a[0,0]}) + ({x[1,1]} x {a[0,1]}) + ({x[2,1]} x {a[0,2]})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01e6eb5-a8d7-4643-a048-64c789342d55",
   "metadata": {},
   "source": [
    "At the same time we're also calculating the second row of (2x0) + (6x1) + (1x1) = 7 as our first 'column' of our x tensor is now being calculated against the second 'row' of our 'a' tensor. This output is stored at the 1,0 indexation of our output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "d27ae8b9-819a-4bbe-a86d-1fbc9b38ab7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(2 x 0) + (6 x 1) + (1 x 1)'"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"({x[0,0]} x {a[1,0]}) + ({x[1,0]} x {a[1,1]}) + ({x[2,0]} x {a[1,2]})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69202fa-c3f5-41d2-8361-a9a0469cf43b",
   "metadata": {},
   "source": [
    "Ok, I'm hoping that very explicit example in python in combination with the matrix multiplication website has knuckled down the laborious task of doing matrix multiplications. Thankfully as we saw, torch does all the magic and we don't have to do this hand-written work but scribing this down really matches up the theory with the python indexation vernacular so that they are welded together in my mind and I feel comfortable explaining the concept as well as demonstrating the mechanics of the interactions between the tensors.\n",
    "\n",
    "I did wonder what happens if the tensors are mis-shapen, so lets just add an extra row to our x tensor so that the 3 columns of tensor 'a' don't match up to the now 4 'rows' of our x tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "94eaea83-8471-49c4-9503-0e9c2a3adfd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x3 and 4x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[269], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m      2\u001b[0m                   [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m      3\u001b[0m                   [\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m]])\n\u001b[0;32m      5\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m5\u001b[39m],\n\u001b[0;32m      6\u001b[0m                   [\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m],\n\u001b[0;32m      7\u001b[0m                   [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m8\u001b[39m],\n\u001b[0;32m      8\u001b[0m                   [\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m100\u001b[39m]])\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x3 and 4x2)"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,1],\n",
    "                  [0,1,1],\n",
    "                  [2,3,1]])\n",
    "\n",
    "x = torch.tensor([[2,5],\n",
    "                  [6,7],\n",
    "                  [1,8],\n",
    "                  [100,100]])\n",
    "\n",
    "torch.mm(a,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a57df0-06aa-475c-a677-33a57645e2f8",
   "metadata": {},
   "source": [
    "Turns out you can't, how bout that!\n",
    "\n",
    "I'm guessing you can add infinite rows to tensor 'a' however since the 'windowing' process doesn't change as the 3 'a' columns x 3 'x' rows match still works and there's simply more windowing to be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "fd893af0-fc7f-41c1-9018-c5593ff84d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  15,   27],\n",
       "        [   7,   15],\n",
       "        [  23,   39],\n",
       "        [ 900, 2000],\n",
       "        [1800, 4000],\n",
       "        [2700, 6000]])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,1],\n",
    "                  [0,1,1],\n",
    "                  [2,3,1],\n",
    "                  [100,100,100],\n",
    "                  [200,200,200],\n",
    "                  [300,300,300]])\n",
    "\n",
    "x = torch.tensor([[2,5],\n",
    "                  [6,7],\n",
    "                  [1,8]])\n",
    "\n",
    "torch.mm(a,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c91b996-84dd-4533-832f-f2a52159e72a",
   "metadata": {},
   "source": [
    "Cool, looks like that still functions fine, good to try these things out. I wondered if the 'x' tensor with its 4th row would just result in a (100x0) operation since there is nothing in tensor 'a' at that indexation (since it doesn't exist) but it looks like you'd simply have to reshape tensor 'a' and fill a value of 0 if you wanted that operation to happen.\n",
    "\n",
    "### Deep Learning with Excel\n",
    "\n",
    "[At this point in the lecture (1:04:22)](https://youtu.be/hBBOjCiFcuo?t=3862), Jeremy builds a deep learning model in excel, which is absolutely insane and proves to me he just operates on another vibrational level, plane, existence, whatever you want to call it. Who gets up in the morning and thinks of doing deep learning in excel?! Then again, he's got some deep (pun not indended but very much enjoyed) programming roots in APL and S which are kind of the roots of excel and Jeremy was doing deep learning in the 90s so it doesn't surprise me he natively thinks in this array programming style. Who knew consultants, accountants, etc are all just huge functional programming fans, the OOP vs functional factional wars continue and people don't even know they're fighting the war.\n",
    "\n",
    "That being said, its super cool, its a great demonstration of how it really is these fundamental calculations that we've done by hand which produce the deep learning outcomes we're seeing. Highly recommend the watch if you're in disbelief of what I'm writing here.\n",
    "\n",
    "I was originally thinking of writing this exercise in python but I'll admit its already been quite a substantial journey to walk through only the lecture content and I'd like to make sure I get through the book content as well before investing what will be a decent chunk of time to get it right. If you're reading this I haven't yet come back to revisit this part and re-implement the excel work, feel free to either remind me or be patient as I likely will come back and pythonify the amazing example that Jeremy works through, maybe we'll even use a new dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963cd2ce-40ff-40a4-9856-8cbf22fac394",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Book Content\n",
    "\n",
    "### Training a Digit Classifier\n",
    "\n",
    "We're going to wind back the clock to 1998 when the \"National Institute of Standards and Technology\" or 'NIST' collected ~60,000 training and ~10,000 testing images of hand written digits and MNIST was born. One of the most famous datasets in all of machines learning, the 'M' in MNIST comes from the \"Modified\" word since the original creators mixed the training and test samples together since NIST originally took their training samples from a different cohort (American Census Bureau Employees) to their training sample (American High School Students). [Thanks Wiki for the history lesson](https://en.wikipedia.org/wiki/MNIST_database), in the same year, Yann Lecun and his colleagues used a Neural Net named \"Lenet-5\" to demonstrate accurate recognition of the handwritten pictures. [Checkout this video of \"Lenet-1\"](https://youtu.be/FwFduRA_L6Q) which Yann states is \"the first convolutional network that could recognise handwritten digits with good speed and accuracy.\" Its honestly bonkers seeing how amazing this tech was back in 93 yet it still took another couple of decades to hit mainstream & for the brilliance to be recognised. Its amazing watching these absolute gangsters in this random basement build history making software like its nothing.\n",
    "\n",
    "Lets Begin!\n",
    "\n",
    "### 3 or 7?\n",
    "\n",
    "Lets download MNIST and then only get the threes and sevens, fastai has some awesome helpers to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ebd49745-5e15-4bd9-83a8-3d9703f2c137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "df739185-f4e7-48b4-878c-df4a232d11e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://s3.amazonaws.com/fast-ai-sample/mnist_sample.tgz'"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URLs.MNIST_SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "a3bd9be3-0192-47e4-b719-63be85d6220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_base = Path(\"../data/\")\n",
    "mnist_path = data_base / \"MNIST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "2620b300-20cf-490d-b270-a8aaa31478ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_path.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "38f4cc15-114b-4587-bff1-81fb842da97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('C:/Users/Nick/.fastai/MNIST/mnist_sample')"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3b1650-1373-4cfc-ae82-bc32d2a31dae",
   "metadata": {},
   "source": [
    "I then move all my data from my .fastai home over to my created directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "5ba04bc8-8dfc-44dc-b430-3ab886584351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('../data/MNIST/mnist_sample/labels.csv'),Path('../data/MNIST/mnist_sample/train'),Path('../data/MNIST/mnist_sample/valid')]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mnist_path / \"mnist_sample\").ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "dfef4dbb-dab9-4994-9888-8bc793d5f091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('../data/MNIST/mnist_sample')"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_path = mnist_path / \"mnist_sample\"\n",
    "sample_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "b8850c8e-c393-4934-b745-cf497e8b8b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('../data/MNIST/mnist_sample/train/3'),Path('../data/MNIST/mnist_sample/train/7')]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sample_path / \"train\").ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2f8ed8-52e6-4137-8a5f-ed42580e6403",
   "metadata": {},
   "source": [
    "Here are our threes and sevens, lets get them into separate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "0db2804a-ec03-45cd-8ab2-d192396457b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#6131) [Path('../data/MNIST/mnist_sample/train/3/10.png'),Path('../data/MNIST/mnist_sample/train/3/10000.png'),Path('../data/MNIST/mnist_sample/train/3/10011.png'),Path('../data/MNIST/mnist_sample/train/3/10031.png'),Path('../data/MNIST/mnist_sample/train/3/10034.png'),Path('../data/MNIST/mnist_sample/train/3/10042.png'),Path('../data/MNIST/mnist_sample/train/3/10052.png'),Path('../data/MNIST/mnist_sample/train/3/1007.png'),Path('../data/MNIST/mnist_sample/train/3/10074.png'),Path('../data/MNIST/mnist_sample/train/3/10091.png')...],\n",
       " (#6265) [Path('../data/MNIST/mnist_sample/train/7/10002.png'),Path('../data/MNIST/mnist_sample/train/7/1001.png'),Path('../data/MNIST/mnist_sample/train/7/10014.png'),Path('../data/MNIST/mnist_sample/train/7/10019.png'),Path('../data/MNIST/mnist_sample/train/7/10039.png'),Path('../data/MNIST/mnist_sample/train/7/10046.png'),Path('../data/MNIST/mnist_sample/train/7/10050.png'),Path('../data/MNIST/mnist_sample/train/7/10063.png'),Path('../data/MNIST/mnist_sample/train/7/10077.png'),Path('../data/MNIST/mnist_sample/train/7/10086.png')...])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threes = (sample_path / \"train/3\").ls().sorted()\n",
    "sevens = (sample_path / \"train/7\").ls().sorted()\n",
    "threes, sevens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b46478-300c-48d8-b845-01ccc1be36d0",
   "metadata": {},
   "source": [
    "Lets checkout a 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "d505e0e5-dd51-457c-b88e-6e8ed5d4ba22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9ElEQVR4nM3Or0sDcRjH8c/pgrfBVBjCgibThiKIyTWbWF1bORhGwxARxH/AbtW0JoIGwzXRYhJhtuFY2q1ocLgbe3sGReTuuWbwkx6+r+/zQ/pncX6q+YOldSe6nG3dn8U/rTQ70L8FCGJUewvxl7NTmezNb8xIkvKugr1HSeMP6SrWOVkoTEuSyh0Gm2n3hQyObMnXnxkempRrvgD+gokzwxFAr7U7YXHZ8x4A/Dl7rbu6D2yl3etcw/F3nZgfRVI7rXM7hMUUqzzBec427x26rkmlkzEEa4nnRqnSOH2F0UUx0ePzlbuqMXAHgN6GY9if5xP8dmtHFfwjuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im3 = Image.open(threes[1])\n",
    "im3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc60f13-7cfe-4cfe-8725-1cbaea9e436a",
   "metadata": {},
   "source": [
    "Its a little baby, so tiny! We can now convert this image into a tensor/array which is what we were playing with earlier in the matrix multiplication section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "8bf6d904-9d62-4cfa-9cde-27c74309a4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  29, 150, 195, 254, 255, 254, 176, 193, 150,  96,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  48, 166, 224, 253, 253, 234, 196, 253, 253, 253, 253, 233,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,  93, 244, 249, 253, 187,  46,  10,   8,   4,  10, 194, 253, 253, 233,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0, 107, 253, 253, 230,  48,   0,   0,   0,   0,   0, 192, 253, 253, 156,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   3,  20,  20,  15,   0,   0,   0,   0,   0,  43, 224, 253, 245,  74,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249, 253, 245, 126,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  14, 101, 223, 253, 248, 124,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 166, 239, 253, 253, 253, 187,  30,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  16, 248, 250, 253, 253, 253, 253, 232, 213, 111,   2,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  43,  98,  98, 208, 253, 253, 253, 253, 187,  22,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   9,  51, 119, 253, 253, 253,  76,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1, 183, 253, 253, 139,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 182, 253, 253, 104,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  85, 249, 253, 253,  36,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  60, 214, 253, 253, 173,  11,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  98, 247, 253, 253, 226,   9,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  42, 150, 252, 253, 253, 233,  53,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  42, 115,  42,  60, 115, 159, 240, 253, 253, 250, 175,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 187, 253, 253, 253, 253, 253, 253, 253, 197,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 103, 253, 253, 253, 253, 253, 232,  67,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array(im3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdc489e-7c97-4481-abfe-ccfb12cb5891",
   "metadata": {},
   "source": [
    "I'm going to take a stab and say that the value of the number is how light or dark that specific pixel is, black being 255 and pure white being 0. Its connecting for me how the tensor calculations we were doing earlier are so applicable to working with images, underneath they're just sneaky matrix friends. We can make it a tensor as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "19725a3d-3ae4-4e7c-8428-8efb3ecd7cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,  29, 150, 195, 254, 255, 254, 176, 193, 150,  96,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,  48, 166, 224, 253, 253, 234, 196, 253, 253, 253, 253, 233,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,  93, 244, 249, 253, 187,  46,  10,   8,   4,  10, 194, 253, 253, 233,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0, 107, 253, 253, 230,  48,   0,   0,   0,   0,   0, 192, 253, 253, 156,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   3,  20,  20,  15,   0,   0,   0,   0,   0,  43, 224, 253, 245,  74,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249, 253, 245, 126,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  14, 101, 223, 253, 248, 124,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 166, 239, 253, 253, 253, 187,  30,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,  16, 248, 250, 253, 253, 253, 253, 232, 213, 111,   2,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  43,  98,  98, 208, 253, 253, 253, 253, 187,  22,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   9,  51, 119, 253, 253, 253,  76,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1, 183, 253, 253, 139,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 182, 253, 253, 104,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  85, 249, 253, 253,  36,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  60, 214, 253, 253, 173,  11,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  98, 247, 253, 253, 226,   9,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  42, 150, 252, 253, 253, 233,  53,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,  42, 115,  42,  60, 115, 159, 240, 253, 253, 250, 175,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0, 187, 253, 253, 253, 253, 253, 253, 253, 197,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0, 103, 253, 253, 253, 253, 253, 232,  67,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=torch.uint8),\n",
       " torch.Size([28, 28]))"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor(im3), tensor(im3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e771cb-999e-4456-8c14-9ff8206aebe0",
   "metadata": {},
   "source": [
    "Only 28,28 pixels but we can totally workout what we're seeing with some detail, how cool. We can index into these tensors like we did earlier when walking through matrix multiplication, fastai has a cool trick to show you the instensity of the pixels via dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "a8b9479c-195b-429b-b802-671ab3c89c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d93d8_row0_col0, #T_d93d8_row0_col1, #T_d93d8_row0_col2, #T_d93d8_row0_col3, #T_d93d8_row0_col4, #T_d93d8_row0_col5, #T_d93d8_row0_col6, #T_d93d8_row0_col7, #T_d93d8_row0_col8, #T_d93d8_row0_col9, #T_d93d8_row0_col10, #T_d93d8_row0_col11, #T_d93d8_row0_col12, #T_d93d8_row0_col13, #T_d93d8_row0_col14, #T_d93d8_row0_col15, #T_d93d8_row0_col16, #T_d93d8_row0_col17, #T_d93d8_row0_col18, #T_d93d8_row0_col19, #T_d93d8_row0_col20, #T_d93d8_row0_col21, #T_d93d8_row0_col22, #T_d93d8_row0_col23, #T_d93d8_row0_col24, #T_d93d8_row0_col25, #T_d93d8_row0_col26, #T_d93d8_row0_col27, #T_d93d8_row1_col0, #T_d93d8_row1_col1, #T_d93d8_row1_col2, #T_d93d8_row1_col3, #T_d93d8_row1_col4, #T_d93d8_row1_col5, #T_d93d8_row1_col6, #T_d93d8_row1_col7, #T_d93d8_row1_col8, #T_d93d8_row1_col9, #T_d93d8_row1_col10, #T_d93d8_row1_col11, #T_d93d8_row1_col12, #T_d93d8_row1_col13, #T_d93d8_row1_col14, #T_d93d8_row1_col15, #T_d93d8_row1_col16, #T_d93d8_row1_col17, #T_d93d8_row1_col18, #T_d93d8_row1_col19, #T_d93d8_row1_col20, #T_d93d8_row1_col21, #T_d93d8_row1_col22, #T_d93d8_row1_col23, #T_d93d8_row1_col24, #T_d93d8_row1_col25, #T_d93d8_row1_col26, #T_d93d8_row1_col27, #T_d93d8_row2_col0, #T_d93d8_row2_col1, #T_d93d8_row2_col2, #T_d93d8_row2_col3, #T_d93d8_row2_col4, #T_d93d8_row2_col5, #T_d93d8_row2_col6, #T_d93d8_row2_col7, #T_d93d8_row2_col8, #T_d93d8_row2_col9, #T_d93d8_row2_col10, #T_d93d8_row2_col11, #T_d93d8_row2_col12, #T_d93d8_row2_col13, #T_d93d8_row2_col14, #T_d93d8_row2_col15, #T_d93d8_row2_col16, #T_d93d8_row2_col17, #T_d93d8_row2_col18, #T_d93d8_row2_col19, #T_d93d8_row2_col20, #T_d93d8_row2_col21, #T_d93d8_row2_col22, #T_d93d8_row2_col23, #T_d93d8_row2_col24, #T_d93d8_row2_col25, #T_d93d8_row2_col26, #T_d93d8_row2_col27, #T_d93d8_row3_col0, #T_d93d8_row3_col1, #T_d93d8_row3_col2, #T_d93d8_row3_col3, #T_d93d8_row3_col4, #T_d93d8_row3_col5, #T_d93d8_row3_col6, #T_d93d8_row3_col7, #T_d93d8_row3_col8, #T_d93d8_row3_col9, #T_d93d8_row3_col10, #T_d93d8_row3_col11, #T_d93d8_row3_col12, #T_d93d8_row3_col13, #T_d93d8_row3_col14, #T_d93d8_row3_col15, #T_d93d8_row3_col16, #T_d93d8_row3_col17, #T_d93d8_row3_col18, #T_d93d8_row3_col19, #T_d93d8_row3_col20, #T_d93d8_row3_col21, #T_d93d8_row3_col22, #T_d93d8_row3_col23, #T_d93d8_row3_col24, #T_d93d8_row3_col25, #T_d93d8_row3_col26, #T_d93d8_row3_col27, #T_d93d8_row4_col0, #T_d93d8_row4_col1, #T_d93d8_row4_col2, #T_d93d8_row4_col3, #T_d93d8_row4_col4, #T_d93d8_row4_col5, #T_d93d8_row4_col6, #T_d93d8_row4_col7, #T_d93d8_row4_col8, #T_d93d8_row4_col9, #T_d93d8_row4_col10, #T_d93d8_row4_col11, #T_d93d8_row4_col12, #T_d93d8_row4_col13, #T_d93d8_row4_col14, #T_d93d8_row4_col15, #T_d93d8_row4_col16, #T_d93d8_row4_col17, #T_d93d8_row4_col18, #T_d93d8_row4_col19, #T_d93d8_row4_col20, #T_d93d8_row4_col21, #T_d93d8_row4_col22, #T_d93d8_row4_col23, #T_d93d8_row4_col24, #T_d93d8_row4_col25, #T_d93d8_row4_col26, #T_d93d8_row4_col27, #T_d93d8_row5_col0, #T_d93d8_row5_col1, #T_d93d8_row5_col2, #T_d93d8_row5_col3, #T_d93d8_row5_col4, #T_d93d8_row5_col5, #T_d93d8_row5_col6, #T_d93d8_row5_col7, #T_d93d8_row5_col8, #T_d93d8_row5_col19, #T_d93d8_row5_col20, #T_d93d8_row5_col21, #T_d93d8_row5_col22, #T_d93d8_row5_col23, #T_d93d8_row5_col24, #T_d93d8_row5_col25, #T_d93d8_row5_col26, #T_d93d8_row5_col27, #T_d93d8_row6_col0, #T_d93d8_row6_col1, #T_d93d8_row6_col2, #T_d93d8_row6_col3, #T_d93d8_row6_col4, #T_d93d8_row6_col5, #T_d93d8_row6_col6, #T_d93d8_row6_col19, #T_d93d8_row6_col20, #T_d93d8_row6_col21, #T_d93d8_row6_col22, #T_d93d8_row6_col23, #T_d93d8_row6_col24, #T_d93d8_row6_col25, #T_d93d8_row6_col26, #T_d93d8_row6_col27, #T_d93d8_row7_col0, #T_d93d8_row7_col1, #T_d93d8_row7_col2, #T_d93d8_row7_col3, #T_d93d8_row7_col4, #T_d93d8_row7_col19, #T_d93d8_row7_col20, #T_d93d8_row7_col21, #T_d93d8_row7_col22, #T_d93d8_row7_col23, #T_d93d8_row7_col24, #T_d93d8_row7_col25, #T_d93d8_row7_col26, #T_d93d8_row7_col27, #T_d93d8_row8_col0, #T_d93d8_row8_col1, #T_d93d8_row8_col2, #T_d93d8_row8_col3, #T_d93d8_row8_col4, #T_d93d8_row8_col10, #T_d93d8_row8_col11, #T_d93d8_row8_col12, #T_d93d8_row8_col13, #T_d93d8_row8_col14, #T_d93d8_row8_col19, #T_d93d8_row8_col20, #T_d93d8_row8_col21, #T_d93d8_row8_col22, #T_d93d8_row8_col23, #T_d93d8_row8_col24, #T_d93d8_row8_col25, #T_d93d8_row8_col26, #T_d93d8_row8_col27, #T_d93d8_row9_col0, #T_d93d8_row9_col1, #T_d93d8_row9_col2, #T_d93d8_row9_col3, #T_d93d8_row9_col4, #T_d93d8_row9_col9, #T_d93d8_row9_col10, #T_d93d8_row9_col11, #T_d93d8_row9_col12, #T_d93d8_row9_col13, #T_d93d8_row9_col19, #T_d93d8_row9_col20, #T_d93d8_row9_col21, #T_d93d8_row9_col22, #T_d93d8_row9_col23, #T_d93d8_row9_col24, #T_d93d8_row9_col25, #T_d93d8_row9_col26, #T_d93d8_row9_col27, #T_d93d8_row10_col0, #T_d93d8_row10_col1, #T_d93d8_row10_col2, #T_d93d8_row10_col3, #T_d93d8_row10_col4, #T_d93d8_row10_col5, #T_d93d8_row10_col6, #T_d93d8_row10_col7, #T_d93d8_row10_col8, #T_d93d8_row10_col9, #T_d93d8_row10_col10, #T_d93d8_row10_col11, #T_d93d8_row10_col12, #T_d93d8_row10_col13, #T_d93d8_row10_col18, #T_d93d8_row10_col19, #T_d93d8_row10_col20, #T_d93d8_row10_col21, #T_d93d8_row10_col22, #T_d93d8_row10_col23, #T_d93d8_row10_col24, #T_d93d8_row10_col25, #T_d93d8_row10_col26, #T_d93d8_row10_col27, #T_d93d8_row11_col0, #T_d93d8_row11_col1, #T_d93d8_row11_col2, #T_d93d8_row11_col3, #T_d93d8_row11_col4, #T_d93d8_row11_col5, #T_d93d8_row11_col6, #T_d93d8_row11_col7, #T_d93d8_row11_col8, #T_d93d8_row11_col9, #T_d93d8_row11_col10, #T_d93d8_row11_col17, #T_d93d8_row11_col18, #T_d93d8_row11_col19, #T_d93d8_row11_col20, #T_d93d8_row11_col21, #T_d93d8_row11_col22, #T_d93d8_row11_col23, #T_d93d8_row11_col24, #T_d93d8_row11_col25, #T_d93d8_row11_col26, #T_d93d8_row11_col27, #T_d93d8_row12_col0, #T_d93d8_row12_col1, #T_d93d8_row12_col2, #T_d93d8_row12_col3, #T_d93d8_row12_col4, #T_d93d8_row12_col5, #T_d93d8_row12_col6, #T_d93d8_row12_col7, #T_d93d8_row12_col8, #T_d93d8_row12_col17, #T_d93d8_row12_col18, #T_d93d8_row12_col19, #T_d93d8_row12_col20, #T_d93d8_row12_col21, #T_d93d8_row12_col22, #T_d93d8_row12_col23, #T_d93d8_row12_col24, #T_d93d8_row12_col25, #T_d93d8_row12_col26, #T_d93d8_row12_col27, #T_d93d8_row13_col0, #T_d93d8_row13_col1, #T_d93d8_row13_col2, #T_d93d8_row13_col3, #T_d93d8_row13_col4, #T_d93d8_row13_col5, #T_d93d8_row13_col6, #T_d93d8_row13_col7, #T_d93d8_row13_col8, #T_d93d8_row13_col20, #T_d93d8_row13_col21, #T_d93d8_row13_col22, #T_d93d8_row13_col23, #T_d93d8_row13_col24, #T_d93d8_row13_col25, #T_d93d8_row13_col26, #T_d93d8_row13_col27, #T_d93d8_row14_col0, #T_d93d8_row14_col1, #T_d93d8_row14_col2, #T_d93d8_row14_col3, #T_d93d8_row14_col4, #T_d93d8_row14_col5, #T_d93d8_row14_col6, #T_d93d8_row14_col7, #T_d93d8_row14_col8, #T_d93d8_row14_col9, #T_d93d8_row14_col10, #T_d93d8_row14_col21, #T_d93d8_row14_col22, #T_d93d8_row14_col23, #T_d93d8_row14_col24, #T_d93d8_row14_col25, #T_d93d8_row14_col26, #T_d93d8_row14_col27, #T_d93d8_row15_col0, #T_d93d8_row15_col1, #T_d93d8_row15_col2, #T_d93d8_row15_col3, #T_d93d8_row15_col4, #T_d93d8_row15_col5, #T_d93d8_row15_col6, #T_d93d8_row15_col7, #T_d93d8_row15_col8, #T_d93d8_row15_col9, #T_d93d8_row15_col10, #T_d93d8_row15_col11, #T_d93d8_row15_col12, #T_d93d8_row15_col13, #T_d93d8_row15_col21, #T_d93d8_row15_col22, #T_d93d8_row15_col23, #T_d93d8_row15_col24, #T_d93d8_row15_col25, #T_d93d8_row15_col26, #T_d93d8_row15_col27, #T_d93d8_row16_col0, #T_d93d8_row16_col1, #T_d93d8_row16_col2, #T_d93d8_row16_col3, #T_d93d8_row16_col4, #T_d93d8_row16_col5, #T_d93d8_row16_col6, #T_d93d8_row16_col7, #T_d93d8_row16_col8, #T_d93d8_row16_col9, #T_d93d8_row16_col10, #T_d93d8_row16_col11, #T_d93d8_row16_col12, #T_d93d8_row16_col13, #T_d93d8_row16_col14, #T_d93d8_row16_col15, #T_d93d8_row16_col16, #T_d93d8_row16_col21, #T_d93d8_row16_col22, #T_d93d8_row16_col23, #T_d93d8_row16_col24, #T_d93d8_row16_col25, #T_d93d8_row16_col26, #T_d93d8_row16_col27, #T_d93d8_row17_col0, #T_d93d8_row17_col1, #T_d93d8_row17_col2, #T_d93d8_row17_col3, #T_d93d8_row17_col4, #T_d93d8_row17_col5, #T_d93d8_row17_col6, #T_d93d8_row17_col7, #T_d93d8_row17_col8, #T_d93d8_row17_col9, #T_d93d8_row17_col10, #T_d93d8_row17_col11, #T_d93d8_row17_col12, #T_d93d8_row17_col13, #T_d93d8_row17_col14, #T_d93d8_row17_col15, #T_d93d8_row17_col16, #T_d93d8_row17_col21, #T_d93d8_row17_col22, #T_d93d8_row17_col23, #T_d93d8_row17_col24, #T_d93d8_row17_col25, #T_d93d8_row17_col26, #T_d93d8_row17_col27, #T_d93d8_row18_col0, #T_d93d8_row18_col1, #T_d93d8_row18_col2, #T_d93d8_row18_col3, #T_d93d8_row18_col4, #T_d93d8_row18_col5, #T_d93d8_row18_col6, #T_d93d8_row18_col7, #T_d93d8_row18_col8, #T_d93d8_row18_col9, #T_d93d8_row18_col10, #T_d93d8_row18_col11, #T_d93d8_row18_col12, #T_d93d8_row18_col13, #T_d93d8_row18_col14, #T_d93d8_row18_col15, #T_d93d8_row18_col21, #T_d93d8_row18_col22, #T_d93d8_row18_col23, #T_d93d8_row18_col24, #T_d93d8_row18_col25, #T_d93d8_row18_col26, #T_d93d8_row18_col27, #T_d93d8_row19_col0, #T_d93d8_row19_col1, #T_d93d8_row19_col2, #T_d93d8_row19_col3, #T_d93d8_row19_col4, #T_d93d8_row19_col5, #T_d93d8_row19_col6, #T_d93d8_row19_col7, #T_d93d8_row19_col8, #T_d93d8_row19_col9, #T_d93d8_row19_col10, #T_d93d8_row19_col11, #T_d93d8_row19_col12, #T_d93d8_row19_col13, #T_d93d8_row19_col14, #T_d93d8_row19_col21, #T_d93d8_row19_col22, #T_d93d8_row19_col23, #T_d93d8_row19_col24, #T_d93d8_row19_col25, #T_d93d8_row19_col26, #T_d93d8_row19_col27, #T_d93d8_row20_col0, #T_d93d8_row20_col1, #T_d93d8_row20_col2, #T_d93d8_row20_col3, #T_d93d8_row20_col4, #T_d93d8_row20_col5, #T_d93d8_row20_col6, #T_d93d8_row20_col7, #T_d93d8_row20_col8, #T_d93d8_row20_col9, #T_d93d8_row20_col10, #T_d93d8_row20_col11, #T_d93d8_row20_col12, #T_d93d8_row20_col13, #T_d93d8_row20_col20, #T_d93d8_row20_col21, #T_d93d8_row20_col22, #T_d93d8_row20_col23, #T_d93d8_row20_col24, #T_d93d8_row20_col25, #T_d93d8_row20_col26, #T_d93d8_row20_col27, #T_d93d8_row21_col0, #T_d93d8_row21_col1, #T_d93d8_row21_col2, #T_d93d8_row21_col3, #T_d93d8_row21_col4, #T_d93d8_row21_col5, #T_d93d8_row21_col6, #T_d93d8_row21_col7, #T_d93d8_row21_col8, #T_d93d8_row21_col9, #T_d93d8_row21_col10, #T_d93d8_row21_col11, #T_d93d8_row21_col19, #T_d93d8_row21_col20, #T_d93d8_row21_col21, #T_d93d8_row21_col22, #T_d93d8_row21_col23, #T_d93d8_row21_col24, #T_d93d8_row21_col25, #T_d93d8_row21_col26, #T_d93d8_row21_col27, #T_d93d8_row22_col0, #T_d93d8_row22_col1, #T_d93d8_row22_col2, #T_d93d8_row22_col3, #T_d93d8_row22_col4, #T_d93d8_row22_col5, #T_d93d8_row22_col18, #T_d93d8_row22_col19, #T_d93d8_row22_col20, #T_d93d8_row22_col21, #T_d93d8_row22_col22, #T_d93d8_row22_col23, #T_d93d8_row22_col24, #T_d93d8_row22_col25, #T_d93d8_row22_col26, #T_d93d8_row22_col27, #T_d93d8_row23_col0, #T_d93d8_row23_col1, #T_d93d8_row23_col2, #T_d93d8_row23_col3, #T_d93d8_row23_col4, #T_d93d8_row23_col5, #T_d93d8_row23_col16, #T_d93d8_row23_col17, #T_d93d8_row23_col18, #T_d93d8_row23_col19, #T_d93d8_row23_col20, #T_d93d8_row23_col21, #T_d93d8_row23_col22, #T_d93d8_row23_col23, #T_d93d8_row23_col24, #T_d93d8_row23_col25, #T_d93d8_row23_col26, #T_d93d8_row23_col27, #T_d93d8_row24_col0, #T_d93d8_row24_col1, #T_d93d8_row24_col2, #T_d93d8_row24_col3, #T_d93d8_row24_col4, #T_d93d8_row24_col5, #T_d93d8_row24_col14, #T_d93d8_row24_col15, #T_d93d8_row24_col16, #T_d93d8_row24_col17, #T_d93d8_row24_col18, #T_d93d8_row24_col19, #T_d93d8_row24_col20, #T_d93d8_row24_col21, #T_d93d8_row24_col22, #T_d93d8_row24_col23, #T_d93d8_row24_col24, #T_d93d8_row24_col25, #T_d93d8_row24_col26, #T_d93d8_row24_col27, #T_d93d8_row25_col0, #T_d93d8_row25_col1, #T_d93d8_row25_col2, #T_d93d8_row25_col3, #T_d93d8_row25_col4, #T_d93d8_row25_col5, #T_d93d8_row25_col6, #T_d93d8_row25_col7, #T_d93d8_row25_col8, #T_d93d8_row25_col9, #T_d93d8_row25_col10, #T_d93d8_row25_col11, #T_d93d8_row25_col12, #T_d93d8_row25_col13, #T_d93d8_row25_col14, #T_d93d8_row25_col15, #T_d93d8_row25_col16, #T_d93d8_row25_col17, #T_d93d8_row25_col18, #T_d93d8_row25_col19, #T_d93d8_row25_col20, #T_d93d8_row25_col21, #T_d93d8_row25_col22, #T_d93d8_row25_col23, #T_d93d8_row25_col24, #T_d93d8_row25_col25, #T_d93d8_row25_col26, #T_d93d8_row25_col27, #T_d93d8_row26_col0, #T_d93d8_row26_col1, #T_d93d8_row26_col2, #T_d93d8_row26_col3, #T_d93d8_row26_col4, #T_d93d8_row26_col5, #T_d93d8_row26_col6, #T_d93d8_row26_col7, #T_d93d8_row26_col8, #T_d93d8_row26_col9, #T_d93d8_row26_col10, #T_d93d8_row26_col11, #T_d93d8_row26_col12, #T_d93d8_row26_col13, #T_d93d8_row26_col14, #T_d93d8_row26_col15, #T_d93d8_row26_col16, #T_d93d8_row26_col17, #T_d93d8_row26_col18, #T_d93d8_row26_col19, #T_d93d8_row26_col20, #T_d93d8_row26_col21, #T_d93d8_row26_col22, #T_d93d8_row26_col23, #T_d93d8_row26_col24, #T_d93d8_row26_col25, #T_d93d8_row26_col26, #T_d93d8_row26_col27, #T_d93d8_row27_col0, #T_d93d8_row27_col1, #T_d93d8_row27_col2, #T_d93d8_row27_col3, #T_d93d8_row27_col4, #T_d93d8_row27_col5, #T_d93d8_row27_col6, #T_d93d8_row27_col7, #T_d93d8_row27_col8, #T_d93d8_row27_col9, #T_d93d8_row27_col10, #T_d93d8_row27_col11, #T_d93d8_row27_col12, #T_d93d8_row27_col13, #T_d93d8_row27_col14, #T_d93d8_row27_col15, #T_d93d8_row27_col16, #T_d93d8_row27_col17, #T_d93d8_row27_col18, #T_d93d8_row27_col19, #T_d93d8_row27_col20, #T_d93d8_row27_col21, #T_d93d8_row27_col22, #T_d93d8_row27_col23, #T_d93d8_row27_col24, #T_d93d8_row27_col25, #T_d93d8_row27_col26, #T_d93d8_row27_col27 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #ffffff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row5_col9, #T_d93d8_row12_col16 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f1f1f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row5_col10, #T_d93d8_row5_col17 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #7c7c7c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row5_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4a4a4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row5_col12, #T_d93d8_row5_col13, #T_d93d8_row5_col14, #T_d93d8_row6_col10, #T_d93d8_row6_col11, #T_d93d8_row6_col15, #T_d93d8_row6_col16, #T_d93d8_row6_col17, #T_d93d8_row7_col8, #T_d93d8_row7_col16, #T_d93d8_row7_col17, #T_d93d8_row8_col5, #T_d93d8_row8_col6, #T_d93d8_row8_col7, #T_d93d8_row8_col16, #T_d93d8_row8_col17, #T_d93d8_row9_col16, #T_d93d8_row10_col15, #T_d93d8_row13_col15, #T_d93d8_row14_col15, #T_d93d8_row14_col16, #T_d93d8_row14_col17, #T_d93d8_row14_col18, #T_d93d8_row15_col17, #T_d93d8_row15_col18, #T_d93d8_row15_col19, #T_d93d8_row16_col18, #T_d93d8_row16_col19, #T_d93d8_row16_col20, #T_d93d8_row17_col18, #T_d93d8_row17_col19, #T_d93d8_row18_col18, #T_d93d8_row18_col19, #T_d93d8_row19_col17, #T_d93d8_row19_col18, #T_d93d8_row20_col16, #T_d93d8_row20_col17, #T_d93d8_row21_col15, #T_d93d8_row21_col16, #T_d93d8_row23_col7, #T_d93d8_row23_col8, #T_d93d8_row23_col9, #T_d93d8_row23_col10, #T_d93d8_row23_col11, #T_d93d8_row24_col7, #T_d93d8_row24_col8, #T_d93d8_row24_col9, #T_d93d8_row24_col10, #T_d93d8_row24_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row5_col15 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #606060;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row5_col16 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4d4d4d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row5_col18 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #bbbbbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row6_col7, #T_d93d8_row8_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e4e4e4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row6_col8, #T_d93d8_row12_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #6b6b6b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row6_col9, #T_d93d8_row9_col15 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #222222;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row6_col12, #T_d93d8_row6_col18, #T_d93d8_row7_col18, #T_d93d8_row21_col17 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #171717;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row6_col13, #T_d93d8_row7_col15 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4b4b4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row6_col14, #T_d93d8_row11_col14, #T_d93d8_row12_col12, #T_d93d8_row12_col14, #T_d93d8_row13_col12, #T_d93d8_row13_col14, #T_d93d8_row22_col14, #T_d93d8_row23_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #010101;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row7_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #272727;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row7_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #0a0a0a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row7_col7, #T_d93d8_row18_col17 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #050505;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row7_col9, #T_d93d8_row12_col15, #T_d93d8_row14_col19, #T_d93d8_row23_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #545454;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row7_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e6e6e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row7_col11, #T_d93d8_row7_col14, #T_d93d8_row12_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fafafa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row7_col12, #T_d93d8_row15_col14, #T_d93d8_row20_col19 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fbfbfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row7_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fdfdfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row8_col8 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #1b1b1b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row8_col15 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4e4e4e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row8_col18 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #767676;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row9_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fcfcfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row9_col6, #T_d93d8_row9_col7, #T_d93d8_row19_col20 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f6f6f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row9_col8, #T_d93d8_row11_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f8f8f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row9_col14, #T_d93d8_row14_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e8e8e8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row9_col17, #T_d93d8_row10_col16 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #090909;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row9_col18 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #d0d0d0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row10_col14, #T_d93d8_row11_col15, #T_d93d8_row13_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #060606;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row10_col17 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #979797;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row11_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #b6b6b6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row11_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #252525;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row11_col16 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #999999;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row12_col11, #T_d93d8_row22_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #101010;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row12_col13, #T_d93d8_row13_col13, #T_d93d8_row21_col14, #T_d93d8_row22_col13, #T_d93d8_row23_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #020202;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row13_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f7f7f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row13_col11, #T_d93d8_row22_col15 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #030303;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row13_col16 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #181818;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row13_col17 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #303030;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row13_col18 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #a9a9a9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row13_col19 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fefefe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row14_col12, #T_d93d8_row14_col13, #T_d93d8_row20_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #bababa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row14_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #393939;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row14_col20 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #eaeaea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row15_col15 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e2e2e2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row15_col16 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #9f9f9f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row15_col20 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #898989;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row16_col17 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #585858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row17_col17 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #5a5a5a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row17_col20 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #525252;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row18_col16, #T_d93d8_row23_col15 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #c5c5c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row18_col20 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #d7d7d7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row19_col15, #T_d93d8_row22_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #dcdcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row19_col16 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #2f2f2f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row19_col19 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #636363;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row20_col15 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #070707;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row20_col18 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #1f1f1f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row21_col12, #T_d93d8_row22_col6, #T_d93d8_row22_col8 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e9e9e9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row21_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #7d7d7d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row21_col18 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e1e1e1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row22_col7, #T_d93d8_row22_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #a4a4a4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row22_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #727272;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row22_col16 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #616161;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row22_col17 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f3f3f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row23_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #484848;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row24_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #b3b3b3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_d93d8_row24_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #1a1a1a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_d93d8_row24_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #d6d6d6;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d93d8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d93d8_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_d93d8_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_d93d8_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_d93d8_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_d93d8_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
       "      <th id=\"T_d93d8_level0_col5\" class=\"col_heading level0 col5\" >5</th>\n",
       "      <th id=\"T_d93d8_level0_col6\" class=\"col_heading level0 col6\" >6</th>\n",
       "      <th id=\"T_d93d8_level0_col7\" class=\"col_heading level0 col7\" >7</th>\n",
       "      <th id=\"T_d93d8_level0_col8\" class=\"col_heading level0 col8\" >8</th>\n",
       "      <th id=\"T_d93d8_level0_col9\" class=\"col_heading level0 col9\" >9</th>\n",
       "      <th id=\"T_d93d8_level0_col10\" class=\"col_heading level0 col10\" >10</th>\n",
       "      <th id=\"T_d93d8_level0_col11\" class=\"col_heading level0 col11\" >11</th>\n",
       "      <th id=\"T_d93d8_level0_col12\" class=\"col_heading level0 col12\" >12</th>\n",
       "      <th id=\"T_d93d8_level0_col13\" class=\"col_heading level0 col13\" >13</th>\n",
       "      <th id=\"T_d93d8_level0_col14\" class=\"col_heading level0 col14\" >14</th>\n",
       "      <th id=\"T_d93d8_level0_col15\" class=\"col_heading level0 col15\" >15</th>\n",
       "      <th id=\"T_d93d8_level0_col16\" class=\"col_heading level0 col16\" >16</th>\n",
       "      <th id=\"T_d93d8_level0_col17\" class=\"col_heading level0 col17\" >17</th>\n",
       "      <th id=\"T_d93d8_level0_col18\" class=\"col_heading level0 col18\" >18</th>\n",
       "      <th id=\"T_d93d8_level0_col19\" class=\"col_heading level0 col19\" >19</th>\n",
       "      <th id=\"T_d93d8_level0_col20\" class=\"col_heading level0 col20\" >20</th>\n",
       "      <th id=\"T_d93d8_level0_col21\" class=\"col_heading level0 col21\" >21</th>\n",
       "      <th id=\"T_d93d8_level0_col22\" class=\"col_heading level0 col22\" >22</th>\n",
       "      <th id=\"T_d93d8_level0_col23\" class=\"col_heading level0 col23\" >23</th>\n",
       "      <th id=\"T_d93d8_level0_col24\" class=\"col_heading level0 col24\" >24</th>\n",
       "      <th id=\"T_d93d8_level0_col25\" class=\"col_heading level0 col25\" >25</th>\n",
       "      <th id=\"T_d93d8_level0_col26\" class=\"col_heading level0 col26\" >26</th>\n",
       "      <th id=\"T_d93d8_level0_col27\" class=\"col_heading level0 col27\" >27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d93d8_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col6\" class=\"data row0 col6\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col7\" class=\"data row0 col7\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col8\" class=\"data row0 col8\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col9\" class=\"data row0 col9\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col10\" class=\"data row0 col10\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col11\" class=\"data row0 col11\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col12\" class=\"data row0 col12\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col13\" class=\"data row0 col13\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col14\" class=\"data row0 col14\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col15\" class=\"data row0 col15\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col16\" class=\"data row0 col16\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col17\" class=\"data row0 col17\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col18\" class=\"data row0 col18\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col19\" class=\"data row0 col19\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col20\" class=\"data row0 col20\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col21\" class=\"data row0 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col22\" class=\"data row0 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col23\" class=\"data row0 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col24\" class=\"data row0 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col25\" class=\"data row0 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col26\" class=\"data row0 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row0_col27\" class=\"data row0 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d93d8_row1_col0\" class=\"data row1 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col5\" class=\"data row1 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col6\" class=\"data row1 col6\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col7\" class=\"data row1 col7\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col8\" class=\"data row1 col8\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col9\" class=\"data row1 col9\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col10\" class=\"data row1 col10\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col11\" class=\"data row1 col11\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col12\" class=\"data row1 col12\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col13\" class=\"data row1 col13\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col14\" class=\"data row1 col14\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col15\" class=\"data row1 col15\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col16\" class=\"data row1 col16\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col17\" class=\"data row1 col17\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col18\" class=\"data row1 col18\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col19\" class=\"data row1 col19\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col20\" class=\"data row1 col20\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col21\" class=\"data row1 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col22\" class=\"data row1 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col23\" class=\"data row1 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col24\" class=\"data row1 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col25\" class=\"data row1 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col26\" class=\"data row1 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row1_col27\" class=\"data row1 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d93d8_row2_col0\" class=\"data row2 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col3\" class=\"data row2 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col4\" class=\"data row2 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col5\" class=\"data row2 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col6\" class=\"data row2 col6\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col7\" class=\"data row2 col7\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col8\" class=\"data row2 col8\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col9\" class=\"data row2 col9\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col10\" class=\"data row2 col10\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col11\" class=\"data row2 col11\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col12\" class=\"data row2 col12\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col13\" class=\"data row2 col13\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col14\" class=\"data row2 col14\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col15\" class=\"data row2 col15\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col16\" class=\"data row2 col16\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col17\" class=\"data row2 col17\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col18\" class=\"data row2 col18\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col19\" class=\"data row2 col19\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col20\" class=\"data row2 col20\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col21\" class=\"data row2 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col22\" class=\"data row2 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col23\" class=\"data row2 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col24\" class=\"data row2 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col25\" class=\"data row2 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col26\" class=\"data row2 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row2_col27\" class=\"data row2 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d93d8_row3_col0\" class=\"data row3 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col1\" class=\"data row3 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col2\" class=\"data row3 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col3\" class=\"data row3 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col4\" class=\"data row3 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col5\" class=\"data row3 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col6\" class=\"data row3 col6\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col7\" class=\"data row3 col7\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col8\" class=\"data row3 col8\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col9\" class=\"data row3 col9\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col10\" class=\"data row3 col10\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col11\" class=\"data row3 col11\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col12\" class=\"data row3 col12\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col13\" class=\"data row3 col13\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col14\" class=\"data row3 col14\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col15\" class=\"data row3 col15\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col16\" class=\"data row3 col16\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col17\" class=\"data row3 col17\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col18\" class=\"data row3 col18\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col19\" class=\"data row3 col19\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col20\" class=\"data row3 col20\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col21\" class=\"data row3 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col22\" class=\"data row3 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col23\" class=\"data row3 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col24\" class=\"data row3 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col25\" class=\"data row3 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col26\" class=\"data row3 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row3_col27\" class=\"data row3 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d93d8_row4_col0\" class=\"data row4 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col1\" class=\"data row4 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col2\" class=\"data row4 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col3\" class=\"data row4 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col4\" class=\"data row4 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col5\" class=\"data row4 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col6\" class=\"data row4 col6\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col7\" class=\"data row4 col7\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col8\" class=\"data row4 col8\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col9\" class=\"data row4 col9\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col10\" class=\"data row4 col10\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col11\" class=\"data row4 col11\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col12\" class=\"data row4 col12\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col13\" class=\"data row4 col13\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col14\" class=\"data row4 col14\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col15\" class=\"data row4 col15\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col16\" class=\"data row4 col16\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col17\" class=\"data row4 col17\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col18\" class=\"data row4 col18\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col19\" class=\"data row4 col19\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col20\" class=\"data row4 col20\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col21\" class=\"data row4 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col22\" class=\"data row4 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col23\" class=\"data row4 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col24\" class=\"data row4 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col25\" class=\"data row4 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col26\" class=\"data row4 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row4_col27\" class=\"data row4 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_d93d8_row5_col0\" class=\"data row5 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row5_col1\" class=\"data row5 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row5_col2\" class=\"data row5 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row5_col3\" class=\"data row5 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row5_col4\" class=\"data row5 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row5_col5\" class=\"data row5 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row5_col6\" class=\"data row5 col6\" >0</td>\n",
       "      <td id=\"T_d93d8_row5_col7\" class=\"data row5 col7\" >0</td>\n",
       "      <td id=\"T_d93d8_row5_col8\" class=\"data row5 col8\" >0</td>\n",
       "      <td id=\"T_d93d8_row5_col9\" class=\"data row5 col9\" >29</td>\n",
       "      <td id=\"T_d93d8_row5_col10\" class=\"data row5 col10\" >150</td>\n",
       "      <td id=\"T_d93d8_row5_col11\" class=\"data row5 col11\" >195</td>\n",
       "      <td id=\"T_d93d8_row5_col12\" class=\"data row5 col12\" >254</td>\n",
       "      <td id=\"T_d93d8_row5_col13\" class=\"data row5 col13\" >255</td>\n",
       "      <td id=\"T_d93d8_row5_col14\" class=\"data row5 col14\" >254</td>\n",
       "      <td id=\"T_d93d8_row5_col15\" class=\"data row5 col15\" >176</td>\n",
       "      <td id=\"T_d93d8_row5_col16\" class=\"data row5 col16\" >193</td>\n",
       "      <td id=\"T_d93d8_row5_col17\" class=\"data row5 col17\" >150</td>\n",
       "      <td id=\"T_d93d8_row5_col18\" class=\"data row5 col18\" >96</td>\n",
       "      <td id=\"T_d93d8_row5_col19\" class=\"data row5 col19\" >0</td>\n",
       "      <td id=\"T_d93d8_row5_col20\" class=\"data row5 col20\" >0</td>\n",
       "      <td id=\"T_d93d8_row5_col21\" class=\"data row5 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row5_col22\" class=\"data row5 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row5_col23\" class=\"data row5 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row5_col24\" class=\"data row5 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row5_col25\" class=\"data row5 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row5_col26\" class=\"data row5 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row5_col27\" class=\"data row5 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_d93d8_row6_col0\" class=\"data row6 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row6_col1\" class=\"data row6 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row6_col3\" class=\"data row6 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row6_col4\" class=\"data row6 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row6_col5\" class=\"data row6 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row6_col6\" class=\"data row6 col6\" >0</td>\n",
       "      <td id=\"T_d93d8_row6_col7\" class=\"data row6 col7\" >48</td>\n",
       "      <td id=\"T_d93d8_row6_col8\" class=\"data row6 col8\" >166</td>\n",
       "      <td id=\"T_d93d8_row6_col9\" class=\"data row6 col9\" >224</td>\n",
       "      <td id=\"T_d93d8_row6_col10\" class=\"data row6 col10\" >253</td>\n",
       "      <td id=\"T_d93d8_row6_col11\" class=\"data row6 col11\" >253</td>\n",
       "      <td id=\"T_d93d8_row6_col12\" class=\"data row6 col12\" >234</td>\n",
       "      <td id=\"T_d93d8_row6_col13\" class=\"data row6 col13\" >196</td>\n",
       "      <td id=\"T_d93d8_row6_col14\" class=\"data row6 col14\" >253</td>\n",
       "      <td id=\"T_d93d8_row6_col15\" class=\"data row6 col15\" >253</td>\n",
       "      <td id=\"T_d93d8_row6_col16\" class=\"data row6 col16\" >253</td>\n",
       "      <td id=\"T_d93d8_row6_col17\" class=\"data row6 col17\" >253</td>\n",
       "      <td id=\"T_d93d8_row6_col18\" class=\"data row6 col18\" >233</td>\n",
       "      <td id=\"T_d93d8_row6_col19\" class=\"data row6 col19\" >0</td>\n",
       "      <td id=\"T_d93d8_row6_col20\" class=\"data row6 col20\" >0</td>\n",
       "      <td id=\"T_d93d8_row6_col21\" class=\"data row6 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row6_col22\" class=\"data row6 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row6_col23\" class=\"data row6 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row6_col24\" class=\"data row6 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row6_col25\" class=\"data row6 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row6_col26\" class=\"data row6 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row6_col27\" class=\"data row6 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_d93d8_row7_col0\" class=\"data row7 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row7_col1\" class=\"data row7 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row7_col2\" class=\"data row7 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row7_col3\" class=\"data row7 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row7_col4\" class=\"data row7 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row7_col5\" class=\"data row7 col5\" >93</td>\n",
       "      <td id=\"T_d93d8_row7_col6\" class=\"data row7 col6\" >244</td>\n",
       "      <td id=\"T_d93d8_row7_col7\" class=\"data row7 col7\" >249</td>\n",
       "      <td id=\"T_d93d8_row7_col8\" class=\"data row7 col8\" >253</td>\n",
       "      <td id=\"T_d93d8_row7_col9\" class=\"data row7 col9\" >187</td>\n",
       "      <td id=\"T_d93d8_row7_col10\" class=\"data row7 col10\" >46</td>\n",
       "      <td id=\"T_d93d8_row7_col11\" class=\"data row7 col11\" >10</td>\n",
       "      <td id=\"T_d93d8_row7_col12\" class=\"data row7 col12\" >8</td>\n",
       "      <td id=\"T_d93d8_row7_col13\" class=\"data row7 col13\" >4</td>\n",
       "      <td id=\"T_d93d8_row7_col14\" class=\"data row7 col14\" >10</td>\n",
       "      <td id=\"T_d93d8_row7_col15\" class=\"data row7 col15\" >194</td>\n",
       "      <td id=\"T_d93d8_row7_col16\" class=\"data row7 col16\" >253</td>\n",
       "      <td id=\"T_d93d8_row7_col17\" class=\"data row7 col17\" >253</td>\n",
       "      <td id=\"T_d93d8_row7_col18\" class=\"data row7 col18\" >233</td>\n",
       "      <td id=\"T_d93d8_row7_col19\" class=\"data row7 col19\" >0</td>\n",
       "      <td id=\"T_d93d8_row7_col20\" class=\"data row7 col20\" >0</td>\n",
       "      <td id=\"T_d93d8_row7_col21\" class=\"data row7 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row7_col22\" class=\"data row7 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row7_col23\" class=\"data row7 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row7_col24\" class=\"data row7 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row7_col25\" class=\"data row7 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row7_col26\" class=\"data row7 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row7_col27\" class=\"data row7 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_d93d8_row8_col0\" class=\"data row8 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row8_col1\" class=\"data row8 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row8_col2\" class=\"data row8 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row8_col3\" class=\"data row8 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row8_col4\" class=\"data row8 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row8_col5\" class=\"data row8 col5\" >107</td>\n",
       "      <td id=\"T_d93d8_row8_col6\" class=\"data row8 col6\" >253</td>\n",
       "      <td id=\"T_d93d8_row8_col7\" class=\"data row8 col7\" >253</td>\n",
       "      <td id=\"T_d93d8_row8_col8\" class=\"data row8 col8\" >230</td>\n",
       "      <td id=\"T_d93d8_row8_col9\" class=\"data row8 col9\" >48</td>\n",
       "      <td id=\"T_d93d8_row8_col10\" class=\"data row8 col10\" >0</td>\n",
       "      <td id=\"T_d93d8_row8_col11\" class=\"data row8 col11\" >0</td>\n",
       "      <td id=\"T_d93d8_row8_col12\" class=\"data row8 col12\" >0</td>\n",
       "      <td id=\"T_d93d8_row8_col13\" class=\"data row8 col13\" >0</td>\n",
       "      <td id=\"T_d93d8_row8_col14\" class=\"data row8 col14\" >0</td>\n",
       "      <td id=\"T_d93d8_row8_col15\" class=\"data row8 col15\" >192</td>\n",
       "      <td id=\"T_d93d8_row8_col16\" class=\"data row8 col16\" >253</td>\n",
       "      <td id=\"T_d93d8_row8_col17\" class=\"data row8 col17\" >253</td>\n",
       "      <td id=\"T_d93d8_row8_col18\" class=\"data row8 col18\" >156</td>\n",
       "      <td id=\"T_d93d8_row8_col19\" class=\"data row8 col19\" >0</td>\n",
       "      <td id=\"T_d93d8_row8_col20\" class=\"data row8 col20\" >0</td>\n",
       "      <td id=\"T_d93d8_row8_col21\" class=\"data row8 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row8_col22\" class=\"data row8 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row8_col23\" class=\"data row8 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row8_col24\" class=\"data row8 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row8_col25\" class=\"data row8 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row8_col26\" class=\"data row8 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row8_col27\" class=\"data row8 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_d93d8_row9_col0\" class=\"data row9 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row9_col1\" class=\"data row9 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row9_col2\" class=\"data row9 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row9_col3\" class=\"data row9 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row9_col4\" class=\"data row9 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row9_col5\" class=\"data row9 col5\" >3</td>\n",
       "      <td id=\"T_d93d8_row9_col6\" class=\"data row9 col6\" >20</td>\n",
       "      <td id=\"T_d93d8_row9_col7\" class=\"data row9 col7\" >20</td>\n",
       "      <td id=\"T_d93d8_row9_col8\" class=\"data row9 col8\" >15</td>\n",
       "      <td id=\"T_d93d8_row9_col9\" class=\"data row9 col9\" >0</td>\n",
       "      <td id=\"T_d93d8_row9_col10\" class=\"data row9 col10\" >0</td>\n",
       "      <td id=\"T_d93d8_row9_col11\" class=\"data row9 col11\" >0</td>\n",
       "      <td id=\"T_d93d8_row9_col12\" class=\"data row9 col12\" >0</td>\n",
       "      <td id=\"T_d93d8_row9_col13\" class=\"data row9 col13\" >0</td>\n",
       "      <td id=\"T_d93d8_row9_col14\" class=\"data row9 col14\" >43</td>\n",
       "      <td id=\"T_d93d8_row9_col15\" class=\"data row9 col15\" >224</td>\n",
       "      <td id=\"T_d93d8_row9_col16\" class=\"data row9 col16\" >253</td>\n",
       "      <td id=\"T_d93d8_row9_col17\" class=\"data row9 col17\" >245</td>\n",
       "      <td id=\"T_d93d8_row9_col18\" class=\"data row9 col18\" >74</td>\n",
       "      <td id=\"T_d93d8_row9_col19\" class=\"data row9 col19\" >0</td>\n",
       "      <td id=\"T_d93d8_row9_col20\" class=\"data row9 col20\" >0</td>\n",
       "      <td id=\"T_d93d8_row9_col21\" class=\"data row9 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row9_col22\" class=\"data row9 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row9_col23\" class=\"data row9 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row9_col24\" class=\"data row9 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row9_col25\" class=\"data row9 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row9_col26\" class=\"data row9 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row9_col27\" class=\"data row9 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_d93d8_row10_col0\" class=\"data row10 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col1\" class=\"data row10 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col2\" class=\"data row10 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col3\" class=\"data row10 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col4\" class=\"data row10 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col5\" class=\"data row10 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col6\" class=\"data row10 col6\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col7\" class=\"data row10 col7\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col8\" class=\"data row10 col8\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col9\" class=\"data row10 col9\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col10\" class=\"data row10 col10\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col11\" class=\"data row10 col11\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col12\" class=\"data row10 col12\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col13\" class=\"data row10 col13\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col14\" class=\"data row10 col14\" >249</td>\n",
       "      <td id=\"T_d93d8_row10_col15\" class=\"data row10 col15\" >253</td>\n",
       "      <td id=\"T_d93d8_row10_col16\" class=\"data row10 col16\" >245</td>\n",
       "      <td id=\"T_d93d8_row10_col17\" class=\"data row10 col17\" >126</td>\n",
       "      <td id=\"T_d93d8_row10_col18\" class=\"data row10 col18\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col19\" class=\"data row10 col19\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col20\" class=\"data row10 col20\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col21\" class=\"data row10 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col22\" class=\"data row10 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col23\" class=\"data row10 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col24\" class=\"data row10 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col25\" class=\"data row10 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col26\" class=\"data row10 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row10_col27\" class=\"data row10 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_d93d8_row11_col0\" class=\"data row11 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row11_col1\" class=\"data row11 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row11_col2\" class=\"data row11 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row11_col3\" class=\"data row11 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row11_col4\" class=\"data row11 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row11_col5\" class=\"data row11 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row11_col6\" class=\"data row11 col6\" >0</td>\n",
       "      <td id=\"T_d93d8_row11_col7\" class=\"data row11 col7\" >0</td>\n",
       "      <td id=\"T_d93d8_row11_col8\" class=\"data row11 col8\" >0</td>\n",
       "      <td id=\"T_d93d8_row11_col9\" class=\"data row11 col9\" >0</td>\n",
       "      <td id=\"T_d93d8_row11_col10\" class=\"data row11 col10\" >0</td>\n",
       "      <td id=\"T_d93d8_row11_col11\" class=\"data row11 col11\" >14</td>\n",
       "      <td id=\"T_d93d8_row11_col12\" class=\"data row11 col12\" >101</td>\n",
       "      <td id=\"T_d93d8_row11_col13\" class=\"data row11 col13\" >223</td>\n",
       "      <td id=\"T_d93d8_row11_col14\" class=\"data row11 col14\" >253</td>\n",
       "      <td id=\"T_d93d8_row11_col15\" class=\"data row11 col15\" >248</td>\n",
       "      <td id=\"T_d93d8_row11_col16\" class=\"data row11 col16\" >124</td>\n",
       "      <td id=\"T_d93d8_row11_col17\" class=\"data row11 col17\" >0</td>\n",
       "      <td id=\"T_d93d8_row11_col18\" class=\"data row11 col18\" >0</td>\n",
       "      <td id=\"T_d93d8_row11_col19\" class=\"data row11 col19\" >0</td>\n",
       "      <td id=\"T_d93d8_row11_col20\" class=\"data row11 col20\" >0</td>\n",
       "      <td id=\"T_d93d8_row11_col21\" class=\"data row11 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row11_col22\" class=\"data row11 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row11_col23\" class=\"data row11 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row11_col24\" class=\"data row11 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row11_col25\" class=\"data row11 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row11_col26\" class=\"data row11 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row11_col27\" class=\"data row11 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_d93d8_row12_col0\" class=\"data row12 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row12_col1\" class=\"data row12 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row12_col2\" class=\"data row12 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row12_col3\" class=\"data row12 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row12_col4\" class=\"data row12 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row12_col5\" class=\"data row12 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row12_col6\" class=\"data row12 col6\" >0</td>\n",
       "      <td id=\"T_d93d8_row12_col7\" class=\"data row12 col7\" >0</td>\n",
       "      <td id=\"T_d93d8_row12_col8\" class=\"data row12 col8\" >0</td>\n",
       "      <td id=\"T_d93d8_row12_col9\" class=\"data row12 col9\" >11</td>\n",
       "      <td id=\"T_d93d8_row12_col10\" class=\"data row12 col10\" >166</td>\n",
       "      <td id=\"T_d93d8_row12_col11\" class=\"data row12 col11\" >239</td>\n",
       "      <td id=\"T_d93d8_row12_col12\" class=\"data row12 col12\" >253</td>\n",
       "      <td id=\"T_d93d8_row12_col13\" class=\"data row12 col13\" >253</td>\n",
       "      <td id=\"T_d93d8_row12_col14\" class=\"data row12 col14\" >253</td>\n",
       "      <td id=\"T_d93d8_row12_col15\" class=\"data row12 col15\" >187</td>\n",
       "      <td id=\"T_d93d8_row12_col16\" class=\"data row12 col16\" >30</td>\n",
       "      <td id=\"T_d93d8_row12_col17\" class=\"data row12 col17\" >0</td>\n",
       "      <td id=\"T_d93d8_row12_col18\" class=\"data row12 col18\" >0</td>\n",
       "      <td id=\"T_d93d8_row12_col19\" class=\"data row12 col19\" >0</td>\n",
       "      <td id=\"T_d93d8_row12_col20\" class=\"data row12 col20\" >0</td>\n",
       "      <td id=\"T_d93d8_row12_col21\" class=\"data row12 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row12_col22\" class=\"data row12 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row12_col23\" class=\"data row12 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row12_col24\" class=\"data row12 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row12_col25\" class=\"data row12 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row12_col26\" class=\"data row12 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row12_col27\" class=\"data row12 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_d93d8_row13_col0\" class=\"data row13 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row13_col1\" class=\"data row13 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row13_col2\" class=\"data row13 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row13_col3\" class=\"data row13 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row13_col4\" class=\"data row13 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row13_col5\" class=\"data row13 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row13_col6\" class=\"data row13 col6\" >0</td>\n",
       "      <td id=\"T_d93d8_row13_col7\" class=\"data row13 col7\" >0</td>\n",
       "      <td id=\"T_d93d8_row13_col8\" class=\"data row13 col8\" >0</td>\n",
       "      <td id=\"T_d93d8_row13_col9\" class=\"data row13 col9\" >16</td>\n",
       "      <td id=\"T_d93d8_row13_col10\" class=\"data row13 col10\" >248</td>\n",
       "      <td id=\"T_d93d8_row13_col11\" class=\"data row13 col11\" >250</td>\n",
       "      <td id=\"T_d93d8_row13_col12\" class=\"data row13 col12\" >253</td>\n",
       "      <td id=\"T_d93d8_row13_col13\" class=\"data row13 col13\" >253</td>\n",
       "      <td id=\"T_d93d8_row13_col14\" class=\"data row13 col14\" >253</td>\n",
       "      <td id=\"T_d93d8_row13_col15\" class=\"data row13 col15\" >253</td>\n",
       "      <td id=\"T_d93d8_row13_col16\" class=\"data row13 col16\" >232</td>\n",
       "      <td id=\"T_d93d8_row13_col17\" class=\"data row13 col17\" >213</td>\n",
       "      <td id=\"T_d93d8_row13_col18\" class=\"data row13 col18\" >111</td>\n",
       "      <td id=\"T_d93d8_row13_col19\" class=\"data row13 col19\" >2</td>\n",
       "      <td id=\"T_d93d8_row13_col20\" class=\"data row13 col20\" >0</td>\n",
       "      <td id=\"T_d93d8_row13_col21\" class=\"data row13 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row13_col22\" class=\"data row13 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row13_col23\" class=\"data row13 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row13_col24\" class=\"data row13 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row13_col25\" class=\"data row13 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row13_col26\" class=\"data row13 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row13_col27\" class=\"data row13 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_d93d8_row14_col0\" class=\"data row14 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row14_col1\" class=\"data row14 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row14_col2\" class=\"data row14 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row14_col3\" class=\"data row14 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row14_col4\" class=\"data row14 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row14_col5\" class=\"data row14 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row14_col6\" class=\"data row14 col6\" >0</td>\n",
       "      <td id=\"T_d93d8_row14_col7\" class=\"data row14 col7\" >0</td>\n",
       "      <td id=\"T_d93d8_row14_col8\" class=\"data row14 col8\" >0</td>\n",
       "      <td id=\"T_d93d8_row14_col9\" class=\"data row14 col9\" >0</td>\n",
       "      <td id=\"T_d93d8_row14_col10\" class=\"data row14 col10\" >0</td>\n",
       "      <td id=\"T_d93d8_row14_col11\" class=\"data row14 col11\" >43</td>\n",
       "      <td id=\"T_d93d8_row14_col12\" class=\"data row14 col12\" >98</td>\n",
       "      <td id=\"T_d93d8_row14_col13\" class=\"data row14 col13\" >98</td>\n",
       "      <td id=\"T_d93d8_row14_col14\" class=\"data row14 col14\" >208</td>\n",
       "      <td id=\"T_d93d8_row14_col15\" class=\"data row14 col15\" >253</td>\n",
       "      <td id=\"T_d93d8_row14_col16\" class=\"data row14 col16\" >253</td>\n",
       "      <td id=\"T_d93d8_row14_col17\" class=\"data row14 col17\" >253</td>\n",
       "      <td id=\"T_d93d8_row14_col18\" class=\"data row14 col18\" >253</td>\n",
       "      <td id=\"T_d93d8_row14_col19\" class=\"data row14 col19\" >187</td>\n",
       "      <td id=\"T_d93d8_row14_col20\" class=\"data row14 col20\" >22</td>\n",
       "      <td id=\"T_d93d8_row14_col21\" class=\"data row14 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row14_col22\" class=\"data row14 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row14_col23\" class=\"data row14 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row14_col24\" class=\"data row14 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row14_col25\" class=\"data row14 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row14_col26\" class=\"data row14 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row14_col27\" class=\"data row14 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_d93d8_row15_col0\" class=\"data row15 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row15_col1\" class=\"data row15 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row15_col2\" class=\"data row15 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row15_col3\" class=\"data row15 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row15_col4\" class=\"data row15 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row15_col5\" class=\"data row15 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row15_col6\" class=\"data row15 col6\" >0</td>\n",
       "      <td id=\"T_d93d8_row15_col7\" class=\"data row15 col7\" >0</td>\n",
       "      <td id=\"T_d93d8_row15_col8\" class=\"data row15 col8\" >0</td>\n",
       "      <td id=\"T_d93d8_row15_col9\" class=\"data row15 col9\" >0</td>\n",
       "      <td id=\"T_d93d8_row15_col10\" class=\"data row15 col10\" >0</td>\n",
       "      <td id=\"T_d93d8_row15_col11\" class=\"data row15 col11\" >0</td>\n",
       "      <td id=\"T_d93d8_row15_col12\" class=\"data row15 col12\" >0</td>\n",
       "      <td id=\"T_d93d8_row15_col13\" class=\"data row15 col13\" >0</td>\n",
       "      <td id=\"T_d93d8_row15_col14\" class=\"data row15 col14\" >9</td>\n",
       "      <td id=\"T_d93d8_row15_col15\" class=\"data row15 col15\" >51</td>\n",
       "      <td id=\"T_d93d8_row15_col16\" class=\"data row15 col16\" >119</td>\n",
       "      <td id=\"T_d93d8_row15_col17\" class=\"data row15 col17\" >253</td>\n",
       "      <td id=\"T_d93d8_row15_col18\" class=\"data row15 col18\" >253</td>\n",
       "      <td id=\"T_d93d8_row15_col19\" class=\"data row15 col19\" >253</td>\n",
       "      <td id=\"T_d93d8_row15_col20\" class=\"data row15 col20\" >76</td>\n",
       "      <td id=\"T_d93d8_row15_col21\" class=\"data row15 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row15_col22\" class=\"data row15 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row15_col23\" class=\"data row15 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row15_col24\" class=\"data row15 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row15_col25\" class=\"data row15 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row15_col26\" class=\"data row15 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row15_col27\" class=\"data row15 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_d93d8_row16_col0\" class=\"data row16 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row16_col1\" class=\"data row16 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row16_col2\" class=\"data row16 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row16_col3\" class=\"data row16 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row16_col4\" class=\"data row16 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row16_col5\" class=\"data row16 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row16_col6\" class=\"data row16 col6\" >0</td>\n",
       "      <td id=\"T_d93d8_row16_col7\" class=\"data row16 col7\" >0</td>\n",
       "      <td id=\"T_d93d8_row16_col8\" class=\"data row16 col8\" >0</td>\n",
       "      <td id=\"T_d93d8_row16_col9\" class=\"data row16 col9\" >0</td>\n",
       "      <td id=\"T_d93d8_row16_col10\" class=\"data row16 col10\" >0</td>\n",
       "      <td id=\"T_d93d8_row16_col11\" class=\"data row16 col11\" >0</td>\n",
       "      <td id=\"T_d93d8_row16_col12\" class=\"data row16 col12\" >0</td>\n",
       "      <td id=\"T_d93d8_row16_col13\" class=\"data row16 col13\" >0</td>\n",
       "      <td id=\"T_d93d8_row16_col14\" class=\"data row16 col14\" >0</td>\n",
       "      <td id=\"T_d93d8_row16_col15\" class=\"data row16 col15\" >0</td>\n",
       "      <td id=\"T_d93d8_row16_col16\" class=\"data row16 col16\" >1</td>\n",
       "      <td id=\"T_d93d8_row16_col17\" class=\"data row16 col17\" >183</td>\n",
       "      <td id=\"T_d93d8_row16_col18\" class=\"data row16 col18\" >253</td>\n",
       "      <td id=\"T_d93d8_row16_col19\" class=\"data row16 col19\" >253</td>\n",
       "      <td id=\"T_d93d8_row16_col20\" class=\"data row16 col20\" >139</td>\n",
       "      <td id=\"T_d93d8_row16_col21\" class=\"data row16 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row16_col22\" class=\"data row16 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row16_col23\" class=\"data row16 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row16_col24\" class=\"data row16 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row16_col25\" class=\"data row16 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row16_col26\" class=\"data row16 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row16_col27\" class=\"data row16 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_d93d8_row17_col0\" class=\"data row17 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col1\" class=\"data row17 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col2\" class=\"data row17 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col3\" class=\"data row17 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col4\" class=\"data row17 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col5\" class=\"data row17 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col6\" class=\"data row17 col6\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col7\" class=\"data row17 col7\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col8\" class=\"data row17 col8\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col9\" class=\"data row17 col9\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col10\" class=\"data row17 col10\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col11\" class=\"data row17 col11\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col12\" class=\"data row17 col12\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col13\" class=\"data row17 col13\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col14\" class=\"data row17 col14\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col15\" class=\"data row17 col15\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col16\" class=\"data row17 col16\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col17\" class=\"data row17 col17\" >182</td>\n",
       "      <td id=\"T_d93d8_row17_col18\" class=\"data row17 col18\" >253</td>\n",
       "      <td id=\"T_d93d8_row17_col19\" class=\"data row17 col19\" >253</td>\n",
       "      <td id=\"T_d93d8_row17_col20\" class=\"data row17 col20\" >104</td>\n",
       "      <td id=\"T_d93d8_row17_col21\" class=\"data row17 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col22\" class=\"data row17 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col23\" class=\"data row17 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col24\" class=\"data row17 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col25\" class=\"data row17 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col26\" class=\"data row17 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row17_col27\" class=\"data row17 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_d93d8_row18_col0\" class=\"data row18 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row18_col1\" class=\"data row18 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row18_col2\" class=\"data row18 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row18_col3\" class=\"data row18 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row18_col4\" class=\"data row18 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row18_col5\" class=\"data row18 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row18_col6\" class=\"data row18 col6\" >0</td>\n",
       "      <td id=\"T_d93d8_row18_col7\" class=\"data row18 col7\" >0</td>\n",
       "      <td id=\"T_d93d8_row18_col8\" class=\"data row18 col8\" >0</td>\n",
       "      <td id=\"T_d93d8_row18_col9\" class=\"data row18 col9\" >0</td>\n",
       "      <td id=\"T_d93d8_row18_col10\" class=\"data row18 col10\" >0</td>\n",
       "      <td id=\"T_d93d8_row18_col11\" class=\"data row18 col11\" >0</td>\n",
       "      <td id=\"T_d93d8_row18_col12\" class=\"data row18 col12\" >0</td>\n",
       "      <td id=\"T_d93d8_row18_col13\" class=\"data row18 col13\" >0</td>\n",
       "      <td id=\"T_d93d8_row18_col14\" class=\"data row18 col14\" >0</td>\n",
       "      <td id=\"T_d93d8_row18_col15\" class=\"data row18 col15\" >0</td>\n",
       "      <td id=\"T_d93d8_row18_col16\" class=\"data row18 col16\" >85</td>\n",
       "      <td id=\"T_d93d8_row18_col17\" class=\"data row18 col17\" >249</td>\n",
       "      <td id=\"T_d93d8_row18_col18\" class=\"data row18 col18\" >253</td>\n",
       "      <td id=\"T_d93d8_row18_col19\" class=\"data row18 col19\" >253</td>\n",
       "      <td id=\"T_d93d8_row18_col20\" class=\"data row18 col20\" >36</td>\n",
       "      <td id=\"T_d93d8_row18_col21\" class=\"data row18 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row18_col22\" class=\"data row18 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row18_col23\" class=\"data row18 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row18_col24\" class=\"data row18 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row18_col25\" class=\"data row18 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row18_col26\" class=\"data row18 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row18_col27\" class=\"data row18 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_d93d8_row19_col0\" class=\"data row19 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row19_col1\" class=\"data row19 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row19_col2\" class=\"data row19 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row19_col3\" class=\"data row19 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row19_col4\" class=\"data row19 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row19_col5\" class=\"data row19 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row19_col6\" class=\"data row19 col6\" >0</td>\n",
       "      <td id=\"T_d93d8_row19_col7\" class=\"data row19 col7\" >0</td>\n",
       "      <td id=\"T_d93d8_row19_col8\" class=\"data row19 col8\" >0</td>\n",
       "      <td id=\"T_d93d8_row19_col9\" class=\"data row19 col9\" >0</td>\n",
       "      <td id=\"T_d93d8_row19_col10\" class=\"data row19 col10\" >0</td>\n",
       "      <td id=\"T_d93d8_row19_col11\" class=\"data row19 col11\" >0</td>\n",
       "      <td id=\"T_d93d8_row19_col12\" class=\"data row19 col12\" >0</td>\n",
       "      <td id=\"T_d93d8_row19_col13\" class=\"data row19 col13\" >0</td>\n",
       "      <td id=\"T_d93d8_row19_col14\" class=\"data row19 col14\" >0</td>\n",
       "      <td id=\"T_d93d8_row19_col15\" class=\"data row19 col15\" >60</td>\n",
       "      <td id=\"T_d93d8_row19_col16\" class=\"data row19 col16\" >214</td>\n",
       "      <td id=\"T_d93d8_row19_col17\" class=\"data row19 col17\" >253</td>\n",
       "      <td id=\"T_d93d8_row19_col18\" class=\"data row19 col18\" >253</td>\n",
       "      <td id=\"T_d93d8_row19_col19\" class=\"data row19 col19\" >173</td>\n",
       "      <td id=\"T_d93d8_row19_col20\" class=\"data row19 col20\" >11</td>\n",
       "      <td id=\"T_d93d8_row19_col21\" class=\"data row19 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row19_col22\" class=\"data row19 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row19_col23\" class=\"data row19 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row19_col24\" class=\"data row19 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row19_col25\" class=\"data row19 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row19_col26\" class=\"data row19 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row19_col27\" class=\"data row19 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_d93d8_row20_col0\" class=\"data row20 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row20_col1\" class=\"data row20 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row20_col2\" class=\"data row20 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row20_col3\" class=\"data row20 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row20_col4\" class=\"data row20 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row20_col5\" class=\"data row20 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row20_col6\" class=\"data row20 col6\" >0</td>\n",
       "      <td id=\"T_d93d8_row20_col7\" class=\"data row20 col7\" >0</td>\n",
       "      <td id=\"T_d93d8_row20_col8\" class=\"data row20 col8\" >0</td>\n",
       "      <td id=\"T_d93d8_row20_col9\" class=\"data row20 col9\" >0</td>\n",
       "      <td id=\"T_d93d8_row20_col10\" class=\"data row20 col10\" >0</td>\n",
       "      <td id=\"T_d93d8_row20_col11\" class=\"data row20 col11\" >0</td>\n",
       "      <td id=\"T_d93d8_row20_col12\" class=\"data row20 col12\" >0</td>\n",
       "      <td id=\"T_d93d8_row20_col13\" class=\"data row20 col13\" >0</td>\n",
       "      <td id=\"T_d93d8_row20_col14\" class=\"data row20 col14\" >98</td>\n",
       "      <td id=\"T_d93d8_row20_col15\" class=\"data row20 col15\" >247</td>\n",
       "      <td id=\"T_d93d8_row20_col16\" class=\"data row20 col16\" >253</td>\n",
       "      <td id=\"T_d93d8_row20_col17\" class=\"data row20 col17\" >253</td>\n",
       "      <td id=\"T_d93d8_row20_col18\" class=\"data row20 col18\" >226</td>\n",
       "      <td id=\"T_d93d8_row20_col19\" class=\"data row20 col19\" >9</td>\n",
       "      <td id=\"T_d93d8_row20_col20\" class=\"data row20 col20\" >0</td>\n",
       "      <td id=\"T_d93d8_row20_col21\" class=\"data row20 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row20_col22\" class=\"data row20 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row20_col23\" class=\"data row20 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row20_col24\" class=\"data row20 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row20_col25\" class=\"data row20 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row20_col26\" class=\"data row20 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row20_col27\" class=\"data row20 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_d93d8_row21_col0\" class=\"data row21 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row21_col1\" class=\"data row21 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row21_col2\" class=\"data row21 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row21_col3\" class=\"data row21 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row21_col4\" class=\"data row21 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row21_col5\" class=\"data row21 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row21_col6\" class=\"data row21 col6\" >0</td>\n",
       "      <td id=\"T_d93d8_row21_col7\" class=\"data row21 col7\" >0</td>\n",
       "      <td id=\"T_d93d8_row21_col8\" class=\"data row21 col8\" >0</td>\n",
       "      <td id=\"T_d93d8_row21_col9\" class=\"data row21 col9\" >0</td>\n",
       "      <td id=\"T_d93d8_row21_col10\" class=\"data row21 col10\" >0</td>\n",
       "      <td id=\"T_d93d8_row21_col11\" class=\"data row21 col11\" >0</td>\n",
       "      <td id=\"T_d93d8_row21_col12\" class=\"data row21 col12\" >42</td>\n",
       "      <td id=\"T_d93d8_row21_col13\" class=\"data row21 col13\" >150</td>\n",
       "      <td id=\"T_d93d8_row21_col14\" class=\"data row21 col14\" >252</td>\n",
       "      <td id=\"T_d93d8_row21_col15\" class=\"data row21 col15\" >253</td>\n",
       "      <td id=\"T_d93d8_row21_col16\" class=\"data row21 col16\" >253</td>\n",
       "      <td id=\"T_d93d8_row21_col17\" class=\"data row21 col17\" >233</td>\n",
       "      <td id=\"T_d93d8_row21_col18\" class=\"data row21 col18\" >53</td>\n",
       "      <td id=\"T_d93d8_row21_col19\" class=\"data row21 col19\" >0</td>\n",
       "      <td id=\"T_d93d8_row21_col20\" class=\"data row21 col20\" >0</td>\n",
       "      <td id=\"T_d93d8_row21_col21\" class=\"data row21 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row21_col22\" class=\"data row21 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row21_col23\" class=\"data row21 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row21_col24\" class=\"data row21 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row21_col25\" class=\"data row21 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row21_col26\" class=\"data row21 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row21_col27\" class=\"data row21 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_d93d8_row22_col0\" class=\"data row22 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row22_col1\" class=\"data row22 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row22_col2\" class=\"data row22 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row22_col3\" class=\"data row22 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row22_col4\" class=\"data row22 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row22_col5\" class=\"data row22 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row22_col6\" class=\"data row22 col6\" >42</td>\n",
       "      <td id=\"T_d93d8_row22_col7\" class=\"data row22 col7\" >115</td>\n",
       "      <td id=\"T_d93d8_row22_col8\" class=\"data row22 col8\" >42</td>\n",
       "      <td id=\"T_d93d8_row22_col9\" class=\"data row22 col9\" >60</td>\n",
       "      <td id=\"T_d93d8_row22_col10\" class=\"data row22 col10\" >115</td>\n",
       "      <td id=\"T_d93d8_row22_col11\" class=\"data row22 col11\" >159</td>\n",
       "      <td id=\"T_d93d8_row22_col12\" class=\"data row22 col12\" >240</td>\n",
       "      <td id=\"T_d93d8_row22_col13\" class=\"data row22 col13\" >253</td>\n",
       "      <td id=\"T_d93d8_row22_col14\" class=\"data row22 col14\" >253</td>\n",
       "      <td id=\"T_d93d8_row22_col15\" class=\"data row22 col15\" >250</td>\n",
       "      <td id=\"T_d93d8_row22_col16\" class=\"data row22 col16\" >175</td>\n",
       "      <td id=\"T_d93d8_row22_col17\" class=\"data row22 col17\" >25</td>\n",
       "      <td id=\"T_d93d8_row22_col18\" class=\"data row22 col18\" >0</td>\n",
       "      <td id=\"T_d93d8_row22_col19\" class=\"data row22 col19\" >0</td>\n",
       "      <td id=\"T_d93d8_row22_col20\" class=\"data row22 col20\" >0</td>\n",
       "      <td id=\"T_d93d8_row22_col21\" class=\"data row22 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row22_col22\" class=\"data row22 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row22_col23\" class=\"data row22 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row22_col24\" class=\"data row22 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row22_col25\" class=\"data row22 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row22_col26\" class=\"data row22 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row22_col27\" class=\"data row22 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_d93d8_row23_col0\" class=\"data row23 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row23_col1\" class=\"data row23 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row23_col2\" class=\"data row23 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row23_col3\" class=\"data row23 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row23_col4\" class=\"data row23 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row23_col5\" class=\"data row23 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row23_col6\" class=\"data row23 col6\" >187</td>\n",
       "      <td id=\"T_d93d8_row23_col7\" class=\"data row23 col7\" >253</td>\n",
       "      <td id=\"T_d93d8_row23_col8\" class=\"data row23 col8\" >253</td>\n",
       "      <td id=\"T_d93d8_row23_col9\" class=\"data row23 col9\" >253</td>\n",
       "      <td id=\"T_d93d8_row23_col10\" class=\"data row23 col10\" >253</td>\n",
       "      <td id=\"T_d93d8_row23_col11\" class=\"data row23 col11\" >253</td>\n",
       "      <td id=\"T_d93d8_row23_col12\" class=\"data row23 col12\" >253</td>\n",
       "      <td id=\"T_d93d8_row23_col13\" class=\"data row23 col13\" >253</td>\n",
       "      <td id=\"T_d93d8_row23_col14\" class=\"data row23 col14\" >197</td>\n",
       "      <td id=\"T_d93d8_row23_col15\" class=\"data row23 col15\" >86</td>\n",
       "      <td id=\"T_d93d8_row23_col16\" class=\"data row23 col16\" >0</td>\n",
       "      <td id=\"T_d93d8_row23_col17\" class=\"data row23 col17\" >0</td>\n",
       "      <td id=\"T_d93d8_row23_col18\" class=\"data row23 col18\" >0</td>\n",
       "      <td id=\"T_d93d8_row23_col19\" class=\"data row23 col19\" >0</td>\n",
       "      <td id=\"T_d93d8_row23_col20\" class=\"data row23 col20\" >0</td>\n",
       "      <td id=\"T_d93d8_row23_col21\" class=\"data row23 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row23_col22\" class=\"data row23 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row23_col23\" class=\"data row23 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row23_col24\" class=\"data row23 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row23_col25\" class=\"data row23 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row23_col26\" class=\"data row23 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row23_col27\" class=\"data row23 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_d93d8_row24_col0\" class=\"data row24 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row24_col1\" class=\"data row24 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row24_col2\" class=\"data row24 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row24_col3\" class=\"data row24 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row24_col4\" class=\"data row24 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row24_col5\" class=\"data row24 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row24_col6\" class=\"data row24 col6\" >103</td>\n",
       "      <td id=\"T_d93d8_row24_col7\" class=\"data row24 col7\" >253</td>\n",
       "      <td id=\"T_d93d8_row24_col8\" class=\"data row24 col8\" >253</td>\n",
       "      <td id=\"T_d93d8_row24_col9\" class=\"data row24 col9\" >253</td>\n",
       "      <td id=\"T_d93d8_row24_col10\" class=\"data row24 col10\" >253</td>\n",
       "      <td id=\"T_d93d8_row24_col11\" class=\"data row24 col11\" >253</td>\n",
       "      <td id=\"T_d93d8_row24_col12\" class=\"data row24 col12\" >232</td>\n",
       "      <td id=\"T_d93d8_row24_col13\" class=\"data row24 col13\" >67</td>\n",
       "      <td id=\"T_d93d8_row24_col14\" class=\"data row24 col14\" >1</td>\n",
       "      <td id=\"T_d93d8_row24_col15\" class=\"data row24 col15\" >0</td>\n",
       "      <td id=\"T_d93d8_row24_col16\" class=\"data row24 col16\" >0</td>\n",
       "      <td id=\"T_d93d8_row24_col17\" class=\"data row24 col17\" >0</td>\n",
       "      <td id=\"T_d93d8_row24_col18\" class=\"data row24 col18\" >0</td>\n",
       "      <td id=\"T_d93d8_row24_col19\" class=\"data row24 col19\" >0</td>\n",
       "      <td id=\"T_d93d8_row24_col20\" class=\"data row24 col20\" >0</td>\n",
       "      <td id=\"T_d93d8_row24_col21\" class=\"data row24 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row24_col22\" class=\"data row24 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row24_col23\" class=\"data row24 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row24_col24\" class=\"data row24 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row24_col25\" class=\"data row24 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row24_col26\" class=\"data row24 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row24_col27\" class=\"data row24 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_d93d8_row25_col0\" class=\"data row25 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col1\" class=\"data row25 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col2\" class=\"data row25 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col3\" class=\"data row25 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col4\" class=\"data row25 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col5\" class=\"data row25 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col6\" class=\"data row25 col6\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col7\" class=\"data row25 col7\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col8\" class=\"data row25 col8\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col9\" class=\"data row25 col9\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col10\" class=\"data row25 col10\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col11\" class=\"data row25 col11\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col12\" class=\"data row25 col12\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col13\" class=\"data row25 col13\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col14\" class=\"data row25 col14\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col15\" class=\"data row25 col15\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col16\" class=\"data row25 col16\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col17\" class=\"data row25 col17\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col18\" class=\"data row25 col18\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col19\" class=\"data row25 col19\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col20\" class=\"data row25 col20\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col21\" class=\"data row25 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col22\" class=\"data row25 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col23\" class=\"data row25 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col24\" class=\"data row25 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col25\" class=\"data row25 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col26\" class=\"data row25 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row25_col27\" class=\"data row25 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_d93d8_row26_col0\" class=\"data row26 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col1\" class=\"data row26 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col2\" class=\"data row26 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col3\" class=\"data row26 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col4\" class=\"data row26 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col5\" class=\"data row26 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col6\" class=\"data row26 col6\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col7\" class=\"data row26 col7\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col8\" class=\"data row26 col8\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col9\" class=\"data row26 col9\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col10\" class=\"data row26 col10\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col11\" class=\"data row26 col11\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col12\" class=\"data row26 col12\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col13\" class=\"data row26 col13\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col14\" class=\"data row26 col14\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col15\" class=\"data row26 col15\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col16\" class=\"data row26 col16\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col17\" class=\"data row26 col17\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col18\" class=\"data row26 col18\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col19\" class=\"data row26 col19\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col20\" class=\"data row26 col20\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col21\" class=\"data row26 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col22\" class=\"data row26 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col23\" class=\"data row26 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col24\" class=\"data row26 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col25\" class=\"data row26 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col26\" class=\"data row26 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row26_col27\" class=\"data row26 col27\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d93d8_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_d93d8_row27_col0\" class=\"data row27 col0\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col1\" class=\"data row27 col1\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col2\" class=\"data row27 col2\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col3\" class=\"data row27 col3\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col4\" class=\"data row27 col4\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col5\" class=\"data row27 col5\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col6\" class=\"data row27 col6\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col7\" class=\"data row27 col7\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col8\" class=\"data row27 col8\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col9\" class=\"data row27 col9\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col10\" class=\"data row27 col10\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col11\" class=\"data row27 col11\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col12\" class=\"data row27 col12\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col13\" class=\"data row27 col13\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col14\" class=\"data row27 col14\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col15\" class=\"data row27 col15\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col16\" class=\"data row27 col16\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col17\" class=\"data row27 col17\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col18\" class=\"data row27 col18\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col19\" class=\"data row27 col19\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col20\" class=\"data row27 col20\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col21\" class=\"data row27 col21\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col22\" class=\"data row27 col22\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col23\" class=\"data row27 col23\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col24\" class=\"data row27 col24\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col25\" class=\"data row27 col25\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col26\" class=\"data row27 col26\" >0</td>\n",
       "      <td id=\"T_d93d8_row27_col27\" class=\"data row27 col27\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a2f7d53d90>"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im3_t = tensor(im3)\n",
    "df = pd.DataFrame(im3_t)\n",
    "df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b92d438-8d33-457a-8a1b-23c5dacdeb73",
   "metadata": {},
   "source": [
    "### Baselines\n",
    "\n",
    "At this moment, before we dive into deep learning our way to victory, the book introduces baseline solutions. I think this is an important concept that I commonly fail to try when starting a data science problem, instead of implementing a solution immedietly that has the following attributes:\n",
    " - Simple\n",
    " - Perform Reasonably Well\n",
    " - Easy to Test\n",
    " \n",
    "I usually get stuck way in the weeds of trying to do something hard an don't end up with a useful output. Lets instead build a baseline for the key reasons the book mentions, you can test your new ideas to see if they are better than your baseline which can be implented almost instantly. You can either try a simple / naive idea or copy down someone elses already implemented solution so you have a starting point for your problem.\n",
    "\n",
    "Lets follow the book example of simply averaging all the pixels of threes and sevens which might yeild an 'ideal' seven or three value. Also this little list making magic is called \"List Comprehension\" and similar to one line methods, it gives you a great way of creating lists in one line.[The python docs are excellent](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions) and I recommend a read through if you haven't seen this before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "57f4ce3e-f93c-47a8-be92-f670cecdd76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6131, 6265)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "len(three_tensors), len(seven_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc107c1-c724-48b9-a7fb-0b6eda496c7f",
   "metadata": {},
   "source": [
    "Lets check if our tensors got built properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "e147809f-1d1b-47d1-9e5e-48b1748536fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  29, 150, 195, 254, 255, 254, 176, 193, 150,  96,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  48, 166, 224, 253, 253, 234, 196, 253, 253, 253, 253, 233,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,  93, 244, 249, 253, 187,  46,  10,   8,   4,  10, 194, 253, 253, 233,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0, 107, 253, 253, 230,  48,   0,   0,   0,   0,   0, 192, 253, 253, 156,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   3,  20,  20,  15,   0,   0,   0,   0,   0,  43, 224, 253, 245,  74,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249, 253, 245, 126,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  14, 101, 223, 253, 248, 124,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 166, 239, 253, 253, 253, 187,  30,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  16, 248, 250, 253, 253, 253, 253, 232, 213, 111,   2,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  43,  98,  98, 208, 253, 253, 253, 253, 187,  22,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   9,  51, 119, 253, 253, 253,  76,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1, 183, 253, 253, 139,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 182, 253, 253, 104,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  85, 249, 253, 253,  36,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  60, 214, 253, 253, 173,  11,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  98, 247, 253, 253, 226,   9,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  42, 150, 252, 253, 253, 233,  53,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  42, 115,  42,  60, 115, 159, 240, 253, 253, 250, 175,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0, 187, 253, 253, 253, 253, 253, 253, 253, 197,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0, 103, 253, 253, 253, 253, 253, 232,  67,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_tensors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "e6066682-c597-48a1-b902-a83ce1a894fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(three_tensors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a8e13d-4c52-4e6d-944e-accdf172315c",
   "metadata": {},
   "source": [
    "Looks good to me, certainly looks modified from our original image but the actual tensor itself on the cell before looks correct so I'm going to roll with it.\n",
    "\n",
    "### Rank-3 Tensors\n",
    "\n",
    "Now is where we start to get a little freaky, we're going to make a rank 3 tensor which you can think of as having 3 'dimensions'. Currently we have a long list of tensors, ie we have a list and each element is a tensor, we can index into the list elements and then into any subset of the pixels of that tensor. We're going to now 'stack' all the list elements into its own dimension so that we have 3 dimensions to index through, instead of one dimension (the list) which then contains the tensors. It should mentally feel like a 'cube' of stacked tensors, where we can slide depth-wise through to each image, and horizontally or vertically to scan within an image.\n",
    "\n",
    "Pytorch has the lovely method stack() which lets us achieve this, we will then convert everything to a float and divide by 255 as usually images have expected values between 0 and 1 if they're floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "f9c7d37a-3d67-4ad4-9604-649bc0d3e2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6131, 28, 28])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "stacked_threes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5728a5-e23c-4e15-8867-a5c95b8e4dbd",
   "metadata": {},
   "source": [
    "See how we have our 6131 images, each with 28x28 pixels, whereas our threes is a list with an individual element containing a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "b25918eb-8377-4ab3-9c85-88312e8566a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6131, torch.Size([28, 28]), 6131)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(three_tensors), three_tensors[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67ca622-3324-4a3a-a22e-0debb5760bcd",
   "metadata": {},
   "source": [
    "Also note that the length of a tensors shape is its 'rank' or how many axes/dimensions it has. The 'ndim' attribute also gives you the same answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "bceb39ea-6dad-4038-9696-a2b2a76dfa51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stacked_threes.shape), stacked_threes.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555261f1-5a65-4803-a93e-f65436cef0e8",
   "metadata": {},
   "source": [
    "Lets now implement that baseline and average all the tensors and show the image to see what 'ideal' looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "6f081dee-3512-442d-ac08-59475aee3733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "me3 = stacked_threes.mean(0)\n",
    "show_image(me3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef344704-af20-48d3-8af3-c99c4810c6b5",
   "metadata": {},
   "source": [
    "Objectively a 'pretty' three if I don't say so myself. Credit to fastai's top tier joke in their book : \"You may not like it, but this is what peak 3 performance looks like\". We've gotta find joy in these sorts of things given the world.\n",
    "\n",
    "Lets checkout 7 as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "655bb71b-682e-4af4-9667-ade490ca7343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "me7 = stacked_sevens.mean(0)\n",
    "show_image(me7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d152e11e-baa9-4f7b-beac-772f8ec1d219",
   "metadata": {},
   "source": [
    "### Measuring Loss\n",
    "\n",
    "Ok so we have our ideal three and ideal seven, we now want to compare any three or seven to the ideal seven or three and whichever category has the smallest loss is most likely the category for the sample we've picked. Some common data science methods for loss functions are the mean absolute difference, also known as the *L1 norm*, or we could square the differences and take that distance, which would be the *L2 norm*.\n",
    "\n",
    "Lets calculate both of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "731f9f1c-792c-47d4-bacd-d2ecbdb6bfa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1114), tensor(0.2021))"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_3 = stacked_threes[1]\n",
    "\n",
    "# Distance of our sample from our mean three or 'ideal 3'\n",
    "error = sample_3 - me3\n",
    "\n",
    "three_abs_dist = error.abs().mean()\n",
    "three_square_dist = (error**2).mean().sqrt()\n",
    "\n",
    "three_abs_dist, three_square_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3fbc9d-321e-4077-a65f-ffbc327ce6e1",
   "metadata": {},
   "source": [
    "How cool that we can just take away a tensor from another and pytorch does the magic, really nice syntax! Lets have a quick look at the actual error tensor too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a7e6b8-f365-44e9-8cf1-7faa5430d9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -7.2918e-05, -1.9637e-04, -2.3410e-04, -1.9253e-04,\n",
       "         -2.7568e-04, -2.6161e-04, -2.9423e-04, -2.8400e-04, -1.5671e-04, -4.8612e-05, -5.7567e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.5991e-05, -4.8676e-04, -7.7331e-04, -1.4468e-03, -2.9788e-03, -5.6486e-03, -9.5177e-03, -1.5693e-02, -2.1113e-02, -2.4280e-02,\n",
       "         -2.5964e-02, -2.4268e-02, -2.0875e-02, -1.7108e-02, -1.1642e-02, -7.0436e-03, -3.9945e-03, -1.4955e-03, -3.2941e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00, -2.4306e-05, -3.2621e-05, -1.5607e-04, -1.3995e-03, -5.7854e-03, -1.3664e-02, -3.0111e-02, -5.5401e-02, -9.0316e-02, -1.3725e-01, -1.8357e-01, -2.2128e-01, -2.4655e-01,\n",
       "         -2.4972e-01, -2.3536e-01, -1.9872e-01, -1.5084e-01, -1.0543e-01, -6.4754e-02, -3.2829e-02, -1.3352e-02, -4.5970e-03, -3.9273e-04, -1.9189e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00, -5.7567e-05, -1.5204e-03, -8.8909e-03, -2.7837e-02, -6.1064e-02, -1.1271e-01, -1.8688e-01, -1.6652e-01,  2.0526e-01,  2.8446e-01,  4.3731e-01,  3.8676e-01,\n",
       "          3.7279e-01,  9.2483e-02,  2.2852e-01,  1.6724e-01,  7.0714e-02, -2.0347e-01, -1.1742e-01, -5.3793e-02, -1.6992e-02, -3.4617e-03, -2.5905e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00, -7.0359e-06, -3.0063e-04, -5.8174e-03, -2.4498e-02, -5.9899e-02, -1.2038e-01, -1.9312e-02,  3.3159e-01,  4.4296e-01,  4.4769e-01,  3.6452e-01,  2.3261e-01,  4.4678e-02,\n",
       "          2.4727e-01,  2.4753e-01,  2.8715e-01,  3.8341e-01,  4.3456e-01, -3.3949e-01, -2.1322e-01, -1.0868e-01, -3.7335e-02, -7.9084e-03, -8.2320e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00, -3.2429e-04, -4.5414e-04, -9.7409e-03, -3.7895e-02,  2.8178e-01,  8.0304e-01,  7.3490e-01,  6.5449e-01,  3.0652e-01, -3.1122e-01, -4.8920e-01, -5.1338e-01, -5.4314e-01,\n",
       "         -5.4719e-01,  1.3328e-01,  3.4090e-01,  3.7103e-01,  3.8523e-01, -4.0753e-01, -2.7025e-01, -1.4412e-01, -5.3465e-02, -1.1405e-02, -1.0490e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.2601e-04, -5.3985e-04, -1.1943e-02, -4.0899e-02,  3.4083e-01,  8.5773e-01,  7.9759e-01,  6.5122e-01, -1.0665e-01, -3.1693e-01, -3.1747e-01, -3.1133e-01, -3.2182e-01,\n",
       "         -3.6634e-01,  3.0088e-01,  4.5456e-01,  4.2148e-01,  8.5761e-02, -4.1737e-01, -2.7770e-01, -1.4791e-01, -5.6850e-02, -1.1186e-02, -5.6543e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.3496e-04, -6.4603e-04, -9.1461e-03, -2.9371e-02, -4.3204e-02, -1.1050e-02, -4.1118e-02, -8.2909e-02, -1.5585e-01, -1.6174e-01, -1.6148e-01, -1.6958e-01, -2.0584e-01,\n",
       "         -1.2349e-01,  4.5972e-01,  4.6169e-01,  3.8632e-01, -2.2679e-01, -3.8845e-01, -2.4350e-01, -1.1984e-01, -4.4328e-02, -8.7073e-03, -1.1641e-04, -3.9657e-05,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00, -6.7161e-05, -4.3047e-04, -6.7775e-03, -1.6751e-02, -2.9374e-02, -4.5093e-02, -5.7854e-02, -6.8061e-02, -7.8151e-02, -9.5189e-02, -1.2533e-01, -1.8025e-01, -2.7419e-01,\n",
       "          5.7379e-01,  4.5862e-01,  3.4705e-01, -1.0244e-01, -4.7979e-01, -3.2004e-01, -1.7885e-01, -7.7661e-02, -2.4957e-02, -4.6878e-03, -3.9657e-05, -1.1833e-04,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00, -4.9251e-05, -3.7035e-04, -3.8589e-03, -8.8301e-03, -1.4541e-02, -2.0740e-02, -2.9064e-02, -4.4311e-02, -7.7774e-02, -1.3957e-01, -1.7820e-01,  4.0984e-02,  3.8579e-01,\n",
       "          3.8228e-01,  2.8562e-01, -1.9648e-01, -5.8363e-01, -4.1155e-01, -2.4346e-01, -1.1769e-01, -4.1552e-02, -1.0649e-02, -1.8121e-03, -9.5944e-06, -1.2857e-04,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00, -8.3152e-06, -4.9891e-05, -1.5166e-03, -4.1403e-03, -8.1841e-03, -1.3161e-02, -2.7825e-02, -6.6674e-02, -1.0544e-01,  3.7335e-01,  5.0240e-01,  4.0856e-01,  2.8931e-01,\n",
       "          2.2066e-01, -4.3275e-02, -5.9397e-01, -5.6779e-01, -3.7920e-01, -2.1411e-01, -9.4611e-02, -3.1342e-02, -7.7146e-03, -1.0701e-03, -9.9782e-05, -1.3560e-04,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -6.3963e-04, -2.5783e-03, -5.4042e-03, -1.4138e-02, -3.9151e-02, -1.0502e-01, -1.6365e-01,  5.7815e-01,  4.1466e-01,  2.9369e-01,  2.2497e-01,\n",
       "          2.1266e-01,  2.4135e-01,  2.1742e-01,  2.5263e-01,  2.5055e-03, -2.5765e-01, -1.2995e-01, -5.0904e-02, -1.3723e-02, -2.6148e-03, -3.2749e-04, -6.7161e-05,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.0234e-04, -5.8206e-05, -6.9975e-04, -2.5758e-03, -6.5549e-03, -1.5612e-02, -4.5825e-02, -1.1788e-01, -2.4133e-01, -3.9015e-01, -3.5296e-01, -2.1834e-01, -2.4438e-01,\n",
       "          1.8811e-01,  3.7491e-01,  3.7905e-01,  3.9943e-01,  4.7672e-01,  3.6268e-01, -1.2452e-01, -9.5741e-02, -3.1867e-02, -7.1351e-03, -7.5860e-04, -2.6225e-05,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.4456e-04, -7.1702e-04, -2.3385e-03, -6.0221e-03, -1.1625e-02, -1.9489e-02, -4.1298e-02, -9.1916e-02, -1.7655e-01, -2.7350e-01, -3.4554e-01, -3.7789e-01, -3.8353e-01,\n",
       "         -3.5299e-01, -2.1357e-01, -6.0592e-03,  4.4523e-01,  4.3521e-01,  5.3212e-01,  1.2486e-03, -1.4911e-01, -6.0777e-02, -1.5610e-02, -1.8025e-03, -3.1981e-06, -1.3368e-04,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.2729e-04, -2.1869e-03, -7.0538e-03, -1.4894e-02, -2.2301e-02, -2.7903e-02, -3.9338e-02, -6.2386e-02, -9.9441e-02, -1.3370e-01, -1.5925e-01, -1.6655e-01, -1.7223e-01,\n",
       "         -1.9161e-01, -2.4334e-01, -3.4062e-01,  2.3549e-01,  4.3115e-01,  4.8852e-01,  1.9305e-01, -1.9422e-01, -8.5188e-02, -2.6331e-02, -3.5276e-03, -1.2793e-06, -2.2387e-05,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.5735e-04, -3.3331e-03, -1.5257e-02, -3.1764e-02, -4.3270e-02, -4.9365e-02, -5.5510e-02, -5.9109e-02, -5.8848e-02, -6.1369e-02, -6.3137e-02, -6.5532e-02, -7.3339e-02,\n",
       "         -9.8233e-02, -1.6722e-01, -2.9171e-01,  2.6120e-01,  4.4182e-01,  4.7753e-01,  3.9084e-02, -2.1820e-01, -1.0305e-01, -3.3861e-02, -3.8557e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00, -1.6183e-04, -5.7592e-03, -2.7754e-02, -5.8420e-02, -8.2884e-02, -9.7888e-02, -1.0189e-01, -9.3467e-02, -7.5450e-02, -6.1778e-02, -5.2316e-02, -4.8228e-02, -5.6958e-02,\n",
       "         -9.1961e-02, -1.8154e-01,  6.6285e-03,  4.9858e-01,  4.3616e-01,  4.8286e-01, -2.2319e-01, -2.2059e-01, -1.0743e-01, -3.3211e-02, -3.2410e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00, -2.5521e-04, -9.1678e-03, -4.0289e-02, -8.8192e-02, -1.3721e-01, -1.6905e-01, -1.8232e-01, -1.7508e-01, -1.5029e-01, -1.2213e-01, -9.8687e-02, -9.3244e-02, -1.1323e-01,\n",
       "         -1.7340e-01, -4.8909e-02,  4.0845e-01,  4.4406e-01,  4.2163e-01,  1.9182e-01, -2.9473e-01, -2.0005e-01, -9.1660e-02, -2.4017e-02, -2.2828e-03, -1.3432e-05,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00, -4.6565e-04, -1.0415e-02, -4.8182e-02, -1.0872e-01, -1.8070e-01, -2.4184e-01, -2.8666e-01, -3.0795e-01, -2.9331e-01, -2.6096e-01, -2.3568e-01, -2.3487e-01, -2.7473e-01,\n",
       "          2.7691e-02,  5.0206e-01,  4.1990e-01,  3.8080e-01,  3.2576e-01, -3.9259e-01, -2.7981e-01, -1.5136e-01, -6.0435e-02, -1.3841e-02, -1.2274e-03, -1.3432e-05, -4.9891e-05,  0.0000e+00],\n",
       "        [ 0.0000e+00, -3.6267e-04, -8.7373e-03, -4.1436e-02, -1.0026e-01, -1.8489e-01, -2.8464e-01, -3.7627e-01, -4.4899e-01, -4.7922e-01, -4.8200e-01, -4.7516e-01, -3.2371e-01,  5.6965e-02,\n",
       "          3.9496e-01,  3.4219e-01,  3.2950e-01,  3.1291e-01, -2.6664e-01, -3.2416e-01, -1.8824e-01, -8.8396e-02, -2.8767e-02, -5.4074e-03, -3.2621e-04,  0.0000e+00, -2.1108e-05,  0.0000e+00],\n",
       "        [ 0.0000e+00, -3.1342e-05, -6.0810e-03, -2.7270e-02, -7.3331e-02, -1.4404e-01, -8.7192e-02,  7.5923e-02, -3.3149e-01, -3.5953e-01, -2.0684e-01, -7.1398e-02,  2.2434e-01,  2.6375e-01,\n",
       "          2.6977e-01,  2.9832e-01,  9.5725e-02, -3.6142e-01, -3.1460e-01, -1.8711e-01, -9.4876e-02, -3.7261e-02, -1.0511e-02, -1.6490e-03, -3.5180e-05,  0.0000e+00, -3.1981e-06,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00, -2.3519e-03, -1.2594e-02, -3.9571e-02, -8.3350e-02,  5.7661e-01,  7.3441e-01,  6.1806e-01,  5.0478e-01,  4.0935e-01,  3.4702e-01,  3.2860e-01,  3.4968e-01,\n",
       "          1.9891e-01, -1.3607e-01, -3.5329e-01, -2.3856e-01, -1.4426e-01, -7.5467e-02, -3.0740e-02, -9.7691e-03, -2.4229e-03, -3.6651e-04, -1.4839e-04, -7.6756e-06, -5.1810e-05,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00, -5.4113e-04, -3.9555e-03, -1.3458e-02, -3.0013e-02,  3.4555e-01,  8.9429e-01,  8.4398e-01,  7.8813e-01,  7.3904e-01,  7.0413e-01,  6.1626e-01, -1.3560e-02,\n",
       "         -2.2647e-01, -1.7364e-01, -1.1796e-01, -7.1760e-02, -3.6760e-02, -1.6373e-02, -5.7541e-03, -2.0769e-03, -6.1021e-04, -1.2153e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00, -3.7099e-05, -1.2473e-04, -1.2447e-03, -3.0402e-03, -6.6873e-03, -1.1371e-02, -1.8533e-02, -2.5284e-02, -3.1993e-02, -3.5295e-02, -3.6504e-02, -3.4298e-02,\n",
       "         -2.8593e-02, -2.1875e-02, -1.5417e-02, -9.1748e-03, -5.0454e-03, -2.8687e-03, -1.1430e-03, -4.5350e-04, -2.1683e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0234e-05, -8.0593e-05, -1.6630e-04, -3.6459e-04, -4.0041e-04, -5.1362e-04, -7.4325e-04, -9.5497e-04, -1.0643e-03, -1.3560e-03,\n",
       "         -1.0484e-03, -8.3855e-04, -1.0260e-03, -9.5497e-04, -7.4645e-04, -5.3793e-04, -3.6523e-04, -1.9637e-04, -2.8783e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dcfbed-2cc0-44f9-bf24-be73bdbb99b9",
   "metadata": {},
   "source": [
    "Ok super messy, not exactly legible but you can see how the absolute bottom rows and top rows have no loss since they're simply empty so our sample three is actual 'ideal' in those pixels but there's loss everywhere else.\n",
    "\n",
    "Lets do sevens now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "59831b3d-b668-46df-b658-5abbd04214ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1586), tensor(0.3021))"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distance of our sample from our mean three or 'ideal 3'\n",
    "error = sample_3 - me7\n",
    "\n",
    "seven_abs_dist = error.abs().mean()\n",
    "seven_square_dist = (error**2).mean().sqrt()\n",
    "\n",
    "seven_abs_dist, seven_square_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a65e3a4-157c-47ef-9049-c9f73d451177",
   "metadata": {},
   "source": [
    "In both the L1 and L2 losses, our sample 3 has a smaller loss compared to our ideal three so we'd correctly categorise it in this situation.\n",
    "\n",
    "Pytorch has both of these loss functions out of the box from the 'torch.nn.functional' modules so we don't need to handwrite out these functions in the future, its also stylistic to import this module as \"F\". I've seen this done with pyspark and some other libraries, seems like a nice habit when importing a library/package which is meant to represent math like 'functions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "c44ae4c4-ef59-45e2-8421-bafddae2edc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1586), tensor(0.3021))"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "F.l1_loss(sample_3.float(),me7), F.mse_loss(sample_3, me7).sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd9d4c0-b4a1-41ac-972e-2ee3a76e4410",
   "metadata": {},
   "source": [
    "Voila! The loss is the same, looks like our handwritten work aint too bad, just messy and I can safely depend on pytorch to calculate it correctly instead of me mis-writing this calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2be3bc7-6984-401c-887e-d08e395911cf",
   "metadata": {},
   "source": [
    "### Building Training and Validation Datasets\n",
    "\n",
    "Ok so we've built our baseline loss and predictive method, however we're not training any components and we're not holding out a portion of our data to make sure we're not over-fitting. The MNIST dataset has already been split for us so lets simple setup those tensors using the pre-split data sets. Building a good validation set is however a really important part of the process and [Rachel Thomas's post explains it best](https://www.fast.ai/posts/2017-11-13-validation-sets.html), go read this post for better words than I'll be able to put together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "0edc6b64-cbbe-47fc-8baa-5e1ee30b0371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('../data/MNIST/mnist_sample/labels.csv'),Path('../data/MNIST/mnist_sample/train'),Path('../data/MNIST/mnist_sample/valid')]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "90d96fcc-a19d-470b-bce1-b8be1da997e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_3 = torch.stack([tensor(Image.open(o)) for o in (sample_path/\"valid/3\").ls()])\n",
    "valid_3 = valid_3.float()/255\n",
    "\n",
    "valid_7 = torch.stack([tensor(Image.open(o)) for o in (sample_path/\"valid/7\").ls()])\n",
    "valid_7 = valid_7.float()/255\n",
    "\n",
    "valid_3.shape, valid_7.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e165bff-2394-400e-b3dc-f0616db3c2cd",
   "metadata": {},
   "source": [
    "Lets now calculate the loss for all our threes in the validation set against our 'ideal' three"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ef9a88-3677-4931-8a79-aace21189a84",
   "metadata": {},
   "source": [
    "### Broadcasting Tensors and Loss Functions\n",
    "\n",
    "When pytorch encounters a function between two tensors of different ranks, it will broadcast the smaller ranked tensor to match and have the same size as the larger tensor. [Pytorch's broadcast semantics](https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics) has a decent description of what they're doing, it [appears to be a numpy concept which is well documented here](https://numpy.org/devdocs/user/basics.broadcasting.html#general-broadcasting-rules).\n",
    "\n",
    "We're going to use this with our loss functions since even though we're giving the function a single example, its going to broadcast it 1,010 times to match the 'depth' of our validation tensor. This allows us to compute these sorts of things on the GPU instead of CPU which makes it lightning fast in comparison, torch also does smart things like not allocating extra memory and simply pretending like its of the proper rank without the wasted duplication. Often this will happen in the background and you don't have to explicitly write the broadcasting which makes it simple to write mentally and understand, love your work pytorch gang!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "c3228e20-2dc8-43f0-8eca-ed907e97849e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1114)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mnist_distance(a,b): return (a-b).abs().mean((-1,-2))\n",
    "\n",
    "mnist_distance(sample_3, me3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed515126-2820-430a-9c92-a1089d3a67c1",
   "metadata": {},
   "source": [
    "There is one important difference here in that we're calling mean() with a tuple of (-1,-2) which we didn't do before. In python you can index with a '-' simple to represent 'from the last index', meaning that we want to calculate the mean from the last, and second last indexes of the tensor, being the two axes of 28x28 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "47f95da6-111d-4a4d-99b8-d6934c6d569d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1280, 0.1623, 0.1242,  ..., 0.1508, 0.1263, 0.1260]),\n",
       " torch.Size([1010]))"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_3_dist = mnist_distance(valid_3, me3)\n",
    "valid_3_dist, valid_3_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "13262c5d-f62e-4882-94ec-2af91de41702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1010, 28, 28])"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(valid_3-me3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94177491-b79d-41d8-a36b-93affc5db037",
   "metadata": {},
   "source": [
    "Awesome, we've got all our ducks in a row, now lets write a function to tell if a sample given is a three or not, ie is the distance smaller from the ideal three or ideal seven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "215c3648-3455-4cf7-94fc-f0f41f63a7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), tensor(1.))"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_3(x): return mnist_distance(x,me3) < mnist_distance(x,me7)\n",
    "\n",
    "is_3(sample_3), is_3(sample_3).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d40831-4107-4bc6-8cb4-8f408ceb1213",
   "metadata": {},
   "source": [
    "Looks good, lets now calculate over all our validation threes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "271c6981-6861-4923-a76b-bcf30392fcbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  ..., False,  True,  True])"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_3(valid_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3988bd1f-864e-46a8-9b83-98bb585a1aa7",
   "metadata": {},
   "source": [
    "Uh oh, I see some errors already, lets check the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "20d7379d-2475-44fe-9dc9-ffff4e909b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_3 = is_3(valid_3).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9587a0ea-e207-4a1b-98a9-0cadc39b373e",
   "metadata": {},
   "source": [
    "Now to calculate whether something is a seven, it should just be the inverse of whether its a three. We can do this two ways, either by calculating '1-' our is_3() function or we can use the python 'unary' or 'invert' operator '~' tilde which allows us to invert an operation. I would argue 1- is easier to read since the unary operator isn't very common and to be honest it can be easy to miss or confuses people as to what it does. Its also known as the bitwise inversion or bitwise operator if you're curious, [checkout the docs](https://docs.python.org/3/reference/expressions.html?highlight=bitwise#unary-arithmetic-and-bitwise-operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "54bdee9d-0d8d-4aca-807d-6b760a3c0d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9168), tensor(0.9854), tensor(0.9854))"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1- since we want to get the inverse of is_3 to get an 'is_7' function\n",
    "accuracy_7 = (1-is_3(valid_7).float().mean())\n",
    "\n",
    "unary_accuracy_7 = (~is_3(valid_7)).float().mean()\n",
    "\n",
    "accuracy_3, accuracy_7, unary_accuracy_7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796f1713-4c54-46b4-9ba2-ac0604fe520a",
   "metadata": {},
   "source": [
    "Well we're already at ~91% and ~99% for threes and sevens, I think thats pretty awesome considering we're just doing some averages and using the raw tensors against each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df77e9ed-bb82-4147-80b1-24bde4cf10b2",
   "metadata": {},
   "source": [
    "### Moving from 'Ideal' to Weights with Activations\n",
    "\n",
    "As mentioned in the book, if we're thinking of Arthur Samuel's interpretation of a self learning machine, we want to have a set of weights which we can update which will be highly activated for a particular category, ie large values. If we're thinking of a '1', the weights representing the middle of the image should be highly activated and the weights down the side should be lowly activated, unlike an '8' which would have highly activated sides since the hips of the digit would activate the weights. We would want a set of weights for each category and we'd want to times all the weights by the pixels, calculate a loss, figure the gradients for the weights and update them by some learning rate. This function might look something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "9a57336f-3b86-4232-ab8d-166b44dbb3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_of_eight(image, weights): return (image*weights).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43767fdc-e73f-445f-9468-c74c00353eda",
   "metadata": {},
   "source": [
    "Assume 'image' is the image represented as a vector, so all the pixels lined up in a rank-1 tensor, all the rows lined up one after the other instead of stacked into a rank-2 tensor like we view them. Assume the 'weights' variable is also a vector where we can update them after calculating the loss and gradients which we times by some learning rate, we can iterate over and over to get to useful activations that tell us which category the digit drawings are.\n",
    "\n",
    "Ok directly from the book, here are the steps we require to make our classifier:\n",
    " 1. Initialise the weights to some set of values\n",
    " 2. For each image, use the weights to predict a 3 or 7 spotted\n",
    " 3. Based on those predictions, calculate how effective the model was or its loss\n",
    " 4. Calculate the gradient for our weights, which will tell us how changing those weights would impact the loss function\n",
    " 5. Change all the weights based on the gradients and some learning rate\n",
    " 6. Repeat steps 2 through 6 until the training process (this loop) is stopped from successfully completing the task or sheer boredom sets in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5e2dba-3d4a-453e-a303-a1a5c2080890",
   "metadata": {},
   "source": [
    "### Step 1: Initialise parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db64eebf-5077-42d8-95e4-17dbeb1ddfc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
